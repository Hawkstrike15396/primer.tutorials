---
title: 'Three Parameters: Overview'
author: Mahima Malhotra and Mann Talati
tutorial:
  id: three-parameters-overview
output:
  learnr::tutorial:
    progressive:  true
    allow_skip::  true
runtime: shiny_prerendered
description: "Chapter 5 Tutorial: Three Parameters"
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(primer.data)
library(rstanarm)
library(gt)

fit_1 <- stan_glm(age ~ party - 1, 
                    data = trains,
                    refresh = 0)

new_obs <- tibble(party = "Democrat")

pp <- posterior_predict(fit_1, newdata = new_obs) |> 
  as_tibble() |> 
  mutate_all(as.numeric)

age_party_graph <- fit_1 |>
  as_tibble() |>
  select(-sigma) |>
  mutate(Democrat = partyDemocrat, Republican = partyRepublican) |>
  pivot_longer(cols = Democrat:Republican,
               names_to = "parameter",
               values_to = "age") |>
  ggplot(aes(x = age, fill = parameter)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = 0.5,
                   bins = 100,
                   position = "identity") +
    labs(title = "Posterior for Average Age",
         subtitle = "More data allows for a more precise posterior for Democrats",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

age_dem <- pp |> 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
    labs(title = "Posterior for a Random Democrat's Age",
         subtitle = "Individual predictions are always more variable than expected values",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

newobs <- tibble(party = c("Democrat", "Democrat", "Democrat", 
                        "Republican", "Republican","Republican"))

pp <- posterior_predict(fit_1, newdata = newobs) |>
    as_tibble() |>
    mutate_all(as.numeric) |> 
    set_names(c("dem_1", "dem_2", "dem_3", 
                "rep_1", "rep_2", "rep_3")) |> 
    rowwise() |> 
    mutate(dems_oldest = max(c_across(dem_1:dem_3)),
           reps_youngest = min(c_across(rep_1:rep_3)),
           age_diff = dems_oldest - reps_youngest)

age_diff_graph <- pp |>  
  ggplot(aes(x = age_diff)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Age Difference",
         subtitle = "Oldest of three Democrats compared to youngest of three Republicans",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local")
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Make the tutorial follow the chapter very closely: section by section. -->

<!-- Use our new skeletons.  -->

<!-- Change text questions to allow for written answers, and then provide your own perfect written answders. -->

<!-- MT: Still need to replace primer.data with other data -->

## Introduction
###

This tutorial covers [Chapter 5](https://ppbds.github.io/primer/08-three-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/). This tutorial will review topics including Three Parameters, cardinal virtues (wisdom, justice, courage, temperance), and an in-depth analysis of the **trains** data.

## Cardinal Virtues with Wisdom
###

*Wisdom* begins with considering the questions we desire to answer and the data set we are given. In this chapter, we are going to ask a series of questions involving train commuters’ ages, party affiliations, incomes, and political ideology, as well as the causal effect of exposure to Spanish-speakers on their attitude toward immigration. These questions will pertain to all train commuters in the US today. 

### Exercise 1

In order to answer the following questions we need to first make our Preceptor Table.

*What is the probability that if a Democrat shows up to a train station in the U.S today, he will be over 50 years old?*

*In a group of train commuters in the U.S. today in which three are Democrats and three are Republicans, what will the age difference be between the oldest Democrat and the youngest Republican?* 

In one sentence explain the columns that we would like to have in our Preceptor Table.

```{r wisdom-1}
question_text(NULL,
	message = "Our columns would be for party and age of the train commuters.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Next let's consider the following questions we need to first make our Preceptor Table.

*What is the average treatment effect, of exposing U.S train commuters today to Spanish-speakers, on their attitudes toward immigration?* 

*What is the largest causal effect on immigration attitudes due to exposing U.S. train commuters today to Spanish-speakers which still has a 1 in 10 chance of occurring?*

In one sentence explain the columns that we would like to have in our Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "These questions would require a column for the immigration attitudes for someone who was not exposed to spanish-speakers and for someone who wasn't exposed.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

*What would you expect the income to be for a random 40 year old train commuter in the U.S. today?*

In one sentence explain the columns that we would like to have in our Preceptor Table.

```{r wisdom-3}
question_text(NULL,
	message = "We would need the columns of age and income within this scenario for the Preceptor Table.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

*Among all people who have an income $100,000, what proportion are liberal?*

*Assume we have a group of eight people, two of whom make $100,000, two $200,000, two $300,000 and two $400,000. How many will be liberal?*

In one sentence explain the columns that we would like to have in our Preceptor Table.

```{r wisdom-4}
question_text(NULL,
	message = "We would need a column for income, and a column for whether someone is liberal or not.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In the past four exercises, we have executed the first step of *Wisdom*, in considering the questions and figuring out ideally what data we would have to answer them. In doing so, we have determined the columns of our Preceptor Table, those being age, political party, immigration attitude for those who were exposed to Spanish speakers and for those who weren't, as well as income, and being liberal or not. 

The combined Preceptor Table for all the question is shown below.

```{r echo = FALSE}
tibble(ID = c("Commuter 1", "Commuter 2", "...", "Commuter 1000", "Commuter 1001", "..."),
       age = c("23", "18", "...", "49", "38", "..."),
       party = c("Democrat", "Republican", "...", "Republican", "Democrat", "..."),
       income = c("50000", "150000", "...", "100000", "200000", "..."),
       liberal = c("Liberal", "Not Liberal", "...", "Liberal", "Liberal", "..."),
       attitude_after_control = c("3", "7", "...", "4", "9", "..."),
       attitude_after_treated = c("8", "7", "...", "8", "7", "...")
       ) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(ID = md("ID"),
             age = md("Age"),
             party = md("Party"),
             income = md("Income"),
             liberal = md("Liberal"),
             attitude_after_control = md("Control Ending Attitude"),
             attitude_after_treated = md("Treated Ending Attitude")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything())
```

### Exercise 5

Next, let's take a look at the dataset we would like to use to answer these questions. We will be using `trains`. First, let's take a look at **trains** through the glimpse method.

```{r wisdom-5, exercise = TRUE}

```

```{r wisdom-5-hint-1, eval = FALSE}
glimpse(...)
```

### 

Notice that `att_end` is an `<int>` rather than a `<dbl>` and that `party` is a `<chr>` while `treatment` is a factor. 

### Exercise 6

Run '?trains'. 

```{r wisdom-6, exercise = TRUE}

```

```{r wisdom-6-hint-1, eval = FALSE}
?trains
```

Notice how `att_end` represents immigration attitudes after treatment of being exposed to Spanish-speakers on a scale of 3 to 15, where higher numbers indicate a more conservative attitude.

### Exercise 7

In two sentences explain how well the data we have matches up with the data we indicated we would need in our Preceptor Table and why we can answer all of our questions.

```{r wisdom-7}
question_text(NULL,
	message = "We can answer every question since we have the data to do so. We will need the columns of age, income, party, liberal, att_end and treatment because age, income, party, liberal, and att_end are all important to validate our data, specfically att_end is the individual's ending attitude on immigration and treatment is whether or not the individual was exposed to Spanish-speakers.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

Recall that this study was done in Boston, MA in 2012. Write two sentences discussing whether you believe it's reasonable to consider this data to be drawn from the same population as our Preceptor Table. Identify at least one reason that you may not consider the data to be drawn from the same population.

```{r wisdom-8}
question_text(NULL,
	message = "One possible reason we may not consider the data to be drawn from the same population as our Preceptor Table due to changes that may have occurred over time. A belief that our larger population is unable to include both 2012 and 2021 for some reason such as if we believed that the political climate was far too different.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

While you may or may not believe that the data can be applied to our population, it is necessary to discuss how the populations may be similar and different in order to determine whether we can continue. 

For our purposes, we will assume that the data is drawn from the same population and can be applied to our population by treating data from 2012 to be exchangeable with data from 2021.

### 

We have now completed *Wisdom* by creating our Preceptor Table and analyzing our data and determining its application to our questions and our population. Therefore, let's take a look at our population table.

```{r}
tibble(source = c("Preceptor Table", "Preceptor Table", "Preceptor Table",  "...", "Data", "Data", "Data", "...", "Population", "Population", "Population"),
       city = c("Chicago, IL", "Seattle, WA", "Atlanta, GA", "...",
                  "Boston, MA", "Boston, MA", "Boston, MA", "...",
                  "?", "?", "?"),
       year = c("2021", "2021", "2021", "...",
                "2012", "2012", "2012", "...",
                "?", "?", "?"),
       age = c("?", "?", "?", "...",
                 "43", "52", "28", "...",
                 "?", "?", "?"),
       party = c("?", "?", "?", "...", 
                  "Democrat", "Republican", "Republican", "...",
                  "?", "?", "?"),
       income = c("?", "?", "?", "...", 
                    "150000", "50000", "200000", "...",
                    "?", "?", "?"),
       liberal = c("?", "?", "?", "...", 
                 "Liberal", "Liberal", "Not Liberal", "...",
                 "?", "?", "?"),
       att_treat = c("?", "?", "?", "...", 
                 "6", "8", "4", "...",
                 "?", "?", "?"),
       att_control = c("?", "?", "?", "...", 
                 "4", "2", "5", "...",
                 "?", "?", "?")) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(source = md("Source"),
             city = md("City"),
             year = md("Year"),
             age = md("Age"),
             party = md("Party"),
             income = md("Income"),
             liberal = md("Liberal"),
             att_treat = md("Treatment"),
             att_control = md("Control")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())  
```

Remember that since we are considering the data from 2012 and from now to be drawn from the same population, then  we are assuming that between 2012 and now, not much has changed in terms of the age distribution or party affiliation, etc., of train commuters. Therefore, we also assume that this data could be applied to some range of years before and after 2012 which includes 2021. Additionally, if we are assuming that the data specific to train stations in Boston, MA, is drawn from the same population as our population of train commuters in the U.S. today, then that also indicates to us that the population table will include commuters from locations in cities around the U.S..

## age ~ party with Justice, Courage, and Temperance
###

We want to build a model and then use that model to make claims about the world. Our questions about the relationship between age and party are the following:

1. What is the expected age of a Democrat at the train station?
2. In a group of three Democrats and three Republicans, what will the age difference be between the oldest Democrat and the youngest Republican?

We can answer these and similar questions by creating a model that uses party affiliation to predict age

### 

Recall the Population Table, narrowed to be specific to this relationship.

```{r}
tibble(source = c("Preceptor Table", "Preceptor Table", "Preceptor Table",  "...", "Data", "Data", "Data", "...", "Population", "Population", "Population"),
       city = c("Chicago, IL", "Seattle, WA", "Atlanta, GA", "...",
                  "Boston, MA", "Boston, MA", "Boston, MA", "...",
                  "?", "?", "?"),
       year = c("2021", "2021", "2021", "...",
                "2012", "2012", "2012", "...",
                "?", "?", "?"),
       age = c("?", "?", "?", "...",
                 "43", "52", "28", "...",
                 "?", "?", "?"),
       party = c("?", "?", "?", "...", 
                  "Democrat", "Republican", "Republican", "...",
                  "?", "?", "?")) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(source = md("Source"),
             city = md("City"),
             year = md("Year"),
             age = md("Age"),
             party = md("Party")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())  
```

### Exercise 1

Let's consider the *validity* of our data. Recall that validity pertains to the columns of the data and whether they have the same meaning down the columns of the population table. Write two sentences discussing whether the *assumption of validity* for `party` has the same meaning in the Preceptor Table and the Population Table. In other words, does it mean the same thing to identify as a Republican or Democrat in 2012 as it does in 2021? Include a possible reason we would not want to do so.

```{r age--party-1}
question_text(NULL,
	message = "While between 2012 and 2021, the political parties have polarized more, we can still consider the overall core beliefs to not have changed significantly, so we will consider our data to be valid. However, you may disagree, but it's important to consider aspects that have influenced the meaning of the columns. Between then and now, there have been divisive elections and national events bringing greater attention to social and political issues which may have changed the meaning of aligning with a party.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Now, consider the *stability* of this relationship. Write two sentences discussing whether you think the relationship between `age` and `party` has changed between 2012 and 2021. Give a specific example or piece of knowledge that could have affected this relationship.

```{r age--party-2}
question_text(NULL,
	message = "One factor that you may consider is how Democrats have been getting younger. Due to this, it is possible that our age distribution made with our 2012 data may not be applicable to our present. Another factor to consider may be that in our present, more companies than did in 2012 may be working online so less people may be commuting to work. If this lessened commuting were to have a more drastic impact on a certain age group, such as those who are elder, this could also impact our age distribution.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

*Stability* means that the relationship between the columns is the same for three categories of rows: the data, the Preceptor table, and the larger population from which both are drawn. With something like political ideology, it is much harder to make the assertion that data collected in 2010 would be stable to data collected in 2030. When we are confronted with this uncertainty, we can consider making our timeframe smaller. However, we would still need to assume stability from 2014 (time of data collection) to today. *Stability* allows us to ignore the issue of time.

### Exercise 3

Before we consider an issue with *representativeness*, recall our sampling mechanism. Essentially, in 9 train stations in Boston, MA., train commuters on two trains were given surveys before and after their respective treatments, one train receiving the control, and the other being exposed to Spanish-speakers. However, participation and submission of this form was voluntary and induced by payment.

###

With this knowledge, we must consider the *representativeness* of the data. Write 2 sentences discussing whether we can assume the data of 2012 Boston train commuters is representative of 2012 US train commuters. Consider specifically the location of train commuters in our data as opposed to our population and how this could lead to issues with *representativeness*.

```{r age--party-3}
question_text(NULL,
	message = "As we know, Boston is going to be fairly different than many places in the US, but no data that we have will be perfectly representative of our population. What we must consider is if it is representative enough. So, while we may feel more comfortable considering Boston to be more similar to some cities than other locations in the US, we can probably consider it representative enough of 2012 US train commuters.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

*Representativeness* has to do with how well our sample represents the larger population we are interested in generalizing to. Does the train experiment allow us to calculate a causal effect for people who commute by cars? Can we calculate the causal effect for people in New York City? Before we generalize to broader populations we have to consider if our experimental estimates are applicable beyond our experiment. Generally: if there was no chance that a certain type of person would have been in this experiment, we cannot make an assumption for that person.

### Exercise 4

In two sentences explain whether our *DGM* would be linear or logistic, include the family that you would use in `stan_glm` when making the fitted model.

```{r age--party-4}
question_text(NULL,
	message = "Since age is our outcome variable and is continuous, we will use a linear model. Therefore we will set the family argument to 'gaussian'.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

###

Any *DGM* with age as its dependent variable will be predictive, not causal, for the simple reason that nothing, other than time, can change your age. You are X years old. It would not matter if you changed your party registration from Democrat to Republican or vice versa. Your age is your age. When dealing with a non-causal DGM, the focus is on predicting things. The underlying mechanism which connects age with party is less important than the brute statistical fact that there is a connection. Predictive models care little about causality.

### Exercise 5

Now, let's make our posterior distribution using `stan_glm()`. Set your outcome variable as `age`and your explanatory variable as `party` (Remember you must insert a tilde `~` between the two). Also, include a `-1` after `party`.

```{r age--party-5, exercise = TRUE}

```

```{r age--party-5-hint-1, eval = FALSE}
stan_glm(age ~ party - 1, 
         data = ...,
         refresh = ...,
         family = ...)
```

###

The variable before the tilde, `age`, is our outcome. The only explanatory variable is `party`. This variable has only two values, ‘Democrat’ and ‘Republican’. We have also added `-1` at the end of the equation, indicating that we do not want an intercept, which would otherwise be added by default.

### Exercise 6

Set `data` to `trains`, and `refresh` to 0.

```{r age--party-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-6-hint, eval = FALSE}
stan_glm(..., 
         data = ...,
         refresh = ...)
```

### Exercise 7

Since it's a linear model, set `family` to `gaussian`.

```{r age--party-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-7-hint, eval = FALSE}
stan_glm(..., 
         ...,
         ...,
         family = ...)
```

###

Recall that our model is linear. Since we are using a linear model, the `family` we use will be `gaussian`.

### Exercise 8

Store the above in an object called `fit_1` and print it out. 

```{r age--party-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-8-hint-1, eval = FALSE}
fit_1 <- ...
```

### Exercise 9

Now let's display this information graphically. To do so, we will make the below plot.

```{r}
age_party_graph <- fit_1 |>
  as_tibble() |>
  select(-sigma) |>
  mutate(Democrat = partyDemocrat, Republican = partyRepublican) |>
  pivot_longer(cols = Democrat:Republican,
               names_to = "parameter",
               values_to = "age") |>
  ggplot(aes(x = age, fill = parameter)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = 0.5,
                   bins = 100,
                   position = "identity") +
    labs(title = "Posterior for Average Age",
         subtitle = "More data allows for a more precise posterior for Democrats",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

age_party_graph
```

###

First, let's make `fit_1` into a tibble with `as_tibble()` and remove `sigma` with `select()`.

```{r age--party-9, exercise = TRUE}

```

```{r age--party-9-hint-1, eval = FALSE}
fit_1 |> 
  ...() |> 
  select(- sigma)
```

### Exercise 10

Continue the pipe and change the labels of `partyDemocrat` and `partyRepublican` to be `Democrat` and `Republican` respectively.

```{r age--party-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-10-hint-1, eval = FALSE}
... |> 
  mutate(Democrat = ..., Republican, ...)
```

###

`partyDemocrat` corresponds to `β1`, the average age of Democrats in the population. `partyRepublican` corresponds to `β2`, the average age of Republicans in the population. 

### Exercise 11

Continue this pipe and use `pivot_longer()` with the arguments `cols` set to `Democrat:Republican`, `names_to` set to `"parameter"`, and `values_to` set to `"age"`.

```{r age--party-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-11-hint-1, eval = FALSE}
... |> 
pivot_longer(cols = ...,
             names_to = "...",
             values_to = "...")
```

### Exercise 12

Map `age` to the x-axis and set `parameter` to fill with `ggplot()`. Then use `geom_histogram()`.

```{r age--party-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-12-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ..., fill = ...)) +
  ...()
```

### Exercise 13

Now convert the y-axis to be a probability by using `aes()` in the first parameter of `geom_histogram()`. Additionally, set `alpha` to 0.5, `bins` to 100, and `position` to "identity".

```{r age--party-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-13-hint-1, eval = FALSE}
... +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = ...,
                   bins = ...,
                   position = "...")
```

### Exercise 14

Add labels and change the scale on the y-value to make it into a percent format. Also add `theme_classic()`. 

The graph should look something like the following:

```{r age--party-14, echo = FALSE}
age_party_graph
```

```{r age--party-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-14-hint-1, eval = FALSE}
To change the label, you can use `scale_y_continuous`
```

```{r age--party-14-hint-2, eval = FALSE}
... |> 
  labs(title = ...,
       subtitle = ...,
       x = ...,
       y = ...) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic()
```

### 

You have now created the posterior probability distribution for average age in relation to each party. Using this, we can answer the questions we began with pertaining to the relationship between age and party affiliation of train commuters.

###

This brings us to the *Temperance* virtue for our model of `age~party`. 

### Exercise 15

Let's start by recalling the first question.

*What is the probability that if a Democrat shows up to the train station, he will be over 50 years old?*

Using our fitted data, we can now attempt to answer this question and to do so, will make the following plot.

```{r echo = FALSE}
age_dem <- pp |> 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
    labs(title = "Posterior for a Random Democrat's Age",
         subtitle = "Individual predictions are always more variable than expected values",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

age_dem
```

###

First make a new tibble with one observation of the `party` set to the value of the `"Democrat"`. Set this equal to `new_obs`.

```{r age--party-15, exercise = TRUE}

```

```{r age--party-15-hint-1, eval = FALSE}
new_obs <- tibble(party = ...)
```

### Exercise 16

Let's use `posterior_predict()` to create draws from the posterior. Set the first argument to the model for which we are running our simulations, `fit_1`, and the second argument to `new_obs`. Additionally, make all of the columns into numeric vectors. Store this as `pp`.

```{r age--party-16, exercise = TRUE}

```

```{r age--party-16-hint-1, eval = FALSE}
Remember to use as_tibble() to convert the result to a tibble as well as mutate() to change the results to numbers.
```

```{r age--party-16-hint-2, eval = FALSE}
pp <- posterior_predict(..., newdata = ...) |> 
  as_tibble() |> 
  mutate_all(as.numeric)
```

### Exercise 17

Now, let's plot this. Map the column representing age to the x-axis. Then use geom_histogram and use `aes()` in as the first argument to make the y-axis represent the probability. To do so, use `aes(y = after_stat(count/sum(count)))` as the first argument. Additionally, set `bins` to 100.

```{r age--party-17, exercise = TRUE}

```

```{r age--party-17-hint-1, eval = FALSE}
Remember that columns aren't named, so since age is in the first column, the x argument would need to be set at `1`. 
```

```{r age--party-17-hint-2, eval = FALSE}
... |> 
  ggplot(aes(x = `1`)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                bins = ...)
```

### Exercise 18

Now, add a labels, make the scale for the y-values into percent-format, and add `theme_classic()`.

Recall, your result should appear similar to the following:

```{r echo = FALSE}
age_dem
```

```{r age--party-18, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-18-hint-1, eval = FALSE}
... +
  labs(title = "...",
       subtitle = "...",
       x = "...",
       y = "...") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()
```

###

Now that we have the posterior distribution, we can determine the probability the next Democrat will be over 50. 

### Exercise 19

In order to do so, use the posterior distribution and sum up the values in which the age is greater than 50. Then divide this value by the number of rows there are.

```{r age--party-19, exercise = TRUE}

```

```{r age--party-19-hint-1, eval = FALSE}
sum(pp$`1` > 50) / nrow(pp)
```

### 

Therefore, the probability that the next Democrat will be over 50 is around 28%. 

<!-- MM: Change that answer so it isn't hardcoded -->

### Exercise 20

Next, let's consider the second question. 

*In a group of three Democrats and three Republicans, what will the age difference be between the oldest Democrat and the youngest Republican?*

To answer this, we will create the following plot.

```{r}
age_diff_graph <- pp |>  
  ggplot(aes(x = age_diff)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Age Difference",
         subtitle = "Oldest of three Democrats compared to youngest of three Republicans",
         x = "Age",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

age_diff_graph
```

###

Since our group has three Democrats and three Republicans, make a tibble with the observations of the column "party" that we desire. Store this as `new_obs`.

```{r age--party-20, exercise = TRUE}

```

```{r age--party-20-hint-1, eval = FALSE}
newobs <- tibble(party = c(...))
```

```{r age--party-20-hint-2, eval = FALSE}
newobs <- tibble(party = c("Democrat", "Democrat", "Democrat", 
                           "Republican", "Republican","Republican"))
```

### 

When doing this, ensure that the column names and the observations align with those of the original data set.

### Exercise 21

Now use posterior predict and make the values numeric vectors in order to create the posterior distribution. Remember to use our first argument as the fitted model `fit_1` we created earlier and the `newdata` equal to `newobs`.

```{r age--party-21, exercise = TRUE}

```

```{r age--party-21-hint-1, eval = FALSE}
posterior_predict(..., newdata = ...) |>
    ...() |>
    mutate_all(as.numeric)
```

### Exercise 22

Currently your posterior predict has numbered columns correlating to the order in which we made the columns in `newobs`. Set the names to "dem_1", "dem_2", "dem_3", "rep_1", "rep_2", and "rep_3", respectively.

```{r age--party-22, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-22-hint-1, eval = FALSE}
Use the method set_names().
```

```{r age--party-22-hint-2, eval = FALSE}
set_names(c(..., ..., ..., ..., ..., ...))
```

### 

While the above step may not be necessary and we could proceed with the numbered columns, renaming makes it easier for us to use the distribution since it makes the columns more clear to us.

### Exercise 23

Next, group the data by row. Then, create a column `dems_oldest` that has the oldest aged Democrat in the row, a column `reps_youngest` with the youngest aged Republican in the row, and a column `age_diff` for the difference between the oldest Democrat and the youngest Republican in this row. Store this as `pp` and print the result.

```{r age--party-23, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-23-hint-1, eval = FALSE}
Recall the methods `max()` and `min()`. Also, `c_across()` can be used to create a list across columns.
```

```{r age--party-23-hint-2, eval = FALSE}
... |> 
  rowwise() |> 
  mutate(dems_oldest = max(c_across(...)),
         reps_youngest = min(c_across(...)),
         age_diff = dems_oldest - reps_youngest)
```

### 

In doing so, we have found the posterior distribution for the age difference between the oldest Democrat and youngest Republican for train commuters with a group of three Democrats and three Republicans.

### Exercise 24

Let's plot this. Start by using `ggplot` and mapping the the age difference to the x-axis. Then, add the layer geom_histogram and use `aes()` within the first argument to set the y-value to be the probability. Additionally, set the second argument `bins` equal to 100.

```{r age--party-24, exercise = TRUE}

```

```{r age--party-24-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ...)) + 
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = ...)
```

### Exercise 25

Continue this pipe by adding labels. Then change the y-axis to be in percent_format and add the layer `theme_classic()`.

Remember, your plot should look something like this:

```{r echo = FALSE}
age_diff_graph
```

```{r age--party-25, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r age--party-25-hint-1, eval = FALSE}
... +
  labs(...) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

### 

With the posterior age difference model, we can now go on to answer our question.

### Exercise 26

Use the distribution to approximate what we would expect the age difference to be between the oldest Democrat and youngest Republican in a group of train commuters with 6 Democrats and 6 Republicans.

```{r age--party-26}
question_text(NULL,
	message = "As can be seen by the above distribution, we would expect the age difference to be about 22 years.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

As we have seen, through the use of our fitted data and `posterior_predict()`, we were able to answer our questions regarding age and party.

Let's continue this process with our questions pertaining to immigration attitude and exposure to Spanish-speakers.

## att_end ~ treatment with Justice, Courage, and Temperance

Recall our questions regarding the treatment effect on `att_end`:

*What is the average treatment effect, of exposing train commuters to Spanish-speakers, on their attitudes toward immigration?*

*What is the largest causal effect of exposing train commuters to Spanish-speakers which still has a 1 in 10 chance of occurring?*

Unlike our previous model, this will be a causal model since the treatment of being exposed to Spanish-speakers may cause a change in immigration attitudes, unlike how changing party registration will have no effect on age.

Here is the sub-part of our population table relevant to our current questions.

```{r}
tibble(source = c("Preceptor Table", "Preceptor Table", "Preceptor Table",  "...", "Data", "Data", "Data", "...", "Population", "Population", "Population"),
       city = c("Chicago, IL", "Seattle, WA", "Atlanta, GA", "...",
                  "Boston, MA", "Boston, MA", "Boston, MA", "...",
                  "?", "?", "?"),
       year = c("2021", "2021", "2021", "...",
                "2012", "2012", "2012", "...",
                "?", "?", "?"),
       att_treat = c("?", "?", "?", "...", 
                 "6", "8", "4", "...",
                 "?", "?", "?"),
       att_control = c("?", "?", "?", "...", 
                 "4", "2", "5", "...",
                 "?", "?", "?")) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(source = md("Source"),
             city = md("City"),
             year = md("Year"),
             att_treat = md("Treatment"),
             att_control = md("Control")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything()) 
```

### Exercise 1

Let's look at the validity of our model. Write a three sentences discussing the meaning of receiving the treatment and some problems that we might run into when combining the `att_end` column from the data and our Preceptor Table. 

```{r attend--treatment-1}
question_text(NULL,
	message = "First, let's consider the validity between 2012 and 2021. If we were to run the study again now, we wouldn't be able to get the exact same Spanish-speakers as we did in 2012. However, we can likely assume that this difference is insignificant when considering the data. Additional problems may occur for those who came early to the train station or were running late and were exposed to Spanish-speakers for more or less time than others.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### Exercise 2

Next, consider the stability of our model. Write two sentences considering whether you believe the model to be stable and provide a possible reason for why we may not consider the relationship between `att_end` and `treatment` to be stable.

```{r attend--treatment-2}
question_text(NULL,
	message = "Some reasons that you may consider could be the controversial elections and events in the US that have occurred between 2012 and now that may have had vast affects on immigration views in the US.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

While you have discussed a reason that the model may not be stable, we will assume that this has not impacted our relationship and assume the model to be stable.
 

### Exercise 3

Now, let's take a look at representativeness. Write two sentences discussing if we can consider the data from Boston in 2012 to be representative of the US in 2012. Include at least one reason for which we may not believe this.

```{r attend--treatment-3}
question_text(NULL,
	message = "One point you may consider is how these may have changed over time. An additional point of discussion could be the location of Boston compared to other locations, such as those with a different sized Spanish-speaking population.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

Lastly, write one sentence stating whether we will use a linear or logistic model. Use the words "outcome variable".

```{r attend--treatment-4}
question_text(NULL,
	message = "Since the outcome variable is `att_end` which is continuous, this will be a linear model.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 5

```{r}
fit_2 <- stan_glm(att_end ~ treatment - 1, 
                      data = trains,
                      refresh = 0)
```

Now, that we have considered the Justice virtue, let's continue to Courage and make our fitted model using `stan_glm()`.  

Set your outcome variable as `att_end`and your explanatory variable as `treatment` (Remember you must insert a tilde `~` between the two). Also, include a `-1` after `treatment` so we do not get an intercept.  Set `data` to `trains`, and `refresh` to 0. Set this to the `fit_2` and print it out.

<!-- MM: Add family argument and break into more sections -->

```{r attend--treatment-5, exercise = TRUE}

```

```{r attend--treatment-5-hint-1, eval = FALSE}
fit_2 <- stan_glm(... ~ ... -1,
                  data = ...
                  refresh = ...)
```

### 

Now, let's look at the posterior distributions for those who were treated and those who weren't.

### Exercise 6

To do so, we will make the following plot.

```{r}
treat_post <- fit_2 |> 
  as_tibble() |> 
  select(-sigma) |> 
  pivot_longer(cols = treatmentTreated:treatmentControl,
               names_to = "Parameter",
               values_to = "attitude") |> 
  ggplot(aes(x = attitude, fill = Parameter)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = 0.5, 
                   bins = 100, 
                   position = "identity") +
    labs(title = "Posterior for Expected Attitude Toward Immigration",
         subtitle = "Treated individuals are more conservative",
         x = "Attitude",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) + 
    theme_classic()

treat_post
```

First, make `fit_2` into a tibble and get rid of `sigma` since it is not of importance to us. Remember that you need to use `as_tibble()`.

```{r attend--treatment-6, exercise = TRUE}

```

```{r attend--treatment-6-hint-1, eval = FALSE}
fit_2 |> 
  as_tibble() |> 
  select(...)
```

### Exercise 7

Next, use `pivot_longer()` with the argument of `cols` set to the "treatmentTreated" and "treatmentControl". Set the argument `names_to` to "Parameter", and `values_to` to "attitude".

```{r attend--treatment-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-7-hint-1, eval = FALSE}
... |> 
  pivot_longer(cols = ...,
               names_to = ...
               values_to = ...)
```

### Exercise 8

Let's plot this.  Map `attitude` on the x-axis and set `fill` to `Parameter`. Add the layer `geom_histogram()` and make y into a probability. Set `alpha` to 0.5, `bins` to 100, and `position` to "identity".

```{r attend--treatment-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-8-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ..., y = ...)) + 
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 alpha = ...,
                 bins = ...
                 position = ...)
```

### Exercise 9

Next, add labels, change the y-scale to be in a percent format and add the layer `theme_classic()`.

The posterior should appear similar to the following:

```{r}
treat_post
```

```{r attend--treatment-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-9-hint-1, eval = FALSE}
... +
  labs(...) + 
  scale_y_continous(labels = scales::percent_format()) + 
  theme_classic()
```

### 

Now, using this posterior distribution, we can go on to answer the questions that we began this section with. 

### Exercise 10

Recall our first question pertaining to this distribution:

*What is the average treatment effect, of exposing people to Spanish-speakers, on their attitudes toward immigration?*

To help us answer this, we will make the following plot.

```{r}
newobs <- tibble(treatment = c("Treated", "Control"))

pe <- posterior_epred(fit_2, newobs) |> 
    as_tibble() |> 
    mutate(ate = `1` - `2`)

```

```{r}
ate_graph <- pe |> 
  ggplot(aes(x = ate)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Average Treatment Effect",
         subtitle = "Exposure to Spanish-speakers shifts immigration attitudes rightward",
         x = "Difference in Attitude",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

ate_graph
```

Using the distribution, approximate the average treament effect.

```{r attend--treatment-10}
question_text(NULL,
	message = "Your answer should fall around 1.5",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 11

Now, let's use `posterior_epred()` to answer this question. Create a tibble like we have done before with our desired ovservations. For this scenario, call it `newobs` and set `treatment` having two values, "Treated" and "Control".

```{r attend--treatment-11, exercise = TRUE}

```

```{r attend--treatment-11-hint-1, eval = FALSE}
newobs <- tibble(treatment = c("Treated", "Control"))
```

### Exercise 12

Next, use `posterior_epred()` and set the first argument to our fitted model and the second to the tibble we just created. Remember we need to use `as_tibble()`.

```{r attend--treatment-12, exercise = TRUE}

```

```{r attend--treatment-12-hint-1, eval = FALSE}
posterior_epred(..., ...) |> 
  as_tibble()
```

### Exercise 13

Continue this pipe and add a column `ate` for the average treatment effect. Set this to `pe`. 

Recall that the average treatment effect is the control value subtracted from the treated value.

```{r attend--treatment-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-13-hint-1, eval = FALSE}
Remember that our columns are not titled, but are numbered and we need to use the format `1` to get the value from our first column.
```

```{r attend--treatment-13-hint-2, eval = FALSE}
pe <- ... |> 
  mutate(ate = `1` - `2`)
```

### 

This results in the posterior probability distribution of average treatment effect.

### Exercise 14

Now, let's graph this. Map `ate` to the x-axis and add the layer `geom_histogram()`. Make the values on the y-axis probabilities and set the argument `bins` to 100. 

```{r attend--treatment-14, exercise = TRUE}

```

```{r attend--treatment-14-hint-1, eval = FALSE}
pe |>
  ggplot(aes(x = ...)) + 
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = ...)
```

### Exercise 15

Next, add labels, format the values on the y-axis to be percents using `scale_y_continuous`, and add the layer `theme_classic()`.

The posterior should look similar to the following:

```{r}
ate_graph
```

```{r attend--treatment-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-15-hint-1, eval = FALSE}
... + 
  labs(...) + 
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

### 

In creating the posterior distribution, we have effectively answered our first question to determine the average treatment.

### Exercise 16

```{r echo = FALSE}
pp <- posterior_predict(fit_2, 
                        newdata = newobs) |>
    as_tibble() |>
    mutate_all(as.numeric) |> 
    mutate(te = `1` - `2`)
```

Now, let's take a look at our second question. 

*What is the largest effect size which still has a 1 in 10 chance of occurring?*

To answer this one, we will use `posterior_predict()` for two people, one who is treated and the other control. In other words, we can use the tibble `newobs` which we already created. Set the first argument to our fitted model and `newdata` to `newobs`. Make sure to use `as_tibble()` and to make all the values numeric as we have done previously.

```{r attend--treatment-16, exercise = TRUE}

```

```{r attend--treatment-16-hint-1, eval = FALSE}
posterior_predict(..., 
                  newdata = ...) |>
  as_tibble() |>
  mutate_all(as.numeric)
```

### Exercise 17

Continue this pipe and add a column `te` which is the difference between the treated person and the untreated person. Remember the columns are unnamed and that you must use numbers. Store this as `pp`.

```{r attend--treatment-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-17-hint-1, eval = FALSE}
pp <- ... |> 
  mutate(te = `1` - `2`)
```

### 

We have now created the posterior distribution for the treatment effect for one person. 

### Exercise 18

Let's now plot this and make the graph shown below. 

```{r echo = FALSE}
te_graph <- pp |> 
  ggplot(aes(x = te)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
    labs(title = "Posterior for Treatment Effect for One Person",
         subtitle = "Causal effects are more variable for indvduals",
         x = "Difference in Attitude",
         y = "Probability") +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

te_graph
```

Map `te` to the x-axis and add the layer `geom_histogram()`. Make the values on the y-axis into probabilities and set the argument `bins` to 100.

```{r attend--treatment-18, exercise = TRUE}

```

```{r attend--treatment-18-hint-1, eval = FALSE}
pp |> 
  ggplot(aes(x = ...)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = ...)
```

### Exercise 19

Continue this pipe and add labels, format the y-axis to percents, and add the layer `theme_classic()`.

The result should appear similar to the following:
```{r echo = FALSE}
te_graph
```

```{r attend--treatment-19, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r attend--treatment-19-hint-1, eval = FALSE}
... +
  labs(...) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic()
```

### 

Using this distribution, we can evaluate the difference between treatment effect for a single individual and notice how large the spread is. To answer our question though, we need to look at the value at the 90th percentile since we are looking to find what the largest causal effect is that has a 1 in 10 chance of occurring.

### Exercise 20

In order to do so, we can use the function `quantile()`. To do so, select the `te` column of `pp` and use this as the first argument of `quantile()`. Set the second argument `prob` to our desired percentile, 0.9.

```{r attend--treatment-20, exercise = TRUE}

```

```{r attend--treatment-20-hint-1, eval = FALSE}
quantile(pp$te, prob = 0.9)
```

### 

As you can see above, the largest treatment effect that will occur about 10% of the time is 6.6

<!-- MM: Don't hardcode that -->

## income ~ age with Justice, Courage, and Temperance

Let's continue to answering our question pertaining to the relationship between income and age. Recall our question.

*What would you expect the income to be for a 40-year old train commuter?*

Recall the population table pertaining to this question.

```{r}
tibble(source = c("Preceptor Table", "Preceptor Table", "Preceptor Table",  "...", "Data", "Data", "Data", "...", "Population", "Population", "Population"),
       city = c("Chicago, IL", "Seattle, WA", "Atlanta, GA", "...",
                  "Boston, MA", "Boston, MA", "Boston, MA", "...",
                  "?", "?", "?"),
       year = c("2021", "2021", "2021", "...",
                "2012", "2012", "2012", "...",
                "?", "?", "?"),
       age = c("?", "?", "?", "...",
                 "43", "52", "28", "...",
                 "?", "?", "?"),
       income = c("?", "?", "?", "...", 
                    "150000", "50000", "200000", "...",
                    "?", "?", "?")) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(source = md("Source"),
             city = md("City"),
             year = md("Year"),
             age = md("Age"),
             income = md("Income")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())
```

<!-- MM: Add Justice questions -->

### Exercise 1

First, let's make our fitted model using `stan_glm()`. Set your outcome variable to `income` and your explanatory variable to `age`. Set data to `trains` and refresh to `0`. Store this as `fit_3`.

<!-- MM: Add family argument -->

```{r income--age-1, exercise = TRUE}

```

```{r income--age-1-hint-1, eval = FALSE}
fit_3 <- stan_glm(income ~ age,
                  data = ...
                  refresh = ...)
```

```{r echo = FALSE}
fit_3 <- stan_glm(income ~ age, 
                  data = trains,
                  refresh = 0)

```

### 

Unlike previous question we have dealt with regarding predictive modeling, the predictor variable income is continuous in that there are a range of varying incomes as opposed to only having two options of "Democrat" and "Republican as we did in our model of party ~ age.

### Exercise 2

Now that we have made our fitted model, let's make our posterior distribution. Start by making a tibble `newobs` with the observation `age` is equal to 40.

```{r income--age-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r income--age-2-hint-1, eval = FALSE}
newobs <- tibble(age = 40)
```

```{r echo = FALSE}
newobs <- tibble(age = 40)
```

### Exercise 3

Now, recall that `posterior_epred()` is used when looking for expected values such as in this case. Therefore, use `posterior_epred()` with the first argument as our fitted model `fit_3` and the `newdata` argument as `newobs`. Remember to use `as_tibble()`. Store this as `pe`.

```{r income--age-3, exercise = TRUE}

```

```{r income--age-3-hint-1, eval = FALSE}
pe <- posterior_epred(..., newdata = ...) |> 
  as_tibble()
```

```{r echo = FALSE}
pe <- posterior_epred(fit_3, newdata = newobs) |> 
  as_tibble() 
```

### 

Now that we have the posterior for expected income, let's plot it.

### Exercise 4

We will be making the graph shown below.

```{r}
income_post <- pe |> 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
    labs(title = "Posterior for Expected Income",
         subtitle = "A 40-years old commuter earns around $140,000",
         x = "Income",
         y = "Probability") +
    scale_x_continuous(labels = scales::dollar_format()) +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()

income_post
```

Map the column for income to the x-axis. Then add the layer `geom_histogram()` and make y-value a probability. Additionally, make the argument `bins` equal to 100. 

```{r income--age-4, exercise = TRUE}

```

```{r income--age-4-hint-1, eval = FALSE}
Remember that the columns are unnamed so you will have to call them using numbers.
```

```{r income--age-4-hint-2, eval = FALSE}
pe |> 
  ggplot(aes(x = `1`)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = ...)
```

### Exercise 5

Now add labels to the graph and format the x-values to be in dollar-format and the y-values to be percent-format. Also, add the layer `theme_classic()`.

The posterior should appear similar to the following:
```{r echo = FALSE}
income_post
```

```{r income--age-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r income--age-5-hint-1, eval = FALSE}
... +
  labs(...) +
  scale_x_continuous(labels = scales::dollar_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

### Exercise 6

Using the above distribution, estimate about how much a 40-year old train commuter would earn.

```{r income--age-6}
question_text(NULL,
	message = "They would earn around $140,000.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

While this may have been different from the previous predictive models we have worked with since income is a continuous scale, you can see that the process which we used to answer the question did not change.

## liberal ~ income with Justice, Courage, and Temperance

Now, let's move on to our final two questions.

*Among all people who have an income $100,000, what proportion are liberal?*

*Assume we have a group of eight people, two of whom make $100,000, two $200,000, two $300,000 and two $400,000. How many will be liberal?*

Recall the subpart of our population table for these questions.

```{r}
tibble(source = c("Preceptor Table", "Preceptor Table", "Preceptor Table",  "...", "Data", "Data", "Data", "...", "Population", "Population", "Population"),
       city = c("Chicago, IL", "Seattle, WA", "Atlanta, GA", "...",
                  "Boston, MA", "Boston, MA", "Boston, MA", "...",
                  "?", "?", "?"),
       year = c("2021", "2021", "2021", "...",
                "2012", "2012", "2012", "...",
                "?", "?", "?"),
       income = c("?", "?", "?", "...", 
                    "150000", "50000", "200000", "...",
                    "?", "?", "?"),
       liberal = c("?", "?", "?", "...", 
                 "Liberal", "Liberal", "Not Liberal", "...",
                 "?", "?", "?")) |>
  
  # Then, we use the gt function to make it pretty
  
  gt() |>
  cols_label(source = md("Source"),
             city = md("City"),
             year = md("Year"),
             income = md("Income"),
             liberal = md("Liberal")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())
```

### Exercise 1

Now, before we make this model, consider the validity of the data. Write two sentences discussing a reason why `income` and `liberal` may not have the same meaning in our data set and our Preceptor Table.

```{r liberal--income-1}
question_text(NULL,
	message = "One possible reason you may consider include inflation altering the real value of income, in that earning $100,000 in 2012 won't have the same value as earning $100,000 in 2021. You may also consider if the meaning of being liberal has changed over the years and if their are different beliefs now than there were in 2012.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

<!-- MM: Add stability and representativeness questions -->

### Exercise 2

State whether the model is linear or logistic and why. Specify the outcome variable.

```{r liberal--income-2}
question_text(NULL,
	message = "This is a logistic model because `liberal` is the outcome variable and it does not have a range of values, but rather only 2.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Unlike our past three models, in this model the outcome variable is not continuous. In the past three models, we have had outcome variables of `age`, `att_end`, and `income`, all of which have a range of values. 

In this model, however, the outcome variable is `liberal` which only has values of TRUE and FALSE, indicating a logistic model. Therefore, when modeling, we must use the `binomial` family.

### Exercise 3

Let's now fit our model. Use `stan_glm()` and in the first argument, set the explanatory variable to `income` and the outcome variable to `liberal`. Use the data set `trains` and set `refresh` to 0. Additionally, recall that `liberal` only has two possible values, so set `family` to `binomial`. Store this as `fit_4` and print your results.

```{r liberal--income-3, exercise = TRUE}

```

```{r liberal--income-3-hint-1, eval = FALSE}
fit_4 <- stan_glm(liberal ~ income,
                  data = ..., 
                  family = ...,
                  refresh = ...)
```

```{r echo = FALSE}
fit_4 <- stan_glm(liberal ~ income,
                  data = trains, 
                  family = binomial,
                  refresh = 0)
```

### Exercise 4

With our fitted model, we can proceed to answer our questions. Recall our first question for this relationship:

*Among all people who have an income $100,000, what proportion are liberal?*

Like always, to answer the question, we must first make a tibble with the observations we desire. In this case, make a tibble with `income` set to 100000, and store this as `newobs`.

```{r liberal--income-4, exercise = TRUE}

```

```{r liberal--income-4-hint-1, eval = FALSE}
newobs <- tibble(income = ...)
```

```{r echo = FALSE}
newobs <- tibble(income = 100000)
```

### Exercise 5

Now, in order to get our posterior distribution, let's use `posterior_epred()` with the first argument as our fitted model, `fit_4`, and the second argument `newdata` as `newobs`. Remember to make this a tibble as well. Store this as `pe`.

```{r liberal--income-5, exercise = TRUE}

```

```{r liberal--income-5-hint-1, eval = FALSE}
pe <- posterior_epred(..., newdata = ...) |> 
  as_tibble()
```

```{r echo = FALSE}
pe <- posterior_epred(fit_4, newdata = newobs) |> 
  as_tibble()
```

### Exercise 6

Print out `pe`.

```{r liberal--income-6, exercise = TRUE}

```

```{r liberal--income-6-hint-1, eval = FALSE}
pe
```

### 

The population proportion is the same as the probability for any single individual.

### Exercise 7

Now that we have made our posterior distribution, let's plot it by making the following graph.

```{r echo = FALSE}
postlib <- pe |> 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
  
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    labs(title = "Posterior for Proportion Liberal Among $100,000 Earners",
         subtitle = "The population proportion is the same as the probability for any individual",
         x = "Income",
         y = "Probability of Being Liberal") +
  theme_classic()

postlib
```

Start by making a pipe and using `ggplot()` to map the proportions to the x-axis. Add the layer `geom_histogram()` and use `aes(y = after_stat(count/sum(count)))` in order to make the y-axis a probability. Set the argument `bins` to 100.

```{r liberal--income-7, exercise = TRUE}

```

```{r liberal--income-7-hint-1, eval = FALSE}
Remember that your columns are not named, but numbered.
```

```{r liberal--income-7-hint-2, eval = FALSE}
pe |> ggplot(aes(x = `1`)) + 
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = ...)
```

### Exercise 8

Now, format the x and y-axis to appear as percentages.

```{r liberal--income-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-8-hint-1, eval = FALSE}
Use `scale_x_continuous` and `scale_y_continuous`. Also, set `accuracy` to 1 in order to make the number an integer.
```

```{r liberal--income-8-hint-2, eval = FALSE}
... +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

### Exercise 9

Next, add in labels and the layer `theme_classic()`. Remember that your graph should appear similar to the following:

```{r echo = FALSE}
postlib
```

```{r liberal--income-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-9-hint-1, eval = FALSE}
... + 
  labs(...) + 
  theme_classic().
```

### Exercise 10

Now that we've answered our first question, let's consider our second question.

*Assume we have a group of eight people, two of whom make $100,000, two $200,000, two $300,000 and two $400,000. How many will be liberal?*

In order to answer this question, let's first make our tibble with the desired observations. In this case, we would like to have 2 people who make $100,000, $200,000, $300,000, and $400,000 each. So, in our tibble, set income to these values. Store this as `newobs`.

```{r liberal--income-10, exercise = TRUE}

```

```{r liberal--income-10-hint-1, eval = FALSE}
`rep()` can be used to replicate items in the tibble.
```

```{r liberal--income-10-hint-2, eval = FALSE}
newobs <- tibble(income = c(rep(100000, 2),
                            rep(200000, 2),
                            rep(300000, 2),
                            rep(400000, 2)))
```

```{r echo = FALSE}
newobs <- tibble(income = c(rep(100000, 2),
                            rep(200000, 2),
                            rep(300000, 2),
                            rep(400000, 2)))
```

### Exercise 11

Now, let's make our posterior distribution. Stary by using `posterior_predict()` with the first argument as our fitted model `fit_4` and the second argument `newdata` set to `newobs`. Make this a tibble and convert the values to be numeric.

```{r liberal--income-11, exercise = TRUE}

```

```{r liberal--income-11-hint-1, eval = FALSE}
posterior_predict(..., newdata = ...) |> 
  as_tibble() |> 
  mutates_all(as.numeric)
```

### Exercise 12

Continue that pipe by grouping the rows using `rowwise()`.

```{r liberal--income-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-12-hint-1, eval = FALSE}
... |> 
  rowwise()
```

### Exercise 13

Now, like we have done before, we are going to add a total column which is the sum of the entire row since every individual who is liberal in our groupings is represented by a `1` and everyone who isn't is represented by a `0`, so the total will give us the number of liberals in the group. Store this as `pp`.

```{r liberal--income-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-13-hint-1, eval = FALSE}
You can use `c_across` to go across all the columns when taking the sum
```

```{r liberal--income-13-hint-2, eval = FALSE}
... |> 
  mutate(total = sum(c_across()))
```

```{r echo = FALSE}
pp <- posterior_predict(fit_4, 
                        newdata = newobs) |> 
  as_tibble() |> 
  mutate_all(as.numeric) |> 
  rowwise() |> 
  mutate(total = sum(c_across()))
```

### Exercise 14

Now, let's plot this by making the below graph.

```{r}
lib_group <- pp |> 
  ggplot(aes(x = total)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100)  +
    labs(title = "Posterior for Number of Liberals in Group with Varied Incomes",
         subtitle = "Two is the most likely number, but values from 0 to 5 are plausible",
         x = "Number of Liberals",
         y = "Probability") +
    scale_x_continuous(labels = scales::number_format(accuracy = 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_classic()
```

Start by mapping `total` to the x-axis using `ggplot()` and add the layer `geom_histogram()`. Make the y-axis represent the probability rather than the count and set the argument `bins` to 100.

```{r liberal--income-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-14-hint-1, eval = FALSE}
To make y a probability, use `aes(y = after_stat(count/sum(count)))` as the first argument of `geom_histogram()`.
```

```{r liberal--income-14-hint-2, eval = FALSE}
pp |> 
  ggplot(aes(x = total)) |> 
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 bins = 100)
```

### Exercise 15

Now format the x and y axis so that x is an integer and y is a percentage. Use `scale_x_continuous` and `scale_y_continous` to do so.

```{r liberal--income-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-15-hint-1, eval = FALSE}
... + 
  scale_x_continuous(labels = scales::number_format(accuracy = 1)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

### Exercise 16

Now, add labels and layer `theme_classic()` in order to complete the graph. It should appear similar to the following.

```{r echo = FALSE}
lib_group
```

```{r liberal--income-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r liberal--income-16-hint-1, eval = FALSE}
... +
  labs(...) + 
  theme_classic()
```

### 

Through this posterior, it can be seen that it is most likely to have 2 liberals in this group with various incomes.

## Summary
###

This tutorial covered [Chapter 5](https://ppbds.github.io/primer/08-three-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/). This tutorial reviewed the topics of Three Parameters, cardinal virtues (wisdom), and an in-depth analysis of the **trains** data.

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
