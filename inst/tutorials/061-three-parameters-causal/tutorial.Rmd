---
title: 'Three Parameters: Causal'
author: David Kane and Gia Khang
tutorial:
  id: three-parameters-causal
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 6 Tutorial: Three Parameters: Causal'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)
library(primer.data)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

#fit_gauss <- brm(formula = att_end ~ treatment,
#             data = trains,
#             family = gaussian(),
#             silent = 2,
#             refresh = 0,
#             seed = 9)
#write_rds(fit_gauss, "data/fit_gauss.rds")

fit_gauss <- read_rds("data/fit_gauss.rds")

ndata <- tibble(treatment = c("Treated", "Control"))
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- This is the template tutorial for creating any tutorial which uses the Cardinal Virtues to answer a question given a data set. Although its primary use is for the main chapters in the Primer, it could be used for other assignments as well. The letters `XX` are used to indicate locations which require editing. Comments with instructions are interspersed. Read https://ppbds.github.io/primer/key-concepts.html for details on the Cardinal Virtues. -->

<!-- There should be a bunch of quotes for each Cardinal Virtue. All quotes are listed at the introduction of each section. Select just one for each virtue in this tutorial. -->

<!-- There are many opportunities for knowledge drops, especially after definition questions. Use them! Point out something about the details of the particular problem from the chapter. Recall that students often won't read the chapter, so we need to pull out the highlights. -->

<!-- The more that questions force students to consult the chapter, the better. -->

<!-- Key problems with current version: We need (?) to flesh out the Courage and Temperance sections. Key skills to practice each time including writing math formulas in Quarto and creating nice looking tables of regression results. -->

<!-- Make sure to uncomment the tests once they are ready to work. -->

## Introduction
### 

This tutorial covers [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

## Wisdom
### 

*Wisdom begins in wonder.* - Plato

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

If it is not *valid* to consider the data you have and the (theoretical) data from the Preceptor Table to have arisen out of the same population, your attempt to estimate your quantity of interest ends at the first stage. 

### 

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

As we are considering *causal model*, our Preceptor Table will have two columns for the potential outcomes. In any causal model, there is at least one covariate which is defined as the “treatment,” something which we can manipulate, at least in theory, so that some units receive one version and other units get a different version.



### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "Our units for this scenario would be individuals because the questions are about the attributes of unique people at the station. The question does not specify which individuals we are interested in, so assume it is adults in Chicago.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

By definition, *units* are the objects on which the outcome is measured.

### Exercise 5

What is/are the outcome/outcomes for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "A person’s attitude toward immigration is the outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A person's attitude toward immigration is measured based on the three questions, each measuring agreement on a 1 to 5 integer scale, with 1 being liberal and 5 being conservative. For each person, the three answers were summed, generating an overall measure of attitude toward immigration which ranged from 3 (very liberal) to 15 (very conservative).

### Exercise 6

What are the covariates for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "Possible covariates include, but are not limited to, sex, age, political party and almost everything else which might be associated with attitudes toward immigration.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Covariates can be any variable that can influence the outcome.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "In this case, the treatment is exposure to Spanish-speakers. Units can either be exposed, i.e., they receive the 'treatment', or they can not be exposed, i.e., they receive the 'control'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In any causal model, there is at least one covariate which is defined as the “treatment,” something which we can manipulate, in theory, so that some units receive one version and other units get a different version. A “treatment” is just a covariate which we *could* manipulate, at least in theory. 



### Exercise 8

What moment in time does the Preceptor Table refer to?

```{r wisdom-8}
question_text(NULL,
	message = "We are interested in the causal effect today, in the year 2024",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The notion of time is important, both in our Preceptor Table and in our data. Our data comes from some point in the past, even if it was collected yesterday while our questions usually refer to now or to an indeterminate moment in the future.

### Exercise 9

Define causal effect.

```{r wisdom-9}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In most circumstances, we are interested in comparing two experimental manipulations, one generally termed “treatment” and the other “control.” According to the [Rubin Causal Model (RCM)](https://ppbds.github.io/primer/rubin-causal-model.html), the causal effect of being on the platform with Spanish-speakers is the difference between what your attitude would have been under “treatment” (with Spanish-speakers) and under “control” (no Spanish-speakers).

### Exercise 10

What is the **Fundamental Problem of Causal Inference**?

```{r wisdom-10}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Recall the attitudes towards immigrants experiment, it is impossible to observe both potential outcomes at once. One of the potential outcomes is always missing, since a person cannot travel back in time, and experience both treatments. 

### Exercise 11

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-11}
question_text(NULL,
	message = "The causal effect of exposure to Spanish-speakers is well defined because it is the simple difference of two potential outcomes, both of which might happen. In this case, we (or something else) can manipulate the world, at least conceptually, so that it is possible that one thing or a different thing might happen.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Question of what can and cannot be manipulated are very complex when it comes to race, sex, or genetics and should be considered with care. For instance, we cannot increase a person's height so it makes no sense to investigate the causal effect of height on weight, hence the slogan: *No Causation without manipulation*.

### Exercise 12

<!-- DK: It is a feature that this question almost forces students to go to the chapter and read about the data. -->

Write one sentence describing the data you have to answer your question.

```{r wisdom-12}
question_text(NULL,
	message = "The data include information about each respondent’s sex, political affiliations, age, income and so on. 'treatment' indicates whether a subject was in the control or treatment group. The key outcome is their attitude toward immigration after the experiment: 'att_end'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 13

Load the **tidyverse** package.

```{r wisdom-13, exercise = TRUE}

```

```{r wisdom-13-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-13-test, include = FALSE}
library(tidyverse)
```

### 

### Exercise 14

Load the **primer.data** package.


```{r wisdom-14, exercise = TRUE}

```

```{r wisdom-14-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-14-test, include = FALSE}
library(primer.data)
```

### 

### Exercise 15

Type `trains` and hit "Run Code".

```{r wisdom-15, exercise = TRUE}

```

```{r wisdom-15-hint-1, eval = FALSE}
trains
```

```{r wisdom-15-test, include = FALSE}
trains
```

### 

### Exercise 16

Pipe `trains` to `select(att_end, treatment)` and then to `summary()`.

```{r wisdom-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-16-hint-1, eval = FALSE}
trains |>
  select(..., treatment) |>
  ...()
```

```{r wisdom-16-test, include = FALSE}
trains |>
  select(att_end, treatment) |>
  summary()
```

### 

<!-- XX: Insert comments about the data. -->


<!-- Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. -->

### Exercise 17

In your own words, define "validity" as we use the term.

```{r wisdom-17}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

### 

### Exercise 18

What can't we do if the assumption of validity is not true?

```{r wisdom-18}
question_text(NULL,
	message = "We can't combine the Preceptor Table and the data in order to construct the Population Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We can either give up on the analysis — and this is often the correct decision! — or we can adjust the meaning of the columns in the Preceptor Table so that they are “close enough” to the data that validity holds. You won’t be surprised to see that we choose the option behind Door #2!

### Exercise 19

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-19}
question_text(NULL,
	message = "Consider the outcome measure in our data, which involves one's attitude toward immigration. The phrases used in the 2012 survey do not mean the same thing today as they meant then, as the aspects of immigration policy which we are most interested in have changed. ",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In a conflict between the data and the Preceptor Table, the latter must adjust because we can’t (easily) change the data.


### Exercise 20

<!-- DK: In creating your own answer to questions like this, check with the chapter. One might already be provided! If not, it is often useful to revisit the relevant section of the Key Concepts chapter in the Primer. -->

<!-- Example: *Using data from a 2012 survey of Boston-area commuters, we seek to understand the relationship between income and political ideology in Chicago and similar cities in 2020. In particular, what percentage of individuals who make more than $100,000 per year are liberal?* -->

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer. 


```{r wisdom-20}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

## Justice
### 

<!-- DK: Choose one, as with each section introduction. -->

*Justice is truth in action.* - Benjamin Disraeli

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table can only be constructed if the *validity* assumption is (mostly) true. Besides incorporating the rows from the Preceptor table and the dataset, it usually has other rows as well, rows which represent unit/time combinations from other parts of the population. 


### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table. 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "In this case, the US politics has changed so much since 2012, especially in regard to immigration. Immigration is much more salient now then it was then, so it is likely that the effect of the treatment might be very different today.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

However, if we don’t assume stability then we can’t use data from 2012 to inform our inferences about 2024. So, we assume it.

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case. 

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Our Preceptor Table is not a random draw from the underlying population today as we only care about Chicago (and not any other city).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A similar set of issues apply to our data as it is not a random draw from the underlying population in 2012. Instead, we only have data from Boston, and not any other city. 

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. A model is *confounded* if this is not true.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The easiest way to ensure unconfoundedness is to assign treatment randomly. 

### Exercise 8

<!-- DK: Delete this question for non-causal models. -->

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-8}
question_text(NULL,
	message = "In this case, the assumption of unconfoundedness might not be true since the participants in the treatment and control group are not randomly selected, which may result in one group that has more males than females.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Since treatment was assigned at random, we can be fairly confident that treatment assignment is idependent of everything. This is the beauty of randomization and the key reason why randomized control trials are the gold standard in statistics for drawing conclusions about causal effects.

### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention at least one specific problem which casts doubt on your approach. 


```{r justice-9}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

## Courage
### 

*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill


### Exercise 1

<!-- DK: Not sure I like this answer. -->

In your own words, name the key goal of Courage and the process we use to get there.

```{r courage-1}
question_text(NULL,
	message = "Courage selects the data generating mechanism. We first specify the mathematical formula which connects the outcome variable we are interested in with the other data that we have. We explore different models. We need to decide which variables to include and to estimate the values of unknown parameters. We check our models for consistency with the data we have. We avoid hypothesis tests. We select one model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage creates a mathematical model which connects the outcome variable to the covariates, if any. Then, using code, we create a fitted model, including posterior probability distributions for all the unknown parameters.

### Exercise 2

As the outcome is a continuous variable, we use the **brms** package to build Bayesian models (“brms” stands for Bayesian regression models.)

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

In this problem, the `treatment` is a factor variable with two levels: "Treatment" and "Control." The `brm()` function will automatically transform `treatment` into a 0/1 variable named `treatmentControl` which will take on the value 1 if person $i$ received control and 0 if they received treatment.

### Exercise 3

The **tidybayes** package makes working with the fitted models easier. 

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

### Exercise 4

Type **?tidybayes** in the Console and copy paste the description. CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX: Some comments about this problem. -->

### Exercise 5

Type `trains` and hit "Run Code." This will generate the data set about US commuters toward immigration, which will be used to construct the model.

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
trains
```

```{r courage-5-test, include = FALSE}
trains
```

### 

The `treatment` can either be “Treated” or “Control” which are the two factors that may influence `att_end`. Participants were asked three questions about immigration issues, each of which allowed for an answer indicating strength of agreement on a scale form 1 to 5, with higher values for `att_end` indicating more agreement with conservative viewpoints.

### 

### Exercise 6

Create a model using `brm()` from the **brms**. Use the argument `formula = att_end ~ treatment`, `data = trains`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 9`.

Assign the result to an object called `fit_gauss`.


```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_gauss <- brm(formula = ...,
                ... = trains,
                family = gaussian(),
                ... = 0,
                silent = ...,
                ... = 9)
```

This will take a little whole to run. It won't produce anything because of the `refresh` and `silent` arguments. 

### 

### Exercise 7

Type `fit_gauss` and hit "Run Code." This generates the same results as using `print(fit_gauss)`.


```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
print(...)
```

```{r courage-7-test, include = FALSE}
print(fit_gauss)
```

### 

The top 4 rows (`Family`, `Link`, `Formula`, `Data`) are the setup of the models, you want to check this to make sure you did not make a mistake in the call to `brm()`. Next, we will go deeper in each of these rows.


### Exercise 8

Run `family()` on `fit_gauss`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
family(...)
```

```{r courage-8-test, include = FALSE}
family(fit_gauss)
```

### 

In this case, the "Family" is "gaussian", which is the default value for the `family` argument in `brm()`. Gaussian is another term for the normal distribution. 

### Exercise 9

Run `formula()` on `fit_gauss`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
formula(...)
```

```{r courage-9-test, include = FALSE}
formula(fit_gauss)
```

### 

In this case, the "Formula" is `att_end ~ treatment`, which is what we passed in to the formula argument when we called `brm()`. 

### Exercise 10

Run `nobs()` on `fit_gauss`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-10-test, include = FALSE}
nobs(fit_gauss)
```

### 

In this case, the "number of observation" is: `r scales::comma(nobs(fit_gauss))`. These are the people for whom we have the data.

### Exercise 11

Recall the definition of `Posterior Distribution` from [Chapter 2](https://ppbds.github.io/primer/probability.html#probability-distributions), which is a type of `Probability Distribution` that is based on our beliefs and expectations.

Run `posterior_interval()` on `fit_gauss`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-11-test, include = FALSE}
posterior_interval(fit_gauss)
```

### 

We are 95% confident that the true value of each parameter lies within its associated confidence interval. Note that we might also use the term "uncertainty interval" to describe this range.

### Exercise 12

Run `fixef()` on `fit_gauss`. The `fixef()` returns information about the **fix**ed **ef**fects in the model, meaning the estimated values for certain parameters.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-12-test, include = FALSE}
fixef(fit_gauss)
```

### 

The precise definition of "fixed effects" is beyond the scope of this tutorial. See [here](https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/) for extended discussion.


### Exercise 13

In order to check whether we have selected the right model, we can compare our model's prediction with our actual data. The bayesplot package includes the `pp_check()` function for that purpose.

Run `pp_check()` on `fit_gauss`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-13-test, include = FALSE}
pp_check(fit_gauss)
```

### 

If we run this code again we will get a (very slightly) different answer because the fitting process is **random**, but if the fake data had looked very different from the real data, we have had a problem. However, for the most part, we conclude that, although not perfect, `pp_check()` shows that the fake outcomes generated by our model are like the actual outcome data. 

### Exercise 14

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package, which helps create professional summary and analytical table. 

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-14-test, include = FALSE}
library(gtsummary)
```

### 

### Exercise 15

Pipe `trains` to `tbl_summary()`. Put `include = c(att_end, treatment)` within the argument. Assign the result to an object called `table1`. Type `table1` in a separate line print out the result. 

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
table1 <- 
  trains |> 
  ...(include = c(...,...))
```

```{r courage-15-test, include = FALSE}
table1 <- 
  trains |> 
  tbl_summary(include = c(att_end, treatment))
```

### 

This function automatically detects continuous, categorical, and dichotomous variables in your data set, calculates appropriate descriptive statistics, and also includes amount of missingness in each variable, if any. 

### Exercise 16

It is also possible to summarize the regression results using the function provided by the **gtsummary** package. 

### 

Run `tbl_regression()` on `fit_gauss`. 


```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
tbl_regression(...)
```

```{r courage-16-test, include = FALSE}
tbl_regression(fit_gauss)
```

### 

The posterior, or the coefficient of $Control$ is centered around $-1.5$ with a $95%$ Confidence Interval between $-2.5$ and $-0.5$. 

### 

### Exercise 17

You can also customize your table by adding more argument into the function and set it equal to `TRUE/FALSE`. Refer to the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package for further instruction.

Copy the previous code. Add `intercept` equal to `TRUE` in the argument. 

```{r courage-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-17-hint-1, eval = FALSE}
tbl_regression(fit_gauss, ... = TRUE)
```

```{r courage-17-test, include = FALSE}
tbl_regression(fit_gauss, intercept = TRUE)
```

### 

The key parameter in our model is the `Intercept`, which is in this case, estimates the attitude toward immigration among the Treated group in the population. The posterior of the `Intercept` is centered around `10` with a $95%$ Confidence Interval between $9.2$ and $11$.

### Exercise 18

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add at least one sentence which describes the modelling approach which you are using, specifying at least the functional form and the dependent variable. Add at least one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-18}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected. We modeled att_end, a summary measure of attitude toward immigration measured on a 3 to 15 integer scale, as a linear function of treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

## Temperance
### 

*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton

### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance guides us in the use of the data generating mechanism --- or the 'model' ---  we have created to answer the questions with which we began. We create posteriors for the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that the posteriors we create are never the “truth.” and the assumptions we made to create the model are never perfect. Yet with decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

Recall the question with which we began:

> What is the average treatment effect, of exposing people to Spanish-speakers, on their attitudes toward immigration?

We will be using the `add_epred_draws` from the `tidybayes` package to generate our prediction on the distribution of the average treatment effect. But first, type `fit_gauss` and hit "Run Code". 

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
fit_gauss 
```

```{r temperance-2-test, include = FALSE}
fit_gauss 
```

### 

We want to examine the behavior of our model with new data sets, data which was not used in model estimation. Therefore, the `add_epred_draws()` require a `newdata` argument.

### Exercise 3

Run the command `tibble()` with the argument `treatment = c("Treated", "Control")`. 

```{r temperance-3, exercise = TRUE}

```

```{r temperance-3-hint-1, eval = FALSE}
tibble(... = c(..., ...))
```

```{r temperance-3-test, include = FALSE}
tibble(treatment = c("Treated", "Control"))
```

### 

This will return a column named "Treatment" and two rows named "Treated" and "Control". We will use this new tibble to generate our model predictions.

### Exercise 4

We have created that tibble for you and store it in an object called ndata. Type `ndata` and hit "Run Code".

```{r temperance-4, exercise = TRUE}

```

```{r temperance-4-hint-1, eval = FALSE}
ndata
```

```{r temperance-4-test, include = FALSE}
ndata
```

### 

Creating the value for the `newdata` argument is tricky since we need to construct the treatment variable by hand. Even though treatment is a factor variable within `trains`, we can get away with using a simple character variable since either version would be transformed into a 0/1 variable by `add_epred_draws()`.

### Exercise 5

Pipe `fit_gauss` to `add_epred_draws()`. Set the `newdata` argument equals `ndata`.

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
... |> 
  add_epred_draws(
    ... = ndata
  )
```

```{r temperance-5-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata)
```

### 

We have 8,000 rows. The first four thousand rows are draws from the first row of `ndata`, meaning `treatment` equals "Treated". The next four thousand rows are draws for `treatment` equals "Control".

### Exercise 6

Continue the pipe with the command `select()` with `treatment`, `.draw`, and `.epred` as argument. 

```{r temperance-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-6-hint-1, eval = FALSE}
... |> 
  select(..., ..., ...)
```

```{r temperance-6-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  select(treatment, .draw, .epred)
```

### 

The key variable here is `.epred`, which gives us a draw from the posterior distribution for Immigration Attitude post experiment. The “e” in `.epred` stands for expected value. 

### Exercise 7

In the output of the pipe, the "Treated" and "Control" posteriors are stacked up on each other, which makes it difficult for us to calculate the average treatment effect. Continue the pipe with `pivot_wider()`, with the `id_cols = .draw, names_from = treatment, values_from = .epred` argument. 

```{r temperance-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-7-hint-1, eval = FALSE}
... |> 
  pivot_wider(...= .draw, names_from = ..., ... = .epred)
```

```{r temperance-7-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred)
```

### 

The resulting table has only 4,000 rows because we have put the posteriors for Treated and Control next to each other. The easiest way to calculate the causal effect is to subtract the posterior for the outcome under Control from the posterior of the outcome under Treatment.

### 

### Exercise 8

Continue the pipe with `mutate()`, and set `causal_effect = Treated - Control` as an argument.

```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}
... |>
  mutate(causal_effect = ... - ...)
```

```{r temperance-8-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control)
```

### 

Recall that we created our Data Generating Mechanism (DGM), or model, to help us "fill in" all the missing elements of the Preceptor Table. However, we will never know the **true** outcome at the end of the experiment, but a posterior for it, which can be used to make a draw. 

### Exercise 9

Continue the pipe with `select(- .draw)` to drop the `.draw` columns.

```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}
... |> 
  select(...)
```

```{r temperance-9-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  select(- .draw)
```

### 

Each row in the output table represent a draw (or a Preceptor table with complete information) from the posterior for the attitude post treatment of the **treated** and the **control** group. With 4,000 **causal_effect** for 4,000 Preceptor table, we have a posterior for this value. 

### Exercise 10

Continue the pipe with `ggplot()`, mapping `x` to `causal_effect` in the `aes()` argument. This will return a graph with nothing in it as we have not mapped the data on. 

```{r temperance-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-10-hint-1, eval = FALSE}
... |> 
  ggplot(...(x = ...))
```

```{r temperance-10-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect))
```

### 

We want to know what is the **average causal effect** of exposing people to Spanish speakers on their attitude toward immigration, our model has generated 4,000 **causal_effect** for 4,000 Preceptor table. Mapping these values on the graph helps us spot out our quantity of interest by looking at where the distribution is centered. 

### Exercise 11

Add `geom_histogram()`, setting `y` equal `after_stat(count/sum(count))` within the `aes()` argument as we want to display the probability distribution of the causal effect.

```{r temperance-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-11-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ...)) + 
    geom_histogram(...(y = ...))
```

```{r temperance-11-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))))
```

### 

Note that the shape of the distribution follows the "bell curve" shape or a normal distribution. We have this "bell curve" distribution because we set the `family()` argument in our `fit_gauss` model to be `gaussian()`, a variable, which is the **causal_effect** in this case, with a **Gausian** distribution is said to be normally distributed. 


### Exercise 12

Adjust the bin width by adding `bins = 100` to the `geom_histogram()` function.

```{r temperance-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-12-hint-1, eval = FALSE}
... |> 
  ggplot(...) + 
    geom_histogram(aes(...), bins = ...)
```

```{r temperance-12-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100)
```

### 

Each bin represent a different range of value of the **causal_effect**, the graph after we adjusted the bin width does not look as nice as before since we divide the bin into smaller intervals. However, the shape and the range of the distribution remains the same.

### Exercise 13

Change the y-axis into the percentage format. Add `scale_y_continuous()`, setting the `labels` argument to `scales::percent_format()`.

```{r temperance-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-13-hint-1, eval = FALSE}
... + 
  geom_histogram(...) + 
  scale_y_continuous(labels = ...)
```

```{r temperance-13-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format())
```

### 

Given that the distribution is normal, the mean (the average value of the total draws), the median (the middle value in the total draws), and the mode (the most frequently appeared values in the total draws) are all approximately equal. In our graph, a value of **causal_effect** around $1.5$ appears the most and in the middle of the distribution and thus is the **average_causal_effect**.

### Exercise 14

Change the theme of the graph by adding `theme_classic()`.

```{r temperance-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-14-hint-1, eval = FALSE}
... + 
  theme_classic()
```

```{r temperance-14-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic()
```

### 

The range from $0.5$ to $2.5$ is the $95%$ Confidence Interval, meaning that we are $95%$ confident that the true **average_causal_effect** lies within this range. 

### Exercise 15

Lastly, add `title`, `subtitle`, labels for `x` and `y`. Remeber that this is what your graph should look like.

```{r temperance-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-15-hint-1, eval = FALSE}
... + 
  labs(title = ...,
       subtitle = ...,
       x = ...,
       y = ...)
```

```{r temperance-15-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic() + 
  labs(title = "Posterior for Average Treatment Effect",
         subtitle = "Exposure to Spanish-speakers shifts immigration attitudes rightward",
         x = "Difference in Attitude",
         y = "Probability")
```

### 

The posterior of the average causal effect is centered around $1.5$, with a $95%$ Confidence Interval from about $0.5$ to $2.5$. 

### 

### Exercise 16

Let's see how big is the average causal effect. Pipe `train` to the `filter()` function with `treatment == "Control"` as an argument. 

```{r temperance-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-16-hint-1, eval = FALSE}
... |> 
  filter(treatment == ...)
```

```{r temperance-16-test, include = FALSE}
trains |> 
  filter(treatment == "Control")
```

### 

One way to determine the size of the causal effect of exposing people to Spanish-speaker on their attitude toward immigration is by comparing with the group that did not get exposed, the Control group. In other words, we want to see how people's attitude towards immigration would have been when there was no exposure to Spanish speakers and see how much this exposure could affect the outcome.

### Exercise 17

Continue the pipe with `summarize()`, with the argument `ave` equal to  `mean(att_end)` and `.by` equal to **party**. 

```{r temperance-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-17-hint-1, eval = FALSE}
... |> 
  summarize(ave = ..., ... = party)
```

```{r temperance-17-test, include = FALSE}
trains |> 
  filter(treatment == "Control") |> 
  summarize(ave = mean(att_end), .by = party)
```

### 

Let's separate people in the Control group by their party, the difference in attitude towards immigration between Democrats and Republicans is about 1.7, meaning that a Democrats is typically more conservative than Republicans. Meanwhile, our estimated average causal effect is 1.5, which can almost fulfill the gap between people from these two parties, making a treated Republican almost as conservative as a typical Democrats.

### Exercise 18

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI. 

```{r temperance-18}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected. We modeled attitude toward immigration, measured on a 3 to 15 integer scale, as a linear function of treatment. The average causal effect of treatment was about 1.5, with a 95% confidence interval of 0.5 to 2.5. For context, the difference in attitude between Democrats and Republicans is about 1.7. So, the causal effect of 1.5 means that we would expect a treated Democrat to become almost as conservative on immigration as a typical Republican.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Recall the three primary levels of possible knowledge in [Chapter 5](https://ppbds.github.io/primer/two-parameters.html#temperance). Our model was built up from a lot of assumptions which are certainly not true in reality, so the actual average treatment effect is always more or less than our estimate. 

### Exercise 19

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval.

```{r temperance-19}
question_text(NULL,
	message = "In our model we assumed the effect of exposing people to Spanish-speakers on their attitude toward immigration in 2012 is the same in 2024, which is certainly false, the estimates for this value might be wrong. A better estimate would be about 1.2 that represent the reduction of effect overtime, with a wider confidence interval of 0 to 3.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

“The world is always more uncertain than our models would have us believe.”

### 

Let's practice creating and publish a quarto document to answer the question we have in a professional way. Professional data scientists always do and store their work on Github, or a similar "source control" tool. If your computer blows up, you don't want to lose your work.

### Exercise 20

Create a Github repo called `project_causal_effect`. Make sure to click the "Add a README file" check box. Copy/paste the URL for its Github location.

```{r temperance-20}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look something like:

```         
https://github.com/giakhang1906/project_causal_effect.git
```

### Exercise 21

Connect the `project_causal_effect` Github repo to an R project on your computer. Name the R project `project_causal_effect` also. (Don't forget the "tab" key trick.) Keeping the names of repos/projects aligned makes organization simpler.

In the Console, run:

````
list.files()
````

CP/CR.

```{r temperance-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should include two files: `README.md` and `project_causal_effect.Rproj`.

### Exercise 22

Select `File -> New File -> Quarto Document ...`. Provide a title ("Causal Effect") and an author (you). Save the document as `causal_effect.qmd`. `Command/Ctrl + Shift + K`.

In the Console, run:

````
list.files(all.files = TRUE)
````

CP/CR.

The `all.files = TRUE` argument for `list.files()` generates all the files/directories, including the "hidden" ones whose names begin with a period, `.`. 

```{r temperance-22}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look like this:

```
[1] "."                           ".."                          ".git"                       
[4] ".gitignore"                  ".Rproj.user"                 "causal_effect.qmd"          
[7] "project_causal_effect.Rproj" "README.md"      

```

### Exercise 23

Edit the `.gitignore` by adding `*Rproj` and `*_files`.

In the Console, run:

````
tutorial.helpers::show_file(".gitignore")
````

CP/CR.

```{r temperance-23}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look like this:

``` 
> tutorial.helpers::show_file(".gitignore")
.Rproj.user
.Rhistory
.RData
.Ruserdata
*Rproj
*_files
``` 

### Exercise 24

Remove everything below the YAML header from `causal_effect.qmd` and save the file. In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

CP/CR.

```{r temperance-24}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look like this:
```
> tutorial.helpers::show_file("causal_effect.qmd")
---
title: "Causal effect"
author: "Khang"
format: html
---
```

### Exercise 25

In the YAML header from `causal_effect.qmd`, add: 

```
execute: 
  echo: false
```
Save the file and in the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

CP/CR.

```{r temperance-25}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`#| echo: false` makes it so that the code in the code chunk does not appear in the rendered HTML.Your answer should look like this:
```
> tutorial.helpers::show_file("causal_effect.qmd")
---
title: "Causal effect"
author: "Khang"
format: html
execute: 
  echo: false
---
```

### Exercise 26

Add a new code chunk, load the following libraries: 

```

# | message: false
library(tutorial.helpers)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)
library(primer.data)

```

Save the file and in the Console, run:

````
tutorial.helpers::show_file("causal_effect.qmd")
````

CP/CR.

```{r temperance-25-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 26

Add a new code chunk. In this code chunk, type `trains` to load the data set. In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

```{r temperance-26-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 27

Within that code chunk, pipe `trains` to `select(att_end, treatment)` and then to `summary()` as we did in the **Wisdom** section. Assign the result to an object called **ch6**. In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

```{r temperance-27-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 28

Create a model using `brm()` from the **brms**. Add a new code chunk copy paste your answer from question 6 in the **Courage**. Add `#| cache: true` on top of the code chunk. Remember to change the argument `data` to **ch6**. 

In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

```{r temperance-28-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 29

Recall that `add_epred_draws()` require a `newdata` argument. In a new code chunk, create a tibble command `tibble()` with the argument `treatment = c("Treated", "Control")` and assign it to an opject called `ndata` as we did in the very first part of this exercise.

In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd")
````

```{r temperance-29-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 30

Let's create a nice plot to answer our question. In a new code chunk, copy & paste your answer in Exercise 15 of this section. 

In the Console, run: 

````
tutorial.helpers::show_file("causal_effect.qmd", chunk = "Last")
````

```{r temperance-30-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 31

Finally, add our answer to the question. Feel free to copy paste your response in exercise 18. 

In the Console, run: 

```
tutorial.helpers::show_file("causal_effect.qmd", start = -1)
```

```{r temperance-31-ex}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

## Summary
### 

This tutorial covered [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
