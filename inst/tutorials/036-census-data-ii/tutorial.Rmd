---
title: Census Data II
author: Anmay Gupta and Soham Gunturu
tutorial:
  id: census-data-ii
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: Mapping data in R
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(primer.data)
library(tidycensus)
library(ggthemes)
library(knitr)
library(jsonlite)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

# This is all of the data that the Census Key is needed for. See the rscripts
# folder if you want to see the source code for these files.

rural <- read_rds("data/rural.rds")

rural_shifted <- read_rds("data/rural-shifted.rds")

county_data <- read_rds("data/county-data.rds")

pums_map <- read_rds("data/pums-map.rds")

cook_stores <- read_rds("data/stores.rds")

cook_map <- read_rds("data/stores_map.rds")
```

```{r copy-code-chunk, child = "../../child_documents/copy_button.Rmd"}
```

```{r info-section, child = "../../child_documents/info_section.Rmd"}
```

<!-- Perhaps of interest: https://milospopovic.net/how-to-make-choropleth-map-in-r/ and https://github.com/r-spatial/mapview. -->

<!-- DK: Do chapters 9 and 10. -->

## Introduction

Throughout this tutorial we will be learning how to access and analyze **microdata**. Microdata refers to individual-level data made available to researchers.

###

US Census microdata, named Public Use Microdata Series (PUMS), allow for detailed cross-tabulations not available in aggregated data.

## Accessing Census microdata

###

US Census microdata, named Public Use Microdata Series (PUMS), allow for detailed cross-tabulations not available in aggregated data. We will learn how to access PUMS in this section.

###

We will be working through [this](https://walker-data.com/census-r/introduction-to-census-microdata.html) book throughout this section. 

### Exercise 1

**American Community Survey** microdata is available using the `get_pums()` function in `tidycensus`. 

Run `get_pums()` below setting `variables` to a vector containing `"SEX"` and `"AGEP"`, and `state` to `"WY"`

```{r accessing-census-mic-1, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-1-hint, eval = FALSE}
get_pums(variables = c("...", "..."),
         state = "...")
```

###

We just got the microdata for variables representing sex and age in Wyoming. We can get national data by setting the `state` argument to `"all"`.

### Exercise 2

Copy and paste your code from above. Add the `year` argument and set it to `2019`.

```{r accessing-census-mic-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-2-hint, eval = FALSE}
get_pums(variables = c("...", "..."),
         state = "...",
         year = ...)
```

###

We have now specified a time period for our data. 

### Exercise 3

Copy and paste your code from above. Add the `survey` argument and set it to `"acs1"`.  

```{r accessing-census-mic-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-3-hint, eval = FALSE}
get_pums(variables = c("...", "..."),
         state = "...",
         year = ...,
         survey = "...")
```

###

The get_pums() function defaults to the 5-year ACS with survey = "acs5"; 1-year ACS data is available with survey = "acs1". 


### Exercise 4

Notice how the tibble came with variables we didn't request such as `PWGTP` which stands for weight, or `SERIALNO`, which is a specific household identifier. `get_pums()` gets these variables by default, keep this in mind.  

###

Copy and paste your code from above. Using the pipe operator, filter the data to where `SERIALNO` is `"2019HU0456721"`. We are only looking at one house. 


```{r accessing-census-mic-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-4-hint, eval = FALSE}
... |> 
  filter(SERIALNO == "...")
```

###

Take a look at the data. The `HHT` column being `1` shows that this is a married household. Also look at the `SEX` and `PWGTP` (weight) columns. We've just successfully inspected the data for a single household. 

### Exercise 5

So far we've just returned households, but what about housing units? What if they're vacant. 

Copy and paste your code from above without the `filter()` command. Add the argument `return_vacant` and set it to `TRUE`.

```{r accessing-census-mic-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-5-hint, eval = FALSE}
get_pums(variables = c("...", "..."),
         state = "...",
         year = ...,
         survey = "...",
         return_vacant = ...)
```

###

Vacant housing units are included in the dataset, but as they do not have person-level characteristics, all person-level variables like `AGEP` and `SEX` have values of `NA`. 

### Exercise 6

So by now we have been exposed to a couple PUMS variables such as `AGEP`, `SEX`, `PWGTP`, etc. 

Run `View()` with `pums_variables` as the argument. 

```{r accessing-census-mic-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-6-hint, eval = FALSE}
View(...)
```

###

By running this, we get a look at various different PUMS variables. You’ll use information in the `var_code` column to fetch variables. Learn more about the other columns [here](https://walker-data.com/census-r/introduction-to-census-microdata.html#variables-available-in-the-acs-pums).

### Exercise 7

We can also return additional contextual information for variables by using the `recode` argument.

Copy and paste your code from exercise 3. Add the `recode` argument and set it to `TRUE`. 

```{r accessing-census-mic-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-7-hint, eval = FALSE}
wy_pums_recoded <- get_pums(
  variables = c(..., ...),
  state = "...",
  ...elt() = "acs1",
  year = ...,
  recode = TRUE
)
```

###

Note that the dataset returns three new columns: `ST_label`, `HHT_label`, and `SEX_label` which include longer and more informative descriptions of the value labels.

### Exercise 8

Sometimes getting PUMS data takes a very long time. We can subset data. 

###

Copy and paste your code from exercise 3. Add the `variables_filter` argument and set it to a list where `SEX` is `2`. You will need to use the `list()` function.

```{r accessing-census-mic-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-8-hint, eval = FALSE}
get_pums(
  variables = c("...", "..."),
  state = "...",
  ... = "acs1",
  variables_filter = list(SEX = 2),
  year = ...
)
```

###

Look at the `SEX` column. Notice that everything is `2`.

### Exercise 9

Some geographical information is available in the PUMS samples in the form of the **Public Use Microdata Area**, or **PUMA**.

###

Run `pumas()` below setting state to `"WY"`, `cb` to `TRUE`, and `year` to `2019`.

```{r accessing-census-mic-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-9-hint, eval = FALSE}
pumas(state = "...", cb = ..., year = ...)
```

###

The `pumas()` function returns PUMAs, where you can specify what state and year you want it from. 

###

The code above just spits out a bunch of random gibberish at us. Let's make this a nice map.  

### Exercise 10

Copy and paste your code from above. Pipe this into `ggplot()`

```{r accessing-census-mic-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-10-hint, eval = FALSE}
... |> 
  ggplot()
```

###

This is the base for our map. 

### Exercise 11

Copy and paste your code from above. Add the `geom_sf()` and `theme_void()` layers. 

```{r accessing-census-mic-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-11-hint, eval = FALSE}
... |> 
  ... + 
  geom_sf() + 
  theme_void()
```

###

Your map should look like this: 

```{r}
include_graphics("images/puma.png")
```

###

These are the 5 PUMAS of Wyoming, which cover large rural areas.

### Exercise 12

Copy and paste your code from above. Simply change the `state` argument in `pumas()` to `"NY"` instead of `"WY"`.

```{r accessing-census-mic-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-12-hint, eval = FALSE}
pumas(state = "NY", cb = ..., year = ...) |> 
 ... + 
  ... + 
  ...
```

###

Notice that there are a lot more PUMAs, which are more aligned with community districts in the area because it is mostly urban. 

###

You should now know how to create simple maps of PUMAs.

### Exercise 13

PUMA information is also available in `get_pums()` under the variable code `PUMA`.

###

Copy and paste your code from exercise 3. In the `variables` column, change `"SEX"` to `"PUMA"`. Keep everything else the same. 

```{r accessing-census-mic-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-13-hint, eval = FALSE}
get_pums(
  variables = c("PUMA", "..."),
  state = "...",
  survey = "...",
  year = ...
)
```

###

You should get a tibble that starts like this: 

```{r}
include_graphics("images/pums_PUMA.png")
```

From this tibble, we can see PUMA is an attribute of PUMS data. 

### Exercise 14

Copy and paste your code from above. Add the `puma` argument and set it to `"00500"` and have variables only set to `"AGEP"`.

```{r accessing-census-mic-14, exercise = TRUE}
get_pums(
  variables = "AGEP",
  state = "...",
  survey = "...",
  year = ...,
  puma = "00500"
)
```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-14-hint, eval = FALSE}

```

###

We can utilize the `puma` argument to select a certain PUMA code. 

### Exercise 15

We can also look at PUMAs from different states at the same time by changing the `state` argument.

###

Copy and paste your code from above. Set the `state` argument to `"multiple"`. You **WILL** get an error, we will fix that in the next exercise. 

```{r accessing-census-mic-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-15-hint, eval = FALSE}
get_pums(
  variables = "...",
  state = "multiple",
  survey = "...",
  year = ...,
  puma = "..."
)
```

###

Let's fix the error. 

### Exercise 16

###

We now have to also modify the `puma` argument. Set `puma` to a vector with one element being `"WY" = "00500"`, and the other being `"UT" = "05001"`.

```{r accessing-census-mic-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r accessing-census-mic-16-hint, eval = FALSE}
get_pums(
  variables = "...",
  state = "...",
  survey = "...",
  year = ...,
  puma =c("WY" = "...", "UT" = "...") 
)
```

###

If you iterated through all the rows in this tibble, you would see PUMA codes of "05001" and "00500". We just looked at two different PUMA codes from different states, pretty neat huh?

###

You should now have a basic idea of how to get microdata(PUMS), inspect PUMS variables, and see geographic microdata(PUMA).\

## Analyzing Census microdata

<!-- SG: This section (chapter 10) uses very advanced skills that I don't think are necessary -->

###

In this section we will learn how to properly analyze and create detailed plots from microdata.

### Exercise 1

Take a look below at the data we've imported already. This is for the state of Mississippi. Pipe it to the `count()` function with argument `wt` set to `PWGTP`

```{r analyzing-census-mic-1, exercise = TRUE}
get_pums(
  variables = c("SEX", "AGEP"),
  state = "MS",
  survey = "acs5",
  year = 2020
)
```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-1-hint, eval = FALSE}
get_pums(
  variables = c("SEX", "AGEP"),
  state = "MS",
  survey = "acs5",
  year = 2020
) |> 
  count(wt = ...)
```

###

This should return **2981835**. We just utilized the `count()` function to see how many people there are in Mississippi and did a simple tabulation.

### Exercise 2

Copy and paste your code from above. Before the `wt` argument, add 2 arguments. One should be `SEX_label`, and the other should be `AGEP`. You should have 3 arguments in total. 

```{r analyzing-census-mic-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-2-hint, eval = FALSE}
... |> 
  count(SEX_label, AGEP, wt = ...)
```

###

We just tabulated data by unique values of age and sex in Mississippi. By specifying `wt = PWGTP`, we say that the `PWGTP` column is the appropriate weight for data tabulation.

### Exercise 3

We can also perform more custom tabulations. 

###

Take for example the PUMS data from earlier. Filter this data so that `AGEP` is 65 or above.

```{r analyzing-census-mic-3, exercise = TRUE}
get_pums(
  variables = c("SEX", "AGEP"),
  state = "MS",
  survey = "acs5",
  year = 2020
) 
```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-3-hint, eval = FALSE}
get_pums(
  variables = c("SEX", "AGEP"),
  state = "MS",
  survey = "acs5",
  year = 2020
) |> 
  filter(AGEP >= ...)
```

###

We just filtered the data so it only includes people who are 65 or older. Now let's tabulate it by sex. 

### Exercise 4

Continue your pipe from earlier and use the `count()` function to tabulate by `SEX`. Also make sure to set the `wt` argument to `PWGTP`. 

```{r analyzing-census-mic-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-4-hint, eval = FALSE}
... |> 
  count(SEX, wt = ...)
```

###

Your code should produce this: 

```{r}
include_graphics("images/tabulate1.png")
```

###

You should now feel comfortable doing simple tabulations with your microdata using `count()`.

###

If you want to learn more about tabulation in a real-life application, visit [here](https://walker-data.com/census-r/analyzing-census-microdata.html#group-wise-data-tabulation). This could be your final project!

### Exercise 5

Now let's map our microdata.

###

Take a look at the variable we've defined. Below that, use `plot()` with the extracted `geometry` column to map it.

```{r analyzing-census-mic-5, exercise = TRUE}
ms_pumas <- pumas("MS", year = 2020)
```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-5-hint, eval = FALSE}
ms_pumas <- pumas("MS", year = 2020)
plot(...$geometry)
```

###

It should produce this: 

```{r}
include_graphics("images/pums_plt.png")
```

Learn about more advanced mapping [here](https://walker-data.com/census-r/analyzing-census-microdata.html#mapping-pums-data).

### Exercise 6

The ACS is a **sample**, meaning it has a margin of error for the real population. The Census Bureau recommends using the *Successive Difference Replication* method to compute standard errors around derived estimates from PUMS data. To calculate standard errors, the Census Bureau publishes 80 *replicate weights* for each observation. 

###

To calculate this margin of error we need to download 80 replicate weights and prepare a hefty math equation - not fun.

###

Run `get_pums()` below with `variables` set to `c("PUMA", "GRPIP", "RAC1P", "HISP", "HHT", "TEN")`, `state` = `"MS"`, and `year` to `2020`. 

```{r analyzing-census-mic-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-6-hint, eval = FALSE}
get_pums(variables = c(...),
         state = "...",
         year = ...)
```

###

Let's build upon this. 

### Exercise 7

Copy and paste your code from above. Add the argument `rep_weights` and set it to `"housing"`. Add `variables_filter = list(SPORDER = 1)` as an argument so this doesn't take forever; although, it will take a little time. 

```{r analyzing-census-mic-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-7-hint, eval = FALSE}
get_pums(
  variables = c(...), 
  state = "...",
  year = ...names(),
  variables_filter = list(
    SPORDER = 1
  ),
  rep_weights = "..."
)
```

###

Don't worry about this output. We have one final step. 

### Exercise 8

Copy and paste your code from above. Pipe it to the `names()` function. 

```{r analyzing-census-mic-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r analyzing-census-mic-8-hint, eval = FALSE}
... |> 
  names()
```

###

You should get this: 

```{r}
include_graphics("images/dupl.png")
```

All 80 household replicates are in the dataset.

To see more complex uses of these replicates and how they play into surveys click [here](https://walker-data.com/census-r/analyzing-census-microdata.html#creating-a-survey-object). 

###

From this section you should just have a basic idea of some of the things in microdata you can play around with.

## Setup project
### 

In this tutorial, we're going to be creating maps based off of US Census Bureau data, then publishing them to a GitHub Pages website. 

We'll be utilizing commands from the "Downloading Census Data" tutorial in order to do this, so please complete that tutorial first.

### Exercise 1

Let's start a new R project so that we can create and eventually publish our maps.

### 

Create a new GitHub repo titled `mapping-in-r` and link it to an RStudio project like you've done so far. Remember to update the `.gitignore` file so that it ignores the `.Rproj` file.

### 

Run `list.files()` in the Console to list all of the files. Copy and paste the output into the space below.

```{r setup-project-1}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    rows = 2)
```

### 

We'll be working in this project for the rest of this tutorial.

### Exercise 2

Create a new R Markdown file titled `index.Rmd` and delete all of the text except for the setup chunk and the YAML header.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r setup-project-2}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    rows = 2)
```

### 

This should include the R Markdown file you created.

### Exercise 3

In this tutorial, we'll be using the **tidyverse**, **tidycensus**, **ggthemes**, and **tigris** packages. Load these packages in the setup chunk of your R Markdown file.

### 

Run `readLines("index.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r setup-project-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You may have to install some of these packages if you don't already have them loaded onto your computer.

### Exercise 4

Now add some information about what you plan to do in this tutorial. Feel free to include information about the tutorial, your name, and how we're using Census Bureau data.

### 

Run `readLines("index.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r setup-project-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This will act as the "home page" of the website that we'll be publishing our graphs to.

## Mapping basics
### 

<!-- Going to move this section when I create a cloropleth map using this information: https://milospopovic.net/how-to-make-choropleth-map-in-r/ as that's when we're actually dealing with shape files and things like that. Keeping it here for now while I work on that. -->

Mapping in R works by using **shapefiles** that are basically just a bunch of geometries. Think of it like drawing a map of the US states, then adding on a topographic map so that we can see how each state has different physical features. It's like that, but instead of a topographic map we're going to be using data.

We'll be using **raster data** to draw our map, which is just a grid. It's like a graph, with the longitude acting as the x axis and the latitude acting as the y axis. By drawing every point in every line on the graph, we can create a perfectly good map with a high level of detail. You can learn more about raster data and mapping [in the Primer](https://ppbds.github.io/primer/maps.html#vector-versus-spatial-data).

### 

Let's try to recreate the following map:

```{r message = FALSE, results = 'hide'}
# This is included in the tutorial rather than the setup chunk because the
# students aren't supposed to be able to access it.

basics_map <- rural |>
                filter(! NAME %in% c("Alaska", "Hawaii", "Puerto Rico")) |>
                ggplot(aes(fill = 100 * P002005 / P001001)) +
                  geom_sf() + 
                  scale_fill_viridis_c(option = "plasma",
                                       direction = -1) +
                  labs(title = "Rural geography of the United States",
                       caption = "Source: Census 2010",
                       fill = "Percent Rural") +
                  theme_void()
basics_map
```

### Exercise 1

First, we need to create a new R Markdown file to actually hold our map.

### 

Create a new R Markdown file titled `rural.Rmd` and delete all of the text except for the setup chunk and the YAML header. Then, load the libraries into the setup chunk like we did in exercise 3 of the previous section.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r mapping-basics-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Feel free to add some text about the map that we're producing and what's included inside it into your R Markdown file.  
Keep in mind that the published tutorial *will* be included in your professional portfolio, so you should try to make it as clean as possible.

### Exercise 2

While R can handle a large amount of file formats for spatial data, we'll be focusing on shape files. While we refer to them as a "shapefile", they're actually composed of 3 basic files: `.shp` files for the shape and vertices, `.shx` files for indexes and offsets, and `.dbf` files to connect the geometry and the data. Luckily, this is already dealt with by **tidycensus** when it imports the Census shapefile.

### 

In order to start mapping in R, we need to get a little more data from the **tidycensus** package. In particular, we need to set geometry = TRUE.

### 

<!-- Walk them through finding the variables again. I will, but that's a final cleanup thing and not necessary as of right now. -->

Add a new code chunk into your R Markdown file and add the `get_decennial()` function into it. Set the argument `geography` to `"state"`, `variables` to `"P001001"` and `"P002005"`, `year` to `2010`, `output` to `"wide"`, and `geometry` to `TRUE`.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-2}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    rows = 2)
```

### 

The `get_decennial()` command pulls data from the US Census Bureau's Decennial Census by using **variables**. These variables refer to information in the Census Bureau. In this case, P001001 refers to the total population in a state while P002005 refers to the percentage of that population that lives in rural areas.

### Exercise 3

If you run the code described in Exercise 1, you can see how there are a series of 5 columns: `GEOID`, `NAME`, `P001001`, `P002005`, and `geometry`.

This is different from the tibbles that we created before because there is now a strange "multipolygon" column called `geometry` and it's actually no longer a tibble. The "multipolygon" column contains the information needed to create maps and such, but this data prevents it from being a tibble.

In fact, if you run `class(rural)`, we can see that it's an `sf`, a special type of tibble that has plotting information. **Never use `as_tibble()` on an `sf` object unless you want to lose all of the plotting information.**

### 

Let's create a map based on this `rural` data. This is similar to what we did before with `ggplot()`, but this time we use the function `geom_sf()`. Create a pipe using `rural` that contains `ggplot()` and `geom_sf()` like the previous plots.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- Should I include examples for methods like this where we're trying to walk through what changes when we change the different arguments? For example, should I show a map for each step of this tutorial or just leave it blank? -->

You may notice that the plot is very stretched out with Alaska, Hawaii, and Puerto Rico causing the map to be zoomed out. Let's try to fix that.

### Exercise 4

Let's first try taking the nuclear option: removing Alaska, Hawaii, and Puerto Rico. By focusing on the continental US, we can zoom in on the states and focus on the areas that we actually have data for.

### 

Create a new map with the same code as last time, but this time add a `filter()` layer before the `ggplot()`. Within the filter, you should check if `"Alaska"`, `"Hawaii"`, `"Puerto Rico"` are in NAME and then filter them out.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You should now only see the continental United States, but there's still no data actually contained in the map.

### Exercise 5

Let's add the ratio of the different populations into the map.

### 

Within the `ggplot()`, map the `fill` argument to the ratio of `P002005` and `P001001`. 

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When you run this code, you should see how the different states have different shadings, with more urban states having a darker color.

### Exercise 6

This graph is passable, but it has a few problems:  
- The fill colors are hard to distinguish  
- The darker colors map to a lower amount, which doesn't make sense  
- The background is grey  
- The legend and labels still don't exist.  

### 

Let's address these problems one at a time, starting with differentiating between the fill colors.

### 

We can do this by changing the ratios into percents, creating a wider difference between the two ends of the scale (1 - 100 is a bigger range than 0.01 - 1).  

Multiply the previous ratio by 100 in order to make this change.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This makes the colors a lot easier to distinguish, but they're still flipped.

### Exercise 7

We can kill 2 birds with 1 stone by using the `scale_fill_viridis_c()` function to change the fill color scheme and invert the colors.

### 

Add `scale_fill_viridis_c()` to the plot, setting `option` to "plasma" and `direction` to -1.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The `scale_fill_viridis_c()` function is extremely versatile for when you want to provide map fill colors because it can create new color palettes and color schemes. You can also reverse the default order of the colors with the direction = -1 option. 

This function is for continuous variables such as prop_rural; if you have a discrete variable, you can use the analogous scale_fill_viridis_d().

### Exercise 8

It's time to finalize this map and add the labels.

Remember that we're trying to recreate this map:

```{r}
basics_map
```

### 

Set the labels as seen in the graph above and set the theme to `theme_void()`.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

That finishes the first part of the map, but there are some pretty important states that we forgot.

### Exercise 9

Let's add Alaska and Hawaii back into the map.

### 

Start a new R code chunk and copy all of the previous code into it. Continue the pipe where we defined `rural` and add the function `shift_geometry()`.

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This shifts Alaska, Hawaii, and Puerto Rico's locations to the corner of the map, allowing you to display the entire country with all 50 states.

### Exercise 10

Finally, change the map to use `rural_shifted` instead of `rural` and remove the `filter()` command we used to remove the states earlier. The final map should look like this:

```{r message = FALSE, results = 'hide'}
rural_shifted |>
  ggplot(aes(fill = 100 * P002005 / P001001)) +
    geom_sf() + 
    scale_fill_viridis_c(option = "plasma",
                         direction = -1) +
    labs(title = "Rural geography of the United States",
         caption = "Source: Census 2010",
         fill = "Percent Rural") +
    theme_void()
```

### 

Run `readLines("rural.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r mapping-basics-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The **tigris** library is a key part in map making because it allows you to modify locations and such to fit on shape files that you can then map.

### Exercise 11

Now that we finished creating this map, let's update our GitHub repository with the new file.

### 

Commit and push the `basics.Rmd` file into your GitHub repository using the "Git" window in the top right of RStudio.

### 

Run `gert::git_ahead_behind()$ahead` in the Console. Copy and paste the command and result below.

```{r mapping-basics-11}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should return `0`, showing that you are 0 commits ahead of your GitHub repository.

In general, you should make sure to pull before you push your changes into a repository so that you can avoid any conflicts between your version of a repo and GitHub's version.

## Faceting maps
A powerful tool in ggplot2 to use with maps is faceting because it allows us to easily compare data from different maps.

Let's try to recreate this map:

```{r message = FALSE, results = 'hide'}
county_map <- county_data |>
                mutate(Percent = 100 * (estimate / summary_est)) |>
                ggplot(aes(fill = Percent, color = Percent)) +
                facet_wrap(~ variable) +
                geom_sf() +
                scale_fill_viridis_c(direction = -1) +
                scale_color_viridis_c(direction = -1) +
                labs(title = "Racial geography of Harris County, Texas",
                     caption = "Source: American Community Survey 2014-2018") +
                theme_void()

county_map
```

### Exercise 1

First, we need to create a new R Markdown file to hold our map. We'll be doing this for every section of this tutorial so that our maps are separated into different pages when we finally publish them.

### 

Create a new R Markdown file titled `county.Rmd` and delete all of the text except for the setup chunk and the YAML header. Then, load the libraries into the setup chunk like we did in exercise 3 of the previous section.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r faceting-maps-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Feel free to add some text about the map that we're producing and what's included inside it into your R Markdown file.

### Exercise 2

This map is based off of the American Community Survey from 2014-2018, so we should use Census data from the ACS5 survey.

The first step is to look at the Census variables so that we know what variables we need to pull our data from.

### 

Create a new code chunk and run `load_variables(2018, "acs5") |> filter(concept == "RACE")` in order to load most of the variables relating to race. Save the name of the variables relating to whites, African Americans, and Asians in a vector called `racevars`.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

While you can't see this under the RACE category, the variable name for Hispanic populations is stored under `B03003_003`. You should also add this to your `racevars` vector.

### Exercise 3

Let's access the Census Data by using the `get_acs()` function.

### 

Use the `get_acs()` function in a new R code chunk, setting the `geography` arguments to `"tract"`, the `variables` argument to the vector you created in the last exercise, the `year` to `2018`, the `state` to your state's name, the `county` to your county's name, the `geometry` to TRUE, and `summary_var` to `"B02001_001"`, the total population of the county. Save this output to the `county_data` variable.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Some new features worth pointing out in this code:

- The `year` for `get_acs()` is the last year of a five year sample.  Thus, our data will be from 2014--2018.  You can choose `year`s from 2009--2018.
- Since our geography is "tract", we are further specifying the `state` and `county`. 
- We are obtaining the data in a long format, which makes faceting easier.
- We added a `summary_var`, "B02001_001", which is the total population.  As we'll see, this appears as a separate column, which is helpful to us.  (As an exercise, try going back to the code that created `rural` and see how you would do that in a long format with `summary_var`.)

### Exercise 4

Now let's create the map of the data that we just accessed.

### 

First of all, let's add a `Percent` column to the data that gets the ratio of `estimate` and `summary_est`, then multiplies it by 100 to get the percentage of the population that is part of that race.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When you run this, you should see how each Census tract has a percentage for what the population actually is.

### Exercise 5

Use the `ggplot()` and `geom_sf()` functions to create a map. Map the `fill` and `color` arguments within `ggplot()` to the `Percent` column that we created earlier.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

While this does show all of the information, it doesn't really tell us anything. It's a lot of different colored rectangles in the shape of a county.

### Exercise 6

Earlier, we loaded all of the different variables but didn't actually differentiate between them in our map. That means that everything is overlaid on top of one another, which doesn't make for a good graph. We can fix this by using the `facet_wrap()` function.

### 

Facet wrap the map created in the last exercise on the `variable` column. This will separate the different columns based on their variable.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If you wanted to differentiate by even more variables like the percentage who are American Indian, just add another variable to the `racevars` vector and run the command again. This will create a new map for each variable used.

### Exercise 7

But our graph is still blue, and that's pretty annoying for colorblind people and anyone trying to conduct specific analysis since all of the colors blend together.

### 

We can fix this by using the `scale_fill_viridis_c()` function to change the fill color to something more vibrant.

Add the layer `scale_fill_viridis_c()` and set the `direction` argument to `-1`.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason we set `direction` to `-1` is so that the areas with a higher value are recorded as darker. This makes it easier to see which parts have a higher value since they clearly stand out from the rest of the map.

### Exercise 8

But our graph still doesn't look that good. The border lines can hide data to the point where we can't even see the center of the county and what the data is like there. There's also a second legend for the border lines, which we don't want.

### 

In order to fix this problem, we can use the `scale_color_viridis_c()` function. This is similar to `scale_fill_viridis_c()` but it instead sets the border color.

Add the layer `scale_color_viridis_c()` and set the `direction` argument to `-1`.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In general, the color refers to the border color of a shape while the fill refers to the fill. This is the common standard used among most functions and packages.

### Exercise 9

Finally, let's pretty up our map.

Remember that our final map is supposed to look like this:

```{r}
county_map
```

### 

Set the labels to what's seen in the graph above and set the theme to `theme_void()`.

### 

Run `readLines("county.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r faceting-maps-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Your map should now look similar to the example, but with your home county instead of Harris County.

### Exercise 10

Now that we finished creating this map, let's update our GitHub repository with the new file.

### 

Commit and push the `county.Rmd` file into your GitHub repository using the "Git" window in the top right of RStudio.

### 

Run `gert::git_ahead_behind()$ahead` in the Console. Copy and paste the command and result below.

```{r faceting-maps-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should return `0`, showing that you are 0 commits ahead of your GitHub repository.

## Dealing with big data
Instead of a census tract map for just one city, let’s do a “big data” project involving every census track in the country, plotting the percentage of people who are two or more races.  

Let's try to recreate this map:

```{r}
include_graphics("images/races-map.png")
```

### Exercise 1

First, we need to create a new R Markdown file to hold our map.

### 

Create a new R Markdown file titled `tworaces.Rmd` and delete all of the text except for the setup chunk and the YAML header. Then, load the libraries into the setup chunk like we did in exercise 3 of the previous section.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r dealing-with-big-dat-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Feel free to add some text about the map that we're producing and what's included inside it.

### Exercise 2

Let's start our map by finding the correct variable in the American Community Survey.

### 

Run `load_variables(2018, "acs5") |> filter(concept == "RACE")` in the Console in order to load most of the variables relating to race.

### 

Type the names of the variables that refers to the total population and the variable that refers to the population that has a heritage of 2 or more races into the box below.

```{r dealing-with-big-dat-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You can determine what the variable refers to by looking at the `label` column. 

For example, the variable `B02001_008` has a label of `Estimate!!Total!!Two or more races`, which means that it's looking at the number of people who are made up of 2 or more races out of the total estimated population. 

By contrast, the variable `B02001_001` has a label of `Estimate!!Total`, showing how it represents the total estimated population.

### Exercise 3

For this map, we want to focus on the mainland US in order to simplify things. In order to do this, we can just filter the states that aren't part of it. This is similar to the nuclear option we did earlier, but this time we're manipulating the data instead of the graph.

### 

Create a new code chunk to contain the code necessary for this function.

Then, create a new variable called `continental` that contains the value `state.name[! state.name %in% c("Alaska", "Hawaii")]`.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The `state.name` variable is automatically installed in R, and it includes the name of every US state. In this case, we're filtering out Alaska and Hawaii so that they aren't included in our search. 

### Exercise 4

Now that we've filtered the data, let's try to download it from the Census onto our computers.

Make sure to do any filters **before** you download any data so that you aren't pulling too much data onto your computer and taking too much time. 

This is especially important when you're working with highly detailed data like this, where one state could have hundreds of rows.

### 

In the "Faceting Maps" section, we created a `get_acs()` command that used multiple variables to create a facet for one county. 

Create another `get_acs()` command with similar characteristics, but this time use the `continental` vector we created earlier as the `state` and the Census variable that described 2 races as the `variables` argument. Additionally, since we're looking at the entire country, remove the `county` argument. Save this to a variable named `races`.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

And here we encounter one of the main problems in dealing with big data: **it takes a massive amount of time**. Unless you're directly plugged into a cell tower, you probably took at least a couple of seconds to download all 87.3 MB of data onto your computer. 

This is why summary statistics are important. Rather than downloading all of the data for every census tract and then totaling it, it's much better to download the data for every state if that's what you need to do. In general, try to look for summary data first rather than finding very specific data about very specific cases.

### Exercise 5

Let's create a graph. If we don't change the information beforehand, we're going to run into the same problems that we did in the "Mapping Basics" section with the color and label problems. Let's implement the same fixes that we did before.

### 

Create a pipe off of `races` and create a `Percent` column that is 100 times the ratio between the `estimate` and `summary_est` columns.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Much like before, this changes the data into a percentage that lets us clearly distinguish between the different data points.

### Exercise 6

Continue the pipe and create a map using the `ggplot()` and `geom_sf()` functions. Map the `fill` argument to the `Percent` column that we created before.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Now we can clearly distinguish between the areas, but it's very hard to distinguish between the different census tracts.

### Exercise 7

Within the `geom_sf()` function, set the `size` argument to `0.003`.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

By setting size to 0.003, we can create thin outlines around our census tracts. Any larger and these outlines would make it hard to see our tracts.

### Exercise 8

Now, continue the pipe and add the `scale_fill_viridis_c()` function. Invert the colors using the `direction` argument and set the `option` to `"inferno"`.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The `inferno` option sets the color palette to have smaller percentages be lighter while higher percentages are darker. This makes it easy for anyone to understand your graph, even if they're colorblind.

### Exercise 9

Lastly, we need to clean up our map and make it understandable.

Remember that our final map is supposed to look like this:

```{r}
include_graphics("images/races-map.png")
```

### 

Set the labels to what's seen in the graph above and set the theme to `theme_void()`.

### 

Run `readLines("tworaces.Rmd") |> tail(15)` in the Console to list the last 15 lines in `index.Rmd`. Copy and paste the output into the space below.

```{r dealing-with-big-dat-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You may have noticed how applying `theme_void()` gets rid of the x and y axes. This is especially important for maps because the x and y axes represent latitude and longitude lines, which aren't very useful when you're trying to create infographics and don't need the exact coordinates of a location.

### Exercise 10

The problem is, that graph took forever to load! Waiting for 10 minutes just to load a small website with a couple of graphics is going to drive anyone insane.

### 

That's why we need to save our graph to an RDS file. Save your graph to a variable, then write that variable to an RDS file named `races_map.rds` using the function `write_rds()`.

### 

Run `list.files()` in the Console to list all of the files in your project. Copy and paste the output into the space below.

```{r dealing-with-big-dat-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This saves our map as an RDS file for future use. Keep in mind that RDS files are unique to R and can't be distributed to other people. If you want to save the graph and send it to somebody else, try saving it as an image using the `ggsave()` function.

### Exercise 11

While we did save our R object, we never actually use it in our website.

### 

Start a new code chunk that just reads the file `races_map.rds` using the `read_rds()` function. Make sure to comment out the previous code so that it doesn't run.

```{r dealing-with-big-dat-11}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

If you want to learn more about RDS files, please read Chapter 3 of the Primer.

### Exercise 12

Now that we finished creating this map, let's update our GitHub repository with the new file.

### 

Commit the `tworaces.Rmd` and the `races_map.rds` file by using the "Git" window in the top right of RStudio. **Do not push the commit to your GitHub repo yet.**

### 

Run `git status` in the Terminal. Copy and paste the command and result below.

```{r dealing-with-big-dat-12}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should show that you're ahead of 'origin/main' by 1 commit and that there's nothing remaining to commit.

### Exercise 13

Try to push the commit using `git push` in the Terminal.

Don't push the commit using the Git window because it doesn't show quite as much information.

### 

Not only does this take a while, it didn't even succeed! This is because we're using big data and our RDS file is a whopping 176.5 MB. GitHub doesn't allow you to upload files larger than 100 MB, and anything larger than 5 MB is already pushing it.

### 

But now there's a pretty big problem: We already committed a really big file, so whenever we push we're just going to keep on trying to add really big files. So now we need to reset back to the previous commit.

### 

Run `git reset --soft HEAD~1` in the Terminal. This will reset you to the commit before the HEAD commit (or the one that you are currently on), but preserve your uncommitted changes.

### 

Run `git status` in the Terminal. Copy and paste the command and result below. You should see that while your branch is up to date with GitHub, you still have the changes that you want to commit.

```{r dealing-with-big-dat-13}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

The `--soft` option keeps your uncommitted changes, so it's especially useful for our purposes since we want to redo our commit without losing our changes. If you want to move back up the Git tree, run `git reset HEAD`. These commands are extremely useful for when you want to go back a few commits but want to keep the same files.

### Exercise 14

Now that we undid our commit, let's commit the right way this time, without the massive RDS file weighing us down.

### 

In your `.gitignore` file, add the line `races_map.rds`. This will prevent the RDS file from being uploaded to GitHub, but still allow you to use it when you build your website.

Then commit and push your changes using the Git window.

### 

Run `cat .gitignore` and `git status` in the Terminal. Copy and paste both commands and their results below.

```{r dealing-with-big-dat-14}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This is the ideal solution whenever you have an extremely large file since it just doesn't upload it at all, saving you time and sanity. However, what if you *need* to upload the large file? 

In that case, you should use [Git LFS](https://git-lfs.github.com/) to upload the files. 

Keep in mind that this won't work for GitHub Pages and is primarily for when you need to share the file with your collaborators rather than creating something using the file.

## PUMS data
The Census also collects **P**ublic **U**se **M**icrodata **S**amples, or **PUMS** data. 

This contains advanced census data on individual people. While it only contains data for about 1% of the US, it's extremely deep and lets you do a lot of cool things.

Let's try to recreate the following map:

```{r}
pums_map
```

### Exercise 1

First, we need to create a new R Markdown file to hold our map.

### 

Create a new R Markdown file titled `senior.Rmd` and delete all of the text except for the setup chunk and the YAML header. Then, load the libraries into the setup chunk like we did in exercise 3 of the previous section.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r pums-data-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Feel free to add some text about the map that we're producing and what's included inside it into your R Markdown file.

### Exercise 2

Accessing PUMS data works just like accessing any Census data. However, there are a few key differences.

### 

Create a new code chunk and run the `glimpse()` function on the dataset `pums_variables`. This will show all of the variables that PUMS collects as well as the various values contained within them.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

As you can see, there's a lot of information here ranging from where the person lives to whether they have a fridge or not. We're not going to be using all of it, but we can filter it by the variable code.

One problem with using PUMS is that you only get the state and PUMA (**p**ublic **u**se **m**icrodata **a**rea) of each individual in the row. PUMAs are Census geographies that are entirely within a single state and are completely independent of other areas, so they don't line up with other boundaries. For example, New York City has PUMAs in its community districts but other places have it in their census tracts. As such, you can't use PUMS data for other small areas.

### Exercise 3

Mapping PUMS data is very different from normal mapping because we need to first map the PUMAS then attach our PUMS data to that map. This is because we can't get the shape files and `geometry` column for PUMAS like we did for the previous examples and as such have to get them from the **tigris** package.

### 

First, let's define what states we need to use. 

### 

Create a new vector containing `"OR"`, `"WA"`, and `"ID"` that's named `nw_states`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

These are the northwestern states shown in the map (Oregon, Washington, and Idaho). While we're using their acronyms here, you can also use their full names for the steps below.

### Exercise 4

Let's use the `get_pums()` function to choose a few select variables such as the age and PUMA that the individual lives in.

### 

In this case, we'll be using the `AGEP` and `PUMA` variables.

### 

If you want to see all of the variables that PUMS collects and what they represent, just run `view(pums_variables)` in the Console to open a table. Keep in mind that this table is *massive*, with over 31,759 variables collected.

### 

We can do this by using the `get_pums()` function. 

Add the `get_pums()` function to the code chunk and set the `variables` argument to the ones described above, `state` to `nw_states`, `recode` to `TRUE`, `survey` to `"acs1"`, and `year` to `2018`. Save the output to a variable called `nw_pums`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

One interesting aspect of `get_pums()` is that it will always contain the `SERIALNO`, `SPORDER`, `WGTP`, `PWGTP`, and `ST` columns. `SERIALNO` and `SPORDER` are the variables that uniquely identify observations, `WGTP` and `PWGTP` are the housing and person weights, and `ST` is the state code. 

### Exercise 5

This is good data, but it's really dirty and it doesn't have the information that we need. It's time to wrangle it into place.

### 

Use the `group_by()` and `summarize()` functions to make a modified version of `nw_pums` called `nw_Senior`.

Group the data by `ST` and `PUMA`, then summarize it to add a `total_pop` column containing the sum of all `PWGTP` and a `pct_Senior` column containing the ratio of the sum of all `PWGTP` with an `AGEP` over 64 and `total_pop`. Make sure to drop the groups after the `summarize()`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The `PWGTP` column is the number of people contained within that sample, so if you total all of the `PWGTP` column then you can get the total population within the study. This is why we can use it to not only find the total population but also the percent of the population that are over 64.

### Exercise 6

Now let's create the geometries for our PUMAs since we weren't able to load them from the `get_pums()` function.

### 

Add `nw_pumas <- map(nw_states, tigris::pumas, class="sf", cb=TRUE) |> reduce(rbind)` to your code chunk. This will create the necessary geometries and shape files for each PUMA in the state, allowing us to map them later.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Keep in mind that the `map()` function **does not generate a map**. It just applies a function to every element inside a list. In this case, the function is `tigris::pumas()`, which creates the shape files of the PUMAs contained within an inputted state.

### Exercise 7

It's time to combine our shape files with our data. We can do this by using `left_join()`.

### 

Join the `nw_pumas` and `nw_Senior` datasets together using the `left_join()` function, mapping `"STATEFP10"` to `"ST"` and `"PUMACE10"` to `"PUMA"`. Save this output to a variable called `nw_final`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Now we have a completed dataset containing both the mapping information and the data that needs to be mapped, allowing us to map the data like we did in the previous sections.

### Exercise 8

Start a pipe with `nw_final` and map it using the `ggplot()` and `geom_sf()` functions. Map the `fill` argument to `pct_Senior` in `ggplot()`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

One interesting thing about PUMAs is that each PUMA covers 100,000 people, which is why areas like Seattle (in western Washington) have a lot of PUMAs while Idaho and Oregon have extremely large PUMAs, as you can see on the map you just created.

### Exercise 9

We now need to adequately color our data so that it's not all blue.

### 

This time, we need to use the `scale_fill_viridis_b()` function in order to "bin" our data.

Add this function as a layer, setting the `name` argument to `NULL`, `option` to `"magma"`, and `labels` to `scales::label_percent(1)`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We're using `scale_fill_viridis_b()` here in order to bin the data, or group it together so that there are set groups rather than a continuous legend. This makes it easier to see the large differences between groups rather than focusing on the percentage points.

### Exercise 10

Finally, we need to clean up our map and add our captions.

Remember that our final map is supposed to look like this:

```{r}
pums_map
```

### 

Set the labels to what's seen in the graph above and set the theme to `theme_void()`.

### 

Run `readLines("senior.Rmd") |> tail(15)` in the Console to list the last 15 lines in `senior.Rmd`. Copy and paste the output into the space below.

```{r pums-data-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 11

Now that we finished creating this map, let's update our GitHub repository with the new file.

### 

Commit and push the `senior.Rmd` file into your GitHub repository using the "Git" window in the top right of RStudio.

### 

Run `gert::git_ahead_behind()$ahead` in the Console. Copy and paste the command and result below.

```{r pums-data-11}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should return `0`, showing that you are 0 commits ahead of your GitHub repository.

## Mapping points
<!-- This is the section for mapping latitude and longitude -->

<!-- Address to lat long converter found here: https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/census-geocoder.html may be a good idea to download a bunch of addresses and then map them. Library found here: https://cran.r-project.org/web/packages/tidygeocoder/tidygeocoder.pdf -->

<!-- The plan is map McDonald locations vs avg income by county and see how they differ. Or something similar to show how there are a bunch of food deserts based on income, forcing people to eat unhealthy foods. It's an interesting concept that I feel suits a final project.-->

<!-- Teach about addresses in the notes. -->

But a lot of the time, we don't have convenient shape files or nice data points from the Census.  

Sometimes, we just have a bunch of addresses or longitude and latitude points that don't look very nice on a map.

Let's create a map of food deserts using those points.

```{r echo = FALSE}
cook_clean_map <- cook_map |>
                    mutate(Percent = 100 * (estimate / summary_est))

cook_stores_map <- ggplot(data = cook_clean_map,
                          aes(fill = Percent, color = Percent)) +
                     geom_sf() +
                     scale_fill_viridis_c(direction = -1) +
                     scale_color_viridis_c(direction = -1) +
                     geom_point(data = cook_stores,
                                aes(x = Longitude, y = Latitude),
                                size = 0.5,
                                inherit.aes = FALSE) +
                     labs(title = "Grocery Stores and Income in Cook County",
                          subtitle = "Cook County has a small food desert in the south.",
                          caption = "Source: SNAP Retailer Locator, U.S. Department of Agriculture Food and Nutrition Service") +
                     theme_void()
cook_stores_map
```

### Exercise 1

First, we need to get our data! We'll do this by using another API: The [Food and Nutrition Service's Snap Retailer Locator](https://www.fns.usda.gov/snap/retailer-locator).

### 

Visit [https://usda-fns.hub.arcgis.com/datasets/USDA-FNS::snap-store-locations/api]() to create your API request. 

Fill out the request form, filtering it so that you only receive data about the store name, state, county, longitude, and latitude.

Then, filter out the state and county so that you only request data about your own state and county. Make sure to use acronyms like "IL" and "COOK" rather than the full name. Also, remember to press "Enter" to apply the filter. Otherwise, you may pull out data about the entire country rather than your county.

```{r out.width = "875px"}
include_graphics("images/grocery_api.gif")
```

### 

Copy and paste the URL in the top right corner of the webpage into the space below. This is the URL that we'll be pulling our data from.

```{r mapping-points-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You may have noticed that there's also an address field on the API. While we don't *need* to get the address of the store since we have the coordinates, you may need to convert between addresses and coordinates in future projects.

You can do this by either using the [Census' API](https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/census-geocoder.html) or by using the [tidygeocoder package](https://cran.r-project.org/web/packages/tidygeocoder/tidygeocoder.pdf). 

Keep in mind that this will slow down your data collection process, so it's best to find coordinate data before looking for addresses.

### Exercise 2

Now we need to create a new R Markdown file to hold our map and its related information.

### 

Create a new R Markdown file titled `deserts.Rmd` and delete all of the text except for the setup chunk and the YAML header. Then, load the **tidyverse**, **tidycensus**, **jsonlite**, and **ggthemes** libraries into the setup chunk using the `library()` command.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r mapping-points-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

It's a good idea to add some plain text information about your map and what you're plotting.

In this case, since we're trying to find food deserts in your county, you can write about how poorer areas often don't have access to grocery stores, forcing the people living there to walk for miles just so that they can feed themselves.

### Exercise 3

Now, the URL we got earlier ends in `.json`, signifying that it'll give us a JSON file. We need to parse that file into an R object so that we can actually use it.

### 

Create a new code chunk in `deserts.Rmd`, then save your URL to the variable `json_url`. 

After that, add the line `fromJSON(json_url)` to your code chunk.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Most of the time when you try to pull data from the Internet, it'll come in the form of a JSON file. It's important to understand what file you're pulling into your R session and what format it is so that you can deal with it easily.

### Exercise 4

We also need to save our data so that we aren't constantly pulling it from the Internet.

### 

Save the result of the previous exercise to the variable `county_stores`.

Then add the line `county_stores <- county_stores$features$attributes` directly after that line.

### 

Run `glimpse(county_stores)`, then copy-paste both the command and the output into the space below.

```{r mapping-points-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When we pulled our data in from the JSON file, we actually got a bunch of tables containing information about the main data set like IDs and variable names. However, since we only care about the attributes (the longitude, latitude, county, state, and store name), we need to use the `$` operator to pull out the `attributes` table from the overall data.

### Exercise 5

However, you may have noticed we didn't actually get any shape files. Instead, we got a bunch of latitude and longitude points.

### 

But in order to create our map, we need to have some shape files. We can use the **tidycensus** package to fetch our shape files, then overlay our coordinate points on top of that shape file.

### 

Add a `get_acs()` command to your code chunk, setting the `geography` to `"tract"`, `variables` to `"B06012_002"`, `year` to `2018`, `state` to `"Illinois"`, `county` to `"Cook County"`, `geometry` to `TRUE`, and `summary_var` to `"B02001_001"`. Save the output of this command to a variable named `county_map`.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This allows us to get ACS data about how many people are below the federal poverty line (the data extracted from the variable `B06012_002`) in every census tract as well as the shape files for every census tract. That means that we can create a normal map describing poverty, then add the grocery store locations to show where the food deserts are.

### Exercise 6

However, we need to take one more step before we start mapping: we need to calculate the percentage of people in poverty for each Census tract.

### 

Add a `Percent` column to `county_map` that gets the ratio of `estimate` and `summary_est`, then multiplies it by 100 to get the percentage of the population currently in poverty for that Census tract.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If we didn't convert our numbers into percentages, our data would only show which areas had the most poor people, rather than the actual poverty level itself.

### Exercise 7

Now we can start mapping.

### 

Pipe the `county_map` variable into a `ggplot()` function, mapping the fill and the color to the `Percent` column. Continue the plot and add the `geom_sf()` layer to complete your map.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is a pretty simple map of which census tracts have the most poverty. However, the colors are inverted and we still need to add our points to the map.

### Exercise 8

Continue the plot and add the lines `scale_fill_viridis_c(direction = -1)` and `scale_color_viridis_c(direction = -1)`.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This sets the darker colors to signify a higher poverty level, making it easier to understand the final map.

### Exercise 9

It's finally time to add our points. These are the locations of every SNAP-certified grocery store in your county, and mapping them will allow us to see which areas are underserved.

### 

We can do this by using the standard `geom_point()` function. Continue the plot and add the `geom_point()` layer, setting `data` to `county_stores`, `inherit.aes` to `FALSE`, and use the `aes()` function to map `x` to `Longitude` and `y` to `Latitude`.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.  

```{r mapping-points-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If you run this code, you can see how all of of the points are extremely clustered and it's hard to tell exactly where everything is. You can fix this by setting the `size` argument in `geom_point()` to `0.5`.

### Exercise 10

Finally, we need to clean up our map and add our captions.

Remember that our final map is supposed to look like this:

```{r}
cook_stores_map
```

### 

Set the labels to what's seen in the graph above (change the subtitle to something fitting your map specifically) and set the theme to `theme_void()`.

### 

Run `readLines("deserts.Rmd") |> tail(15)` in the Console to list the last 15 lines in `deserts.Rmd`. Copy and paste the output into the space below.

```{r mapping-points-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 11

Now that we finished creating this map, let's update our GitHub repository with the new file.

### 

Commit and push the `senior.Rmd` file into your GitHub repository using the "Git" window in the top right of RStudio.

### 

Run `gert::git_ahead_behind()$ahead` in the Console. Copy and paste the command and result below.

```{r mapping-points-11}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should return `0`, showing that you are 0 commits ahead of your GitHub repository.

## Citations
Since we're publishing these maps onto the Internet, it's crucial to properly cite your sources.

We'll be doing this using [BibTeX](http://www.bibtex.org/) citations, which make it easy to consistently cite our sources.

### Exercise 1

<!-- List of sources: -->

<!-- US Decennial Census 2010 -->

<!-- US American Community Survey 2018 -->

We can use BibTeX citations by adding a `bibliography.bib` file to our project.

### 

Run `touch bibliography.bib` in the Terminal to create the `bibliography.bib` file.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r citations-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

The `.bib` file format was initially created to interface with LaTeX files that are used to create PDFs. You can learn more about the `.bib` file format [here](https://libguides.utsa.edu/c.php?g=522165&p=3570389).

### Exercise 2

Copy and paste the below text into the `bibliography.bib` file:

```
@manual{decennial2010,
  author        = {{U.S. Census Bureau}},
  title         = "2010 Census",
  howpublished  = "U.S. Department of Commerce",
  month         = feb,
  year          = "2011",
}
```

### 

Run `readLines("bibliography.bib")` in the Console, then copy-paste the command and its results into the space below.

```{r citations-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This generates a BibTeX citation labeled "decennial2010" that has the author, title, publisher, published month, and published year. If you want to add a link to the direct source, just use the `url` field like so: `url = {your_link_here}`.

### Exercise 3

Copy and paste the below text into the `bibliography.bib` file:

```
@manual{acs2018,
  author        = {{U.S. Census Bureau}},
  title         = "2018 American Community Survey",
  howpublished  = "U.S. Department of Commerce",
  month         = feb,
  year          = "2018",
}
```

### 

Run `readLines("bibliography.bib")` in the Console, then copy-paste the command and its results into the space below.

```{r citations-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

Notice how the `author` field is contained within double curly brackets rather than within strings like the other fields. This is because BibTeX will only use the last word in the `author` field for inline citations since that's normally the last name. We can override this by containing it within double curly brackets.

### Exercise 4

And finally, we need to add cite the **tidycensus** package.

### 

RUn `citation(package = "tidycensus")` in the Console, then copy-paste the BibTeX entry into your `bibliography.bib` file. Make sure to set the name of the entry to `tidycensus`.

### 

Your final citation should look like this:

```
@Manual{tidycensus,
    title = {tidycensus: Load US Census Boundary and Attribute Data as 'tidyverse' and
'sf'-Ready Data Frames},
    author = {Kyle Walker and Matt Herman},
    year = {2021},
    note = {R package version 1.0},
    url = {https://CRAN.R-project.org/package=tidycensus},
  }
```

### 

Run `readLines("bibliography.bib")` in the Console, then copy-paste the command and its results into the space below.

```{r citations-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We can use the `citation()` function to properly cite R packages and their creators. You should do this when you use an API or download data directly from a package.

### Exercise 5

Now that we've created our BibTex citations, let's add some of our own commentary onto them.

### 

Create 2 new R Markdown files named "source1.Rmd" and "source2.Rmd".

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r citations-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

These are going to contain the information about our sources, the US Decennial Census and US American Community Survey. Make sure to title them accordingly.

### Exercise 6

In `source1.Rmd`, delete all of the text except for the setup chunk and the YAML header, then add the line `bibliography: bibliography.bib` to the bottom of the header.

### 

Two lines below the setup chunk in `source1.Rmd`, add the following plain text: 

```
Source 1 was the US Decennial Census Survey in 2010. This allowed us to generate maps about which states are the most rural. [@decennial2010]

This was accessed by using the `tidycensus` package. [@tidycensus]
```

### 

Run `readLines("source1.Rmd")` in the Console, then copy-paste the command and its results into the space below.

```{r citations-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This will include the information about our citation of the US Decennial Census as well as some commentary about it. The `[@decennial2010]` means that we're using our BibTeX citation of the Decennial Census in the text.

### Exercise 7

In `source2.Rmd`, delete all of the text except for the setup chunk and the YAML header, then add the line `bibliography: bibliography.bib` to the bottom of the header.

### 

Two lines below the setup chunk in `source2.Rmd`, add the following plain text: 

```
Source 2 was the US American Community Survey. This allowed us to generate maps about the racial breakdown of the US. [@acs2018]"

This was accessed by using the `tidycensus` package. [@tidycensus]
```

### 

Run `readLines("source2.Rmd")` in the Console, then copy-paste the command and its results into the space below.

```{r citations-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

You may have noticed that when you knit the file, there are actually two citations: one within the text (like `(U.S Census Bureau 2018)`) and one at the bottom of the file which includes all of the information in our citation. 

This is because the `[@acs2018]` flag means that the previous sentence is based on the `acs2018` citation, so it puts a citation both by the sentence and at the bottom as a footnote.

This makes BibTeX great for essays and studies because it automatically generates both inline and full citations with the proper formatting.

## Publishing
We're going to publish this project to a GitHub Pages website so that we can show all of our maps off.

This is extremely similar to what we did with Distill, but we're not using the extra systems that Distill provides. This is so that this page is still accessible on the Internet, but it's much more lightweight and doesn't include all of the unused infrastructure.

### Exercise 1

Clean up your R Markdown files and format them as you wish.

Make sure to clearly separate the different functions and different graphs so that you know what they do later.

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r publishing-1}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should display all of the files you've created so far, including `index.Rmd`, `rural.Rmd`, `county.Rmd`, `tworaces.Rmd`, `senior.Rmd`, and `deserts`.Rmd`. These are the pages that we'll be using in our GitHub Pages website.

### Exercise 2

First, we need to tell RStudio that our project is actually a website. We can do this by configuring the project's options.

### 

Go to Tools -> Project Options -> Build Tools and change the "Project Build Tools" field from "None" to "Website". This will restart your R session and will show a "Build" tab in the top right of RStudio.

```{r out.width = "875px"}
include_graphics("images/proj_to_website.gif")
```

### 

Run `tail(readLines("mapping-in-r.Rproj"), 1)` in the Console. Copy and paste the command and the result below.

```{r publishing-2}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should show `"BuildType: Website"` to signify that your R project is a website. If it doesn't show that, you didn't set your project build tools correctly.

This is also how you can turn your R project into a package, but it's recommended to make your project a package when you create the project as this method requires you to create all of the necessary files from scratch.

### Exercise 3

Navigate to the "Build" tab in the top right corner and press "Build Website" or run `rmarkdown::render_site()` in the Console. This should return an error because there's no site generator found.

### 

Basically, we made it so that our project is a website, but we never defined what files we want to show or how we want our website to be structured. We can do this by create a `_site.yml` file.

### 

Create a new text file using File -> New File -> New Text File, then save it as `_site.yml`. This will change the file's type into a `.yml` file that defines the structure of our website.

```{r out.width = "875px"}
include_graphics("images/create_yml.gif")
```

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r publishing-3}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

**Y**et **A**nother **M**arkup **L**anguage (YAML) files are a type of markup file like HTML files that determines the structure of a website, and they're the main thing that we use to structure websites on GitHub pages. These are *very* picky as to their syntax, so make sure you follow the instructions exactly.

This is the same thing that's at the top of your R Markdown files, but when you use it as a website there are a lot more functions that you can use.

### Exercise 4

Now, if you built the website at this point, you'd only seeing one file and wouldn't be able to access any other pages. This is because you haven't set up your website and are instead hosting only one page.

### 

The first step to structure your website is to name it and bring the files out into the open. Add the lines `name: mapping-in-r` and `output_dir: "."` to your `_site.yml` file. Save the `_site.yml` file.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-4}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This names the website and brings the output files into your current directory, allowing you to publish your website to GitHub pages.

### Exercise 5

But we still have a problem. We can't navigate between the different pages of our website. We can do this by using a navigation bar.

### 

Add the line `navbar:` to your file, then add `title: Mapping Demonstration` below it. Make sure to indent the `title:` line once so that it's contained within the `navbar:` block.

```
navbar:
  title: "Mapping Demonstration"
```

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-5}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This adds a navigation bar to the top of the website, creating the basics for navigating through it. However, we still need to add our other pages.

### Exercise 6

Add the lines `left:`, `- text: "Home"`, and `href: index.html`, indenting the last two lines so that they're contained under the `left:` command.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-6}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

So far, your `_site.yml` file should look like this:

```
name: mapping-in-r
output_dir: "."
navbar:
  title: "Mapping Demonstration"
  left:
    - text: "Home"
      href: index.html
```

This adds a new item on the left of the navigation bar that contains the text `"Home"` and a link to the `index.html` file. The `index.html` file is created by the `index.Rmd` file that we created in the Setup Project section of this tutorial.

### Exercise 7

Let's add our other pages to the navigation bar.

### 

Repeat adding the `- text:` and `href` lines, this time substituting the names of the files that we created in the previous sections like `county.html`, `tworaces.html`, and `senior.html`. Try to make sure that all of the lines have the same format, with all of the `- text:` commands lining up and all of the `href` commands lining up as well.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-7}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This adds all of our pages to the navigation bar, allowing us to click between them with ease.

### Exercise 8

But we still have to add our sources to the website. Let's create a dropdown menu named "Sources" that contains the pages we created.

### 

Add the line `- text: Sources` to the `_site.yml` file, indenting it so that it's in line with the other `- text` lines.

### 

Underneath that, add the code `menu:`, indenting it so that it's line with the other `href` lines.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-8}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This creates a dropdown menu in your website titled `Sources`. This will contain our `source1.Rmd` and `source2.Rmd` files.

### Exercise 9

Let's add those pages in so that our menu isn't completely empty.

### 

Indent and add the line `- text: "Decennial Census"` to the `_site.yml` file. Then underneath that line, indent once more and add `href: source1.html`.

### 

Repeat this process with `source2.html`, making sure that the `- text:` and `href` commands line up with their `source2.html` counterparts.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-9}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

This adds our source pages under a dropdown menu labeled `Sources`, making them very easy to access.

### Exercise 10

So far, your `_site.yml` file should include the `name`, `output_dir`, `navbar`, `title`, `left`, `menu`, text`, and `href` fields, repeating the last two multiple times in order to include all of the pages created in this tutorial.

### 

Now let's make our website look a little bit better. On a new line with no indentation, add the line `output:`. Underneath that, indent and add `html_document:`. Finally, add a new line and indent then type `theme: cosmo`.

### 

Run `readLines("_site.yml")` in the Console to list the content of `_site.yml`. Copy and paste the output into the space below.

```{r publishing-10}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This isn't the limit of YAML files. Visit one of the websites below to learn more about publishing R Markdown files and using YAML files.

* https://resources.github.com/whitepapers/github-and-rstudio/  
* https://garrettgman.github.io/rmarkdown/rmarkdown_websites.html#overview  
* https://bookdown.org/yihui/rmarkdown/rmarkdown-site.html  
* https://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html#Types_of_websites

### Exercise 11

We're just about done now, but we need to add one more file.

### 

By default, GitHub pages uses [Jekyll](https://github.com/jekyll/jekyll) to create websites from scratch, but that doesn't work for when we're using R Markdown and YAML files to structure our content. We can fix this by adding the `.nojekyll` file.

### 

Create a text file using the same method as when we created our `_site.yml` file, but this time save it as `.nojekyll.

```{r out.width = "875px"}
include_graphics("images/create_nojekyll.gif")
```

### 

Run `list.files()` in the Console to list all of the files within your project. Copy and paste the output into the space below.

```{r publishing-11}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Learn more about Jekyll and using it in GitHub pages [here](https://jekyllrb.com/docs/github-pages/).

### Exercise 12

It's finally time to publish our website to GitHub pages and push it into the Internet.

### 

First, we need to update our GitHub repository so that it has the files it needs. Commit and push the `senior.Rmd` file into your GitHub repository using the "Git" window in the top right of RStudio.

### 

Run `gert::git_ahead_behind()$ahead` in the Console. Copy and paste the command and result below.

```{r publishing-12}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This should return `0`, showing that you are 0 commits ahead of your GitHub repository.

### Exercise 13

Now that our files are updated, let's create our website.

### 

Go to the GitHub page for your repository, then navigate Settings -> Pages. Change the source for your GitHub page from "None" to "master". Click "Save" to finally publish your website.

### 

Copy-paste your GitHub website URL into the space below.

```{r publishing-13}
question_text(NULL,
	message = "answer here",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Congratulations on completing the tutorial.

### 

If you want to explore further:

- Take a look at the [**tidycensus** website](https://walkerke.github.io/tidycensus/).
- If you have shapefiles from a place other than **tidycensus**, you can read them in using `st_read()` in the **sf** package, join them with other data using **dplyr** functions, and then map them with `geom_sf()` as we have shown above.
    - You may have to look into using [`coord_sf()`](https://ggplot2.tidyverse.org/reference/ggsf.html) if you have trouble displaying your data.
- Want to add interactivity to your maps?  Check out the **leaflet** package.  [Here's](https://juliasilge.com/blog/using-tidycensus/) a good introduction to using **leaflet** with **tidycensus**.
- Practice your skills with [Andrew Tran's case study slides](https://andrewbtran.github.io/NICAR/2019/mapping/02_case_study_slides.html), where you can replicate a graphic from the Washington Post. Note: this involves some packages we haven't shown you in this book, but if you follow along step by step you will be able to see how they are used.

Downloading feature geometry from the Census website. To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.

### 

```{r download-answers, child = "../../child_documents/download_answers.Rmd"}
```
