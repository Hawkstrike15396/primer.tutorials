---
title: N Parameters
author: David Kane and Mihir Kaushal
tutorial:
  id: n-parameters
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 10 Tutorial: N Parameters'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(gt)
library(brms)
library(tidybayes)
library(gtsummary)
library(primer.data)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

set.seed(9)

ch10_data <- shaming |> 
  mutate(p_00 = (primary_00 == "Yes"), 
         p_02 = (primary_02 == "Yes"),
         p_04 = (primary_04 == "Yes"), 
         g_00 = (general_00 == "Yes"),
         g_02 = (general_02 == "Yes"), 
         g_04 = (general_04 == "Yes"),
civ_engage = p_00 + p_02 + p_04 + g_00 + g_02 + g_04,
voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                        civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                        civ_engage %in% c(1, 2) ~ "Rarely Vote"),
voter_class = factor(voter_class, levels = 
                       c("Rarely Vote", "Sometimes Vote", "Always Vote")), 
age_z = as.numeric(scale(age))) |> 
  rename(voted = primary_06) |> 
  select(voted, treatment, sex, age_z, civ_engage, voter_class) |> 
  drop_na() |> 
  slice_sample(prop = 0.1)


# fit_postcard_vote <- brm(formula = voted ~ age_z + sex + 
#                            treatment + voter_class + treatment*voter_class, 
#                          data = ch10_data, 
#                          family = gaussian(), 
#                          refresh = 0, 
#                          silent = 2, 
#                          seed = 19)
# 
# write_rds(fit_postcard_vote, "data/fit_postcard_vote.rds")

fit_postcard_vote <- read_rds("data/fit_postcard_vote.rds")
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

## Introduction
### 

This tutorial covers [Chapter 10: N Parameters](https://ppbds.github.io/primer/n-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

In this tutorial, we will consider models with many parameters and the complexities that arise therefrom.

As our models grow in complexity, we need to pay extra attention to basic assumptions like validity, stability, representativeness, and unconfoundedness. It is easy to jump right in and start interpreting. It is harder, but necessary, to ensure that our models are really answering our questions.

### 

Imagine you are a Republican running for Governor in Texas. You need to allocate your campaign spending intelligently. For example, you want to do a better job of getting your voters to vote.

We will be looking at the shaming tibble from the [**primer.data**](https://ppbds.github.io/primer.data/) package, sourced from “[Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment](https://doi.org/10.1017/S000305540808009X)” by Gerber, Green, and Larimer (2008).

## The Question
### 

*A prudent question is one half of wisdom.* - Francis Bacon

### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(...)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data is from a study which aimed to find out whether and to what extent people are motivated to vote by social pressure.

### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(...)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from “[Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment](https://doi.org/10.1017/S000305540808009X)” is available in the `shaming` tibble.

### Exercise 3

Familiarize yourself with the data by loading **primer.data** at the Console and then typing `?shaming`. 

Find the year which this experiment took place and how many households were in the experiment. Write your answers below. 

```{r the-question-3}
question_text(NULL,
	message = "The experiment was conducted prior to the August 2006 primary election in Michigan. A total of 180,000 households were part of this experiment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In their published article, the authors note that “Only registered voters who voted in November 2004 were selected for our sample.” After this, the authors found their history then sent out the mailings. Thus, anyone who did not vote in the 2004 general election is excluded, by definition. Keep that fact in mind when we discuss representativeness later or.

### Exercise 4

How campaigns influence voters is the broad topic of this tutorial. Given that topic, which variable in `shaming` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "The outcome is voting or not voting. That is, we are researching the question of how to convince people to vote, not how to convince them to vote for a specific candidate. This project is about getting our voters to the polls, not about convincing their voters to switch to our side.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

The outcomes in a Preceptor Table refer to a moment in time. In this case, the outcome occurs on Election Day in 2026. The covariates and treatments must be measured before the outcome, otherwise they can’t be modeled as connected with the outcome. 

The `primary_06` is 0/1 integer variable indicating whether the respondent voted in the 2006 primary election. This is an important variable.

Notice the time difference between the data we have and the data we want to have.

### Exercise 5

Pick a variable in the data which might have a connection to the outcome variable and which we might consider to be, at least in theory, a treatment. (If you don't see a reasonable variable in the data, you can just name a variable which *might have been* included in the data.) How might we manipulate this variable?

```{r the-question-5}
question_text(NULL,
	message = "We can manipulate the value of the type of campaign the individuals are exposed to, at least in theory, by focusing on postcards that promote voting. We can randomly assign people different types of postcards, and no postcards to some, to see the effect of postcards on voting. ",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: This question and the ones that follow are tricky. We are trying to drive home some related points. First, any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. Second, any data set can be used to construct a predictive model. Third, the same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.-->

There is no one right answer. But, going forward, we will be using the type of postcard as the treatment. For the rest of this tutorial, we will be referring to this treatment variable as `treatment`.

Recall that a treatment is just another covariate. But, it is special in that we can, at least in theory, manipulate it to discover different potential outcomes for the same individual.

### Exercise 6

Write a sentence which speculates as to the different potential outcomes which we might observe in `shaming` when we change the value of the treatment variable `treatment`. 

```{r the-question-6}
question_text(NULL,
	message = "The value of `treatment` would demonstrate 2 different potential outcomes for each unit as we vary the treatment variable. Either the person votes, or does not vote.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If we had a different outcome we were measuring, then our potential outcomes would also be different. We will be sticking with the potential outcomes listed above.

The definition of a causal effect is the difference between potential outcomes. So, there must be two (or more) potential outcomes for any causal model to make sense. This treatment only has two different values, thereby generating only two potential outcomes.

<!-- DK: Not two outcomes. -->

### Exercise 7

Write a few sentences which specify two different values for the treatment variable, for a single unit, and then guesses at the potential outcomes which would result, and then calculates the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For a given person, assume that the value of the treatment variables, the types of postcard, might be 'Civic Duty' or 'No Postcard'. If the person gets 'Civic Duty', then the outcome would be 1, which would signify that the person did vote. If the person gets 'No Postcard', then the outcome would be 0, which would signify that the person did not vote. The causal effect on the outcome of a treatment of 'Civic Duty' versus 'No Postcard' is 1 - 0, which equals 1.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. We will use the default sense in which the causal effect is defined as treatment minus control.

The causal effect on whether or not a person votes after seeing a political postcard versus not seeing a postcard is 1.

### Exercise 8

Let's consider a *predictive* model. Which variable in `shaming` do you think might have an important connection to `primary_06`? (If you don't see a reasonable variable in the data, you can just name a variable which *might have been* included in the data.)

```{r the-question-8}
question_text(NULL,
	message = "Whether or not the person has voted in the previous elections.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

<!-- DK: Include stuff here, and elsewhere, about how 1/0 for voting/not-voting is arbitrary. Maybe use the hair cut example. A causal effect is the "difference" between two potential outcome. There is no requirement that there are numbers associated with those outcomes, although we might assign arbitary numbers. -->

### Exercise 9

Write a few sentences which specify two different groups of voters with different values for past civic engagement. Explain that the outcome variable might differ between these two groups.

```{r the-question-9}
question_text(NULL,
	message = "Some people might have a value for whether the respondent voted in the 2000 primary election of true. Others might have a value of false. Those two groups will, on average, have different values for the outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The key point is that, with a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be treatment variables. We assume that all covariates are "fixed." 

### Exercise 10

Write a causal question which connects the outcome variable primary_06 to a covariate of interest. 

```{r the-question-10}
question_text(NULL,
	message = "What is the causal effect of postcards on voting in the 2006 election? Do those effects vary by political engagement?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

It is OK if you did not write what is written in the answer! There are lots of interesting questions which one might write. 

For this tutorial, our question is:

  > *What is the causal effect of postcards on voting in the 2026 election? Do those effects vary by political engagement?*

### Exercise 11

What is the Quantity of Interest which might help us to explore the answer to our question?

```{r the-question-11}
question_text(NULL,
	message = "We care about 'primary_06', which is the outcome variable. The type of postcard they recieved also matters.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note the time difference between the data we have and the data we want to have. There is a 20 year gap which we will discuss more later on.

## Wisdom
### 

*All we can know is that we know nothing. And that’s the height of human wisdom.* - Leo Tolstoy

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The authors conducted a field experiment to answer their questions about the extent people are motivated to vote by social pressure. Households were randomly assigned to either a control group or one of four treatment groups.

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The more experience you get as a data scientist, the more that you will come to understand that the Four Cardinal Virtues are not a one-way path. Instead, we circle round and round. Our initial question, instead of being fixed forever, is modified as we learn more about the data, and as we experiment with different modeling approaches.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This problem is causal so one of the covariates is a treatment. In our problem, the treatment is the type of postcard that the people get. 

### Exercise 4

Create a Github repo called `n-parameters`. Make sure to click the "Add a README file" check box. 

Connect the `n-parameters` Github repo to an R project on your computer. Name the R project `n-parameters` also. 

Select `File -> New File -> Quarto Document ...`. Provide a title (`"N Parameters"`) and an author (you). Save the document as `causal_effect.qmd`. 

Edit the `.gitignore` by adding `*Rproj`. Save and commit this in the Git tab. Push the commit.

In the Console, run:

```
show_file(".gitignore")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `analysis.qmd` and render the file. `Command/Ctrl + Shift + K` renders the file, this automatically saves the file as well.

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "The units of our Preceptor Table are individual voters in Texas around the time of the next election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There is no one correct answer for these types of questions, it all depends on the question we are answering. We could have focused on all voters throughout America. For this tutorial, we will be focusing on just individual voters in Texas.

### Exercise 6

What moment in time does the Preceptor Table refer to? It might be helpful to refer to the [N Parameters chapter](https://ppbds.github.io/primer/n-parameters.html).

```{r wisdom-6}
question_text(NULL,
	message = "We care about the upcoming Texas election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There is no one correct answer, just like many other parts of the Preceptor Table. It all depends on the question we are trying to answer.

We can include the time in our question:

> *What will be the causal effect of postcards on voting in the 2026 Texas election?*

### Exercise 7

What is the fundamental problem of causal inference?

```{r wisdom-7}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If we observe that a person who got a postcard ended up voting, we can never know for sure that the postcard *caused* that person to vote because we will never know what the outcome would have been if that person didn't get a postcard.

### Exercise 8

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-8}
question_text(NULL,
	message = "If we did not have any manipulation, so we did not sent out any postcards and instead did an observational study, then we would never be able to create a caual inference. We need to have treatments so we can compare the outcome between the different groups of treatments.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We have to choose a variable that we can change to be the treatment. If we do not have such variable that we can manipulate, then we would have to create a predictive model instead. For example, if we were focused on household income, one conclusion may be: Rich people are more likely to vote than poor people. Correlation does not mean causation, we cannot assume that wealth directly causes people to have more civic engagement. In order to find a causation relationship, we would need to manipulate the treatment so that we can measure it's effect on the outcome. 

### Exercise 9

Describe in words the Preceptor Table for this problem.

```{r wisdom-9}
question_text(NULL,
	message = "The Preceptor Table has 5 columns. There is a column for the ID, two for the outcomes: Voting After Control and Voting After Treatment. There two covariates: Treatment and Engagement. Each row represents one individual.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       voting_after_treated = c("1", "1", "...", "1", "0", "...", "1"),
       voting_after_control = c("1", "0", "...", "1", "1", "...", "0"),
       treatment = c("Yes", "No", "...", "Yes", "Yes", "...", "No"),
       engagement = c("1", "3", "...", "6", "2", "...", "2")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             voting_after_treated = md("Voting After Treatment"),
             voting_after_control = md("Voting After Control"),
             treatment = md("Treatment"),
             engagement = md("Engagement")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Covariates", columns = c(treatment, engagement)) |>
  tab_spanner(label = "Outcomes", columns = c(voting_after_control, voting_after_treated))
```

### Exercise 10

In `causal_effect.qmd`, load the **tidyverse** and the **primer.data** packages in a new code chunk. Label it the set up by adding `#| label: setup`. Render the file.

Notice that the file does not look good because it is has code that is showing and it also has messages. To take care of  this, add `#| message: false` to remove all the messages in the setup chunk. Also add the following to the YAML header to remove all echo from the whole file:

```
execute: 
  echo: false
```

In the Console, run:

```
show_file("causal_effect.qmd", start = -5)
```

CP/CR.

```{r wisdom-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 11

Run `glimpse()` on `shaming`. 

```{r wisdom-11, exercise = TRUE}

```

```{r wisdom-11-hint-1, eval = FALSE}
glimpse(...)
```

```{r wisdom-11-test, include = FALSE}
glimpse(shaming)
```

### 

`glimpse()` gives us a look at the raw data contained within the `shaming` data set. At the very top of the output, we can see the number of rows and columns, or observations and variables, respectively. We see that there are 344,084 observations, with each row corresponding to a unique respondent.

### Exercise 12

Pipe `shaming` to `count()` with `treament` inside of it.

```{r wisdom-12, exercise = TRUE}

```

```{r wisdom-12-hint-1, eval = FALSE}
shaming |> count(...)
```

```{r wisdom-12-test, include = FALSE}
shaming |> count(treatment)
```

### 

Four types of treatments were used in the experiment, with voters receiving one of the four types of mailing. All of the mailing treatments carried the message, “DO YOUR CIVIC DUTY - VOTE!”.

### Exercise 13

Pipe `shaming` to the following:
         
```
mutate(p_00 = (primary_00 == "Yes"), p_02 = (primary_02 == "Yes"),
       p_04 = (primary_04 == "Yes"), g_00 = (general_00 == "Yes"),
       g_02 = (general_02 == "Yes"), g_04 = (general_04 == "Yes"),
civ_engage = p_00 + p_02 + p_04 + g_00 + g_02 + g_04,
voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                        civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                        civ_engage %in% c(1, 2) ~ "Rarely Vote"),
voter_class = factor(voter_class, levels = c("Rarely Vote", "Sometimes Vote", "Always Vote")), age_z = as.numeric(scale(age))) 
```

```{r wisdom-13, exercise = TRUE}

```

```{r wisdom-13-hint-1, eval = FALSE}
shaming |> mutate(...)
```

```{r wisdom-13-test, include = FALSE}
shaming |> mutate(p_00 = (primary_00 == "Yes"),
         p_02 = (primary_02 == "Yes"),
         p_04 = (primary_04 == "Yes"),
         g_00 = (general_00 == "Yes"),
         g_02 = (general_02 == "Yes"),
         g_04 = (general_04 == "Yes"),
         civ_engage = p_00 + p_02 + p_04 + 
                      g_00 + g_02 + g_04,
         voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                                 civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                                 civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         voter_class = factor(voter_class, levels = c("Rarely Vote", 
                                                      "Sometimes Vote", 
                                                      "Always Vote")),
         age_z = as.numeric(scale(age)))
```

### 

The code above converts the Yes/No columns to binaries with the function we made. Note that primary_06 is already binary and also that we didn't need it to construct a variable based on previous voting behavior.

### Exercise 14

Continue the pipe to `rename()` with `voted` being set to `primary_06` inside `rename()``.
         
```{r wisdom-14, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-14-hint-1, eval = FALSE}
... |> rename(...)
```

```{r wisdom-14-test, include = FALSE}
shaming |> mutate(p_00 = (primary_00 == "Yes"),
         p_02 = (primary_02 == "Yes"),
         p_04 = (primary_04 == "Yes"),
         g_00 = (general_00 == "Yes"),
         g_02 = (general_02 == "Yes"),
         g_04 = (general_04 == "Yes"),
         civ_engage = p_00 + p_02 + p_04 + 
                      g_00 + g_02 + g_04,
         voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                                 civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                                 civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         voter_class = factor(voter_class, levels = c("Rarely Vote", 
                                                      "Sometimes Vote", 
                                                      "Always Vote")),
         age_z = as.numeric(scale(age))) |> rename(voted = primary_06)
```

### 

Voted in a more natural name for our outcome variable. This will also help us in the future when we will graph this data.

### Exercise 15

Continue the pipe to `select()` and choose `voted`, `treatment`, `sex`, `age_z`, `civ_engage`, and `voter_class`. Then pipe with `drop_na()`.
         
```{r wisdom-15, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-15-hint-1, eval = FALSE}
... |> select(...) |> drop_na()
```

```{r wisdom-15-test, include = FALSE}
shaming |> mutate(p_00 = (primary_00 == "Yes"),
         p_02 = (primary_02 == "Yes"),
         p_04 = (primary_04 == "Yes"),
         g_00 = (general_00 == "Yes"),
         g_02 = (general_02 == "Yes"),
         g_04 = (general_04 == "Yes"),
         civ_engage = p_00 + p_02 + p_04 + 
                      g_00 + g_02 + g_04,
         voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                                 civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                                 civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         voter_class = factor(voter_class, levels = c("Rarely Vote", 
                                                      "Sometimes Vote", 
                                                      "Always Vote")),
         age_z = as.numeric(scale(age))) |> rename(voted = primary_06) |> select(voted, treatment, sex, age_z, civ_engage, voter_class) |> drop_na()
```

### 

The data we have right now is too much, it will take too long to use it later on in the tutorial. 

### Exercise 16

To finish, pipe `slice_sample(prop = 0.1)` at the end so we only get 10% of all the data.
         
```{r wisdom-16, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-16-hint-1, eval = FALSE}
... |> slice_sample(...)
```

```{r wisdom-16-test, include = FALSE}
shaming |> mutate(p_00 = (primary_00 == "Yes"),
         p_02 = (primary_02 == "Yes"),
         p_04 = (primary_04 == "Yes"),
         g_00 = (general_00 == "Yes"),
         g_02 = (general_02 == "Yes"),
         g_04 = (general_04 == "Yes"),
         civ_engage = p_00 + p_02 + p_04 + 
                      g_00 + g_02 + g_04,
         voter_class = case_when(civ_engage %in% c(5, 6) ~ "Always Vote",
                                 civ_engage %in% c(3, 4) ~ "Sometimes Vote",
                                 civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         voter_class = factor(voter_class, levels = c("Rarely Vote", 
                                                      "Sometimes Vote", 
                                                      "Always Vote")),
         age_z = as.numeric(scale(age))) |> rename(voted = primary_06) |> select(voted, treatment, sex, age_z, civ_engage, voter_class) |> drop_na() |> slice_sample(prop = 0.1)
```

### 

`slice_sample()` gives a new random set of the data each time it is run. If you run the previous code again, you will notice that some numbers might change. The important thing to keep in mind is that the summary numbers of the data, such as the percent of people who voted or the percent of people who got no postcard, stay roughly the same. The 10% we will use is still representative of the whole data because it is randomly selected. 

### Exercise 17

In the background of this tutorial, an object called `ch10_data` was created and given the value of the code above. Start a new pipe with `ch10_data` to `sample_frac()` with `0.5` as the parameter.
         
```{r wisdom-17, exercise = TRUE}

```

```{r wisdom-17-hint-1, eval = FALSE}
ch10_data |> sample_frac(...)
```

```{r wisdom-17-test, include = FALSE}
ch10_data |> sample_frac(0.5)
```

### 

Of course, when doing the analysis, you don’t know when you start what you will be using at the end. Data analysis is a circular process. We mess with the data. We do some modeling. We mess with the data on the basis of what we learned from the models. With this new data, we do some more modeling. And so on.

### Exercise 18

Continue the pipe to `ggpot()` with `x` set to `civ_engage` and `y` set to `voted` inside `aes()`. Also add `geom_jitter()` with `alpha` set to `0.03` and `height` set to `0.1`.
         
```{r wisdom-18, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-18-hint-1, eval = FALSE}
... |> 
  ggplot(aes(...)) +
    geom_jitter(...)
```

```{r wisdom-18-test, include = FALSE}
ch10_data |> sample_frac(0.5) |> 
  ggplot(aes(x = civ_engage, y = voted)) +
    geom_jitter(alpha = 0.03, height = 0.1)
```

### 

In this graph, we are trying to see if the past civic engagement of the individual can help predict weather or not they voted. 

### Exercise 19

Using the previous code, add `scale_x_continuous()` with `breaks` set to `1:6` and also add `scale_y_continuous()` with `breaks` set to `c(0, 1)` and `labels` set to `c("No", "Yes")`.
         
```{r wisdom-19, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-19-hint-1, eval = FALSE}
... +
    scale_x_continuous(breaks = ...) + 
    scale_y_continuous(breaks = ..., labels = ...)
```

```{r wisdom-19-test, include = FALSE}
ch10_data |> sample_frac(0.5) |> 
  ggplot(aes(x = civ_engage, y = voted)) +
    geom_jitter(alpha = 0.03, height = 0.1) +
    scale_x_continuous(breaks = 1:6) + 
    scale_y_continuous(breaks = c(0, 1), labels = c("No", "Yes"))
```

### 

Through the graph, we can see that past voting predicts future voting.

### Exercise 20

Finally, using the previous code, add the `labs()` layer.
         
```{r wisdom-20, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-20-hint-1, eval = FALSE}
... +
  labs(...)
```

```{r wisdom-20-test, include = FALSE}
ch10_data |> sample_frac(0.5) |> 
  ggplot(aes(x = civ_engage, y = voted)) +
    geom_jitter(alpha = 0.03, height = 0.1) +
    scale_x_continuous(breaks = 1:6) + 
    scale_y_continuous(breaks = c(0, 1), labels = c("No", "Yes")) +
    labs(title = "Civic Engagement and Voting Behavior in Michigan",
         subtitle = "Past voting predicts future voting.",
         x = "Civic Engagement",
         y = "Voted in 2006 Primary Election",
         caption = "Random sample of 5% of the data from Gerber, Green, and Larimer (2008)")
```

### 

The graph should look like this:

```{r}
#| echo: false

ch10_data |>
  sample_frac(0.05) |> 
  ggplot(aes(x = civ_engage, y = voted)) +
    geom_jitter(alpha = 0.03, height = 0.1) +
    scale_x_continuous(breaks = 1:6) + 
    scale_y_continuous(breaks = c(0, 1), labels = c("No", "Yes")) +
    labs(title = "Civic Engagement and Voting Behavior in Michigan",
         subtitle = "Past voting predicts future voting.",
         x = "Civic Engagement",
         y = "Voted in 2006 Primary Election",
         caption = "Random sample of 5% of the data from Gerber, Green, and Larimer (2008)")
```

Although this plot is pleasing, we need to create an actual model with this data in order to answer our questions.

### Exercise 21

Add the code from Exercise 16 and set it to an object named `ch10_data` in a new code chunk in `causal_effect.qmd`. At the top of this code chunk, add `set.seed(9)`. This will generate the same random sample of the whole data so we don't have new new samples from the data each time.

Also add the code from the previous exercise to add the graph in the file. 

Your code should look something like this:

```
set.seed(9)

ch10_data <- shaming |> ... |> slice_sample(prop = 0.1)

ch10_data |> ...
```

Render the file. 

In the Console, run:

```
show_file("causal_effect.qmd", start = -5)
```

CP/CR.

```{r wisdom-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

In the `.gitignore`, add `*_files` so that we do not commit those junk files. Commit and push. 

### Exercise 22

In your own words, define "validity" as we use the term.

```{r wisdom-22}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other.

### Exercise 23

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-23}
question_text(NULL,
	message = "Voting in a primary election in 2006 in Michigan is not the same thing as voting in a general election in Texas in 2026. Primary elections are less newsworthy and, usually, less competitive. We cannot assume tha the two elections are similar enough for us to make connections between them.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Fortunately, at least for our continued use of this example, we will assume that validity holds. The outcome variable in our data and in our Preceptor Table are close enough — even though one is for a primary election while the other is for a general election — that we can just stack them. At the back of our minds we should remember that the answer that we will find will be nowhere close to being 100% accurate. 

### Exercise 24

Summarize the state of your work so far in one sentence. Make reference to the data you have and to the specific question you are trying to answer. 

```{r wisdom-24}
question_text(NULL,
	message = "Using the data from an experiment to find out whether and to what extent people are motivated to vote by social pressure, we seek to forecast the causal effect on voter participation of sending postcards in the Texas gubernatorial general election of 2026.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `causal_effect.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*It is in justice that the ordering of society is centered.* - Aristotle

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: All of Justice is about concerns that you have, reasons why the model you create might not work as well as you hope. Drop knowledge/discussion as you see fit, but the central theme is *worries*. Connect some of the specific data discussion from Wisdom to these assumptions. -->

In the previous section we noted why validity may not hold. We also noticed some other potentially problematic things about the data. We will be looking at them on a deeper level in this section. The goal is to understand that our model will not be perfect, because none of them are! We strive to make our conclusions as accurate as possible but they will never reach perfection. It is important as data scientists to take note of our limitations.

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Recall that every row from both the Preceptor Table and the data is included in the Population Table (at least at the start), along with all the rows from the underlying population from which we assume that both the Preceptor Table and the data were drawn. The Population Table includes rows from three sources: the Preceptor Table, the actual data, and all other members of the population.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "The data collected in 2006 on voting behavior might not be the same in 2026. We aren’t sure what would impact someone’s response to a postcard encouraging them to vote. It is possible, for instance, that a postcard informing neighbors of voting status has a bigger effect in a world with more social media.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When we are confronted with this uncertainty, we can consider making our time frame smaller. However, we would still need to assume stability from 2006 (time of data collection) to 2026. Stability allows us to ignore the issue of time.

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Michigan and Texas are different states. We are trying to use data from Michigan to make an inference about Texas. The obvious problem is that voters in Michigan are different from voters in Texas, in all sorts of ways which might matter to our analysis.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In one sense, neither the data nor the Preceptor Table is a sample. Both include, more or less, the entire electorates in their respective states. But, from the point of view of the Population Table, they are both samples from the underling population.

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. 

### Exercise 8

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-8}
question_text(NULL,
	message = "The experiment should be randomized, but there is a posibility that the people who ran the experiment did not actually make it fully randomized. It is easy to lie and say that there was randomization, but we can not know for sure if this was truly random assignment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The great advantage of randomized assignment of treatment is that it guarantees unconfoundedness. There is no way for treatment assignment to be correlated with anything, including potential outcomes, if treatment assignment is random. 

### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 

```{r justice-9}
question_text(NULL,
	message = "Using the data from an experiment to find out whether and to what extent people are motivated to vote by social pressure, we seek to forecast the causal effect on voter participation of sending postcards in the Texas gubernatorial general election of 2026. Stability might not be true because the way people view politics has changed from 2006 because of new things such as social media.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `causal_effect.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.

## Courage
### 

*Courage is being scared to death, but saddling up anyway.* - John Wayne

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We first specify the mathematical formula which connects the outcome variable we are interested in with the other data that we have. We need to decide which variables to include and to estimate the values of unknown parameters. We check our models for consistency with the data we have. We avoid hypothesis tests.

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

Given that the outcome variable is 0/1, a logistic model is the obvious choice. However, in this case, a linear model with a normal error term provides more or less the same answer.

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

It is time to look at interactions! We will create a model that estimates `voted` as a function of `age_z`, `sex`, `treatment`, `voter_class`, and the interaction between treatment and voter classification. 

The math (very long): 

$$y_{i} = \beta_{0} + \beta_{1} age\_z + \beta_{2}male_i + \beta_{3}civic\_duty_i + \\ \beta_{4}hawthorne_i + \beta_{5}self_i + \beta_{6}neighbors_i + \\ \beta_{7}Sometimes\ vote_i + \beta_{8}Always\ vote_i + \\ \beta_{9}civic\_duty_i Sometimes\ vote_i + \beta_{10}hawthorne_i Sometimes\ vote_i + \\ \beta_{11}self_i Sometimes\ vote_i + \beta_{11}neighbors_i Sometimes\ vote_i + \\ \beta_{12}civic\_duty_i Always\ vote_i + \beta_{13}hawthorne_i Always\ vote_i + \\ \beta_{14}self_i Always\ vote_i + \beta_{15}neighbors_i Always\ vote_i + \epsilon_{i}$$

### Exercise 4

Add `library(brms)` and `library(tidybayes)` to `causal_effect.qmd`. `Command/Ctrl + Shift + K`. At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd", pattern = "brms|tidybayes")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

There are two ways to formalize the model: with and without the variable names. The former is related to the concept of Justice as we acknowledge that the model is constructed via the linear sum of `n` parameters times the value for `n` variables, along with an error term. In other words, it is a linear model.

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments should be `formula = voted ~ age_z + sex + treatment + voter_class + treatment*voter_class`, `data = ch10_data`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 19`. 

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
brm(...)
```

### 

The second type of formal notation, more associated with the virtue Courage, includes the actual variable names we are using. The trickiest part is the transformation of character/factor variables into indicator variables, meaning variables with 0/1 values. Because `treatment` has 5 levels, we need 4 indicator variables. The fifth level is incorporated in the intercept.

### Exercise 6

Behind the scenes, we have assigned the result of the `brm()` call to an object named `fit_postcard_vote`. Type `fit_postcard_vote` and hit "Run Code." This generates the same results as using `print(fit_postcard_vote)`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_postcard_vote
```

```{r courage-6-test, include = FALSE}
fit_postcard_vote
```

### 

<!-- XX Say some general words about the object. Note that we are about to go through the top 4 rows. -->

### Exercise 7

Run `family()` on `fit_postcard_vote`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_postcard_vote)
```

### 

In this case, the family is gaussian, which means the distribution of the output variable is continuous. The family is determined by the `family` argument which you passed in to the `brm()` call.

### Exercise 8

Run `formula()` on `fit_postcard_vote`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_postcard_vote)
```

### 

In this case, XX . . .

### Exercise 9

Run `nobs()` on `fit_postcard_vote`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_postcard_vote)
```

### 

In this case, XX

### Exercise 10

Add mathematical formula for your model, using $\LaTeX$ math notation to `causal_effect.qmd`.

```
$$y_{i} = \beta_{0} + \beta_{1} age\_z + \beta_{2}male_i + \beta_{3}civic\_duty_i + \\ \beta_{4}hawthorne_i + \beta_{5}self_i + \beta_{6}neighbors_i + \\ \beta_{7}Sometimes\ vote_i + \beta_{8}Always\ vote_i + \\ \beta_{9}civic\_duty_i Sometimes\ vote_i + \beta_{10}hawthorne_i Sometimes\ vote_i + \\ \beta_{11}self_i Sometimes\ vote_i + \beta_{11}neighbors_i Sometimes\ vote_i + \\ \beta_{12}civic\_duty_i Always\ vote_i + \beta_{13}hawthorne_i Always\ vote_i + \\ \beta_{14}self_i Always\ vote_i + \beta_{15}neighbors_i Always\ vote_i + \epsilon_{i}$$
```

`Command/Ctrl + Shift + K`. Ensure that the formula looks correct. 

At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd", start = -8)
```

CP/CR.

```{r courage-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 11

Create a new code chunk in `causal_effect.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model using `brm()` into the code chunk, assigning the result to `fit_postcard_vote`. 

`Command/Ctrl + Shift + K`. It may take some time to render `causal_effect.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `causal_effect.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd", start = -8)
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 12

Run `posterior_interval()` on `fit_postcard_vote`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-12-test, include = FALSE}
posterior_interval(fit_postcard_vote)
```

### 

In this case, XX . . .

### Exercise 13

Run `fixef()` on `fit_postcard_vote`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-13-test, include = FALSE}
fixef(fit_postcard_vote)
```

### 

In this case, XX . . .

<!-- XX: Consider adding questions about conditional_effects(), ranef() and other commands, if relevant. -->

### Exercise 14

Run `pp_check()` on `fit_postcard_vote`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-14-test, include = FALSE}
pp_check(fit_postcard_vote)
```

### 

In this case, XX

<!-- If the fake data had looked very different from the real data, we have had a problem. But, for the most part, we conclude that, although not perfect, pp_check() shows that the fake outcomes generated by our model are like the actual outcome data. -->

### Exercise 15

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
library(...)
```

```{r courage-15-test, include = FALSE}
library(gtsummary)
```

### 

<!-- Drop some knowledge about gtsummary. Or say something more about your DGM. -->

### Exercise 16

<!-- XX: This can be just one question or several, especially if you want to teach some more gtsummary or gt tricks. Make any adjustments to this question, like `intercept = TRUE`, so that this question works. -->

Pipe `fit_postcard_vote` to `tbl_regression(intercept = TRUE, estimate_fun = function(x) style_sigfig(x, digits = 3))`.

```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
fit_postcard_vote |> 
  tbl_regression(...)
```

```{r courage-16-test, include = FALSE}
fit_postcard_vote |> 
  tbl_regression(intercept = TRUE, estimate_fun = function(x) style_sigfig(x, digits = 3))
```

### 

<!-- XX: Drop some knowledge about what you have learned by looking at the resulting table. Of course, you could have learned the same thing when you first took a look at fit_postcard_vote. But the table makes it easier to see the relationships between the variables and the outcome. With luck, students will take the hint when they answer the next question. -->

<!-- https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html -->

### Exercise 17

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using, specifying the functional form and the dependent variable. Add one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-17}
question_text(NULL,
	message = "Using the data from an experiment to find out whether and to what extent people are motivated to vote by social pressure, we seek to forecast the causal effect on voter participation of sending postcards in the Texas gubernatorial general election of 2026. Stability might not be true because the way people view politics has changed from 2006 because of new things such as social media. We modeled `primary_06`, a binary 0/1 integer variable indicating whether the respondent voted in the 2006 primary election, and the type of postcard they recieved. People who have been voting in the past are more likely to vote again.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX -->

### Exercise 18

Update `causal_effect.qmd`. First, add `library(gtsummary)` to the `setup` code chunk,. Second, add the mathematical formula, in $\LaTeX$ and surrounded by double dollar signs, for your model. Third, add a new code chunk which creates the table of model parameters. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd", start = -8)
```

CP/CR.

```{r courage-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Temperance
### 

<!-- XX: Choose one. -->

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha
*Temperance is the greatest of all virtues. It subdues every passion and emotion, and almost creates a Heaven upon Earth.* - Joseph Smith Jr.
*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton
*Temperance is the firm and moderate dominion of reason over passion and other unrighteous impulses of the mind.* - Marcus Tullius Cicero
*Temperance to be a virtue must be free, and not forced.* - Philip Massinger
*Temperance is simply a disposition of the mind which binds the passion.* - Thomas Aquinas


### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "XX: Should be exactly how you started the Wisdom section.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create a `newdata` object. Which variables do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX -->

### Exercise 4

Which values do you want the variables in your `newdata` object to have? This is not easy! 

```{r temperance-4}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 5

Here is the R code which creates the `newdata` object: `tibble(whatever) code here`. Type it into the code exercise block and hit "Run Code."

<!-- Asking students to create this object --- even after you help them figure out the columns, rows and values --- is too hard, at least until they get more experiences. Your knowledge drop, for this question and the next, should give them advice on the broad topic of how they can create newdata objects themselves. -->

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}

```

```{r temperance-5-test, include = FALSE}

```

### 

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

<!-- Of course, you need to have added the code to create `ndata` in the setup chunk at the top of the file. -->

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}

```

```{r temperance-6-test, include = FALSE}

```

### 

### Exercise 7

Now that we have the `newdata` object, we can create a pipe which uses out fitted model to answer our question. Begin by typing `fit_postcard_vote` and clicking "Run Code."

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-hint-1, eval = FALSE}

```

```{r temperance-7-test, include = FALSE}

```

### 

<!-- XX: Again, the main point of knowledge drops is this area is to explain to students why the newdata object looks the way it does and what it will produce. A great way to teach is via example. That is, explaining that if we had another way with these values, then we would get this posterior. Or, explaining what would be produced if we used add_epred instead of add_predict, and vice verse. -->


### Exercise 8

Pipe `fit_postcard_vote` to [XX: either `add_epred_draws()` or `add_predicted_draws()`] with the argument `newdata = ndata`.



```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}

```

```{r temperance-8-test, include = FALSE}

```

### 

<!-- XX: How do students know whether to use add_epred_draws or add_predicted_draws? This is non-trivial. On some level, we just tell them with the above command. (We don't make them guess.) But we also address this issue explicitly in various knowledg drops, especially this one. -->

<!-- XX: Insert as many questions as necessary to build a nice-looking example of your final plot. In early chapters, this is simple since our questions are simple. They are just one posterior. In later chapters, they become more complex, with the inclusion of several posteriors, as well as manipulation of them to calculate causal effects and whatnot. See the voting postcard example. -->

### Exercise 9

Create a new code chunk in `causal_effect.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. `Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd", start = -8)
```

CP/CR.

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 10

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.

<!-- XX: Most of the time, there will be some measure of uncertainty associated with your QoI. But not always! The most common counter-example involves a question which asks about the odds or probability of something happening. We would answer such a question by simulating the event with `add_predicted_draws()`. We would then calculate the odds/probability of something happening by seeing how many of the 4,000 draws met the criteria for the event. Assume that was 40%. So, we think that there is a 40% chance that event A will happen. Yet there is no uncertainty associated with that estimate because it, itself, is an expression of uncertainty. -->

```{r temperance-10}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragrpah in `causal_effect.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.


<!-- XX: Again, spend time to make your recommended paragraph perfect. Study the examples in https://ppbds.github.io/primer/cardinal-virtues.html closely. -->

### Exercise 11

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-11}
question_text(NULL,
	message = "XX: This is another example in which the quality of your answer is important. You might or might not suggest an alternate estimate. I always adjust the estimate toward my own subjective sense of a longrun average and/or typical value and/or zero. But that is not necessary. However, you should always increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 12

Publish `causal_effect.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 13

Rearrange the material in `causal_effect.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("causal_effect.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.


## Summary
### 

This tutorial covered [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
