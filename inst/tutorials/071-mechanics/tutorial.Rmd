---
title: Mechanics
author: David Kane and Gia Khang
tutorial:
  id: mechanics
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 7 Tutorial: Mechanics'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(primer.data)
library(brms)
library(broom.mixed)
library(patchwork)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

x <- kenya |> 
  filter(rv13 > 0)

rv_p <- x |> 
  ggplot(aes(rv13)) + 
    geom_histogram(bins = 100) +
    labs(x = "Registered Voters",
         y = NULL) 

log_rv_p <- x |> 
  ggplot(aes(log(rv13))) + 
    geom_histogram(bins = 100) +
    labs(x = "Log of Registered Voters",
         y = NULL) +
    expand_limits(y = c(0, 175))

#no_na_nhanes <- nhanes |> 
#  select(height, age) |> 
#  drop_na() 

# Create and save all the models we use.

# fit_1 <- brm(formula = income ~ age, 
#              data = trains,
#              family = gaussian(),
#              silent = 2,
#              refresh = 0,
#              seed = 45)
# write_rds(fit_1, "data/fit_1.rds")
fit_1 <- read_rds("data/fit_1.rds")

trains_2 <- trains |> 
  mutate(c_age = age - mean(age))

# fit_1_c <- brm(formula = income ~ c_age, 
#                data = trains_2,
#                family = gaussian(),
#                silent = 2,
#                refresh = 0,
#                seed = 16)
# write_rds(fit_1_c, "data/fit_1_c.rds")
fit_1_c <- read_rds("data/fit_1_c.rds")

no_na_nhanes <- nhanes |> 
  select(height, age) |> 
  drop_na() 

# nhanes_1 <- brm(height ~ age,
#                 data = no_na_nhanes,
#                 family = gaussian(),
#                 silent = 2,
#                 refresh = 0,
#                 seed = 16)
# write_rds(nhanes_1, "data/nhanes_1.rds")
nhanes_1 <- read_rds("data/nhanes_1.rds")

# nhanes_3 <- brm(formula = height ~ 
#                   I(ifelse(age > 18, 18, age)),
#                 data = no_na_nhanes,
#                 family = gaussian(),
#                 silent = 2,
#                 refresh = 0,
#                 seed = 87)
# write_rds(nhanes_3, "data/nhanes_3.rds")
nhanes_3 <- read_rds("data/nhanes_3.rds")

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

## Introduction
### 

This tutorial covers [Chapter 7: Mechanics](https://ppbds.github.io/primer/mechanics.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

In our haste to make progress — to get all the way through the process of building, interpreting and using models — we have given short shrift to some of the messy details of model building and evaluation. This chapter fills in those lacunae.

## Transforming variables 
### 

It is often convenient to transform a predictor variable so that our model makes more sense.

### 

Let's say we are interested in predicting a person's income based on their age. We have a model of `income` as a function of `age`: 
$$ income_i = \beta_0  + \beta_1 age_i + \epsilon_i$$
### Exercise 1

Load the **brms** package.

```{r transforming-variables-1, exercise = TRUE}

```

```{r transforming-variables-1-hint-1, eval = FALSE}
library(brms)
```

```{r transforming-variables-1-test, include = FALSE}
library(brms)
```

### 

### Exercise 2

Load the **tidyverse** package.

```{r transforming-variables-2, exercise = TRUE}

```

```{r transforming-variables-2-hint-1, eval = FALSE}
library(tidyverse)
```

```{r transforming-variables-2-test, include = FALSE}
library(tidyverse)
```

### 

### Exercise 3

We will be using the `trains` data set from **primer.data** for our model. Load the **primer.data** package.

```{r transforming-variables-3, exercise = TRUE}

```

```{r transforming-variables-3-hint-1, eval = FALSE}
library(primer.data)
```

```{r transforming-variables-3-test, include = FALSE}
library(primer.data)
```

### 

### Exercise 4

We will also be using a new package, **broom.mixed**, which allows us to tidy regression data for plotting. Load the **broom.mixed** package.

```{r transforming-variables-4, exercise = TRUE}

```

```{r transforming-variables-4-hint-1, eval = FALSE}
library(broom.mixed)
```

```{r transforming-variables-4-test, include = FALSE}
library(broom.mixed)
```

### 

### Exercise 5

Type `trains` and hit "Run Code".

```{r transforming-variables-5, exercise = TRUE}

```

```{r transforming-variables-5-hint-1, eval = FALSE}
trains
```

```{r transforming-variables-5-test, include = FALSE}
trains
```

### 

### Exercise 6

Create a model using `brm()` from the **brms**. Use the argument `formula = income ~ age`, `data = trains`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 45`.

Assign the result to an object called `fit_1`.


```{r transforming-variables-6, exercise = TRUE}

```

```{r transforming-variables-6-hint-1, eval = FALSE}
fit_1 <- brm(... = income ~ age, 
             data = ...,
             ... = gaussian(),
             ... = 2,
             refresh = ...,
             ... = 45)
```

### 

### Exercise 7

Type `fit_1` and hit "Run Code."

```{r transforming-variables-7, exercise = TRUE}

```

```{r transforming-variables-7-hint-1, eval = FALSE}
fit_1
```

```{r transforming-variables-7-test, include = FALSE}
fit_1
```

### 

### Exercise 8

Run `fixef()` on `fit_1` and hit "Run Code."

```{r transforming-variables-8, exercise = TRUE}

```

```{r transforming-variables-8-hint-1, eval = FALSE}
fixef(...)
```

```{r transforming-variables-8-test, include = FALSE}
fixef(fit_1)
```

### 

The value of $\beta_0$, the intercept in the regression, is `r scales::comma(round(fixef(fit_1)["Intercept", "Estimate"], 0))`. This represent the estimated average income for a person with an age of zero, which is awkward and useless since there are no people of zero age in our data. 

### Exercise 9

One way to make the intercept more meaningful is to transform `age`. Start a pipe with `trains` to `mutate` with the argument `c_age = age - mean(age)`. Assign the result to a new object called `trains_2`.

```{r transforming-variables-9, exercise = TRUE}

```

```{r transforming-variables-9-hint-1, eval = FALSE}
... <- trains |> 
  mutate(... = age - ...(age))
```

```{r transforming-variables-9-test, include = FALSE}
trains_2 <- trains |> 
  mutate(c_age = age - mean(age))
```

### 


### Exercise 10

Copy your previous code from exercise 5, but set `formula` equal `income ~ c_age`, and `data` equal `trains_2`. Assign the result to an object called `fit_1_c`.

```{r transforming-variables-10, exercise = TRUE}

```

```{r transforming-variables-10-hint-1, eval = FALSE}
fit_1_c <- brm(formula = ..., 
               ... =  = trains_2,
               family = gaussian(),
               silent = 2,
               refresh = 0,
               seed = 16)
```


### 

### Exercise 11

Run `fixef()` on `fit_1_c` and hit "Run Code."

```{r transforming-variables-11, exercise = TRUE}

```

```{r transforming-variables-11-hint-1, eval = FALSE}
fixef(fit_1_c)
```

```{r transforming-variables-11-test, include = FALSE}
fixef(fit_1_c)
```

### 

The intercept, `r scales::comma(round(fixef(fit_1_c)["Intercept", "Estimate"], 0))`, is the expected income for someone with `c_age = 0`, i.e., someone of an average age in the data, which is around `r round(mean(trains$age), 0)`.

### 

Centering — changing a variable via addition/subtraction — often makes the intercept easier to interpret. Scaling — changing a variable via multiplication/division — often makes it easier to interpret coefficients. 

### Exercise 12

The most common scaling method is to divide the variable by its standard deviation. Start a pipe with `trains` to `mutate` with the argument `s_age = age / sd(age)`. Assign the result to a new object called `trains_3`.

```{r transforming-variables-12, exercise = TRUE}

```

```{r transforming-variables-12-hint-1, eval = FALSE}
... <- trains |> 
  mutate(... = age / ...(age))
```

```{r transforming-variables-12-test, include = FALSE}
trains_3 <- trains |> 
  mutate(s_age = age / sd(age))
```

### 

### Exercise 13

Create a model using `brm()` from the **brms**. Use the argument `formula = income ~ s_age`, `data = trains_3`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 16`. Assign the result to an object called `fit_1_s`. 

```{r transforming-variables-13, exercise = TRUE}

```

```{r transforming-variables-13-hint-1, eval = FALSE}
... <- brm(formula = ..., 
               ... = trains_3,
               family = ...,
               ... = 2,
               refresh = ...,
               seed = ...)
```

```{r transforming-variables-13-test, include = FALSE}
fit_1_s <- brm(formula = income ~ s_age, 
               data = trains_3,
               family = gaussian(),
               silent = 2,
               refresh = 0,
               seed = 16)
```

### 

### Exercise 14

Run `fixef()` on `fit_1_s` and hit "Run Code."

```{r transforming-variables-14, exercise = TRUE}

```

```{r transforming-variables-14-hint-1, eval = FALSE}
fixef(...)
```

```{r transforming-variables-14-test, include = FALSE}
fixef(fit_1_s)
```

### 

### Exercise 15

The most common transformation applies both centering and scaling. Start a pipe with `trains` to `mutate` with the argument `z_age = scale(age)`. Assign the result to a new object called `trains_4`.

```{r transforming-variables-15, exercise = TRUE}

```

```{r transforming-variables-15-hint-1, eval = FALSE}
... <- ... |> 
  mutate(z_age = scale(...))
```

```{r transforming-variables-15-test, include = FALSE}
trains_4 <- trains |> 
  mutate(z_age = scale(age))
```

### 

### Exercise 16

Create a model using `brm()` from the **brms**. Use the argument `formula = income ~ z_age`, `data = trains_4`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 16`. Assign the result to an object called `fit_1_z`. 

```{r transforming-variables-16, exercise = TRUE}

```

```{r transforming-variables-16-hint-1, eval = FALSE}
... <- brm(formula = ..., 
              ... = trains_4,
               family = ...,
               ... = 2,
               refresh = ...,
               ... = 16)

```

```{r transforming-variables-16-test, include = FALSE}
fit_1_z <- brm(formula = income ~ z_age, 
               data = trains_4,
               family = gaussian(),
               silent = 2,
               refresh = 0,
               seed = 16)

```

### 

### Exercise 17

Run `fixef()` on `fit_1_z` and hit "Run Code". 

```{r transforming-variables-17, exercise = TRUE}

```

```{r transforming-variables-17-hint-1, eval = FALSE}
fixef(...)
```

```{r transforming-variables-17-test, include = FALSE}
fixef(fit_1_z)
```

### 

### Exercise 18

It is often helpful to take the log of predictor variables, especially in cases in which their distribution is skewed. We will be using the `kenya` data set from **primer.data**. Type `kenya` and hit "Run Code".

```{r transforming-variables-18, exercise = TRUE}

```

```{r transforming-variables-18-hint-1, eval = FALSE}
kenya
```

```{r transforming-variables-18-test, include = FALSE}
kenya
```

### 

### Exercise 19

Pipe `kenya` to `summary()` to return some statistics about the data.

```{r transforming-variables-19, exercise = TRUE}

```

```{r transforming-variables-19-hint-1, eval = FALSE}
... |> 
  summary()
```

```{r transforming-variables-19-test, include = FALSE}
kenya |> 
  summary()
```

### 

Let's say we are interested in the number of registered voters `rv13`. The summary shows that there is no missing values (NAs) in this column, however, there are rows with 0 voters, resulting in the min equals 0.

### Exercise 20

To fix this, pipe `kenya` to the command `filter()` with the argument `rv13 > 0`. Assign the result to an object called `x`. 

```{r transforming-variables-20, exercise = TRUE}

```

```{r transforming-variables-20-hint-1, eval = FALSE}
... <- ... |> 
  filter(... > 0)
```

```{r transforming-variables-20-test, include = FALSE}
x <- kenya |> 
  filter(rv13 > 0)
```

### 

### Exercise 21

Next, we will look at the distribution of `rv13` in the our data. Behind the scene, we have created the graph for you. Type `rv_p` and hit "Run Code"

```{r transforming-variables-21, exercise = TRUE}

```

```{r transforming-variables-21-hint-1, eval = FALSE}
rv_p
```

```{r transforming-variables-21-test, include = FALSE}
rv_p
```

### 

### Exercise 22

Now let's see how the distribution looks like after transforming `rv13` into the log version. Type `log_rv_p` and hit "Run Code".

```{r transforming-variables-22, exercise = TRUE}

```

```{r transforming-variables-22-hint-1, eval = FALSE}
log_rv_p
```

```{r transforming-variables-22-test, include = FALSE}
log_rv_p
```

### 

### Exercise 23

Let's put the two distribution next to each other to see the differences. Type `rv_p` and `log_rv_p`, connect them by `+`. Hit "Run Code"

```{r transforming-variables-23, exercise = TRUE}

```

```{r transforming-variables-23-hint-1, eval = FALSE}
... + ...
```

```{r transforming-variables-23-test, include = FALSE}
rv_p + log_rv_p
```

### 

### Exercise 24

Lastly, add `title`, `subtitle` for the graph using the command `plot_annotation()`. Remember that this is what your graph should look like. 

```{r}
rv_p + log_rv_p +
  plot_annotation(title = 'Registered Votes In Kenya Communities',
                  subtitle = "Taking logs helps us deal with outliers")
```

```{r transforming-variables-24, exercise = TRUE}

```

```{r transforming-variables-24-hint-1, eval = FALSE}
... + ... + 
  plot_annotation(title = ..., 
                  subtitle = ...)
```

```{r transforming-variables-24-test, include = FALSE}
rv_p + log_rv_p +
  plot_annotation(title = 'Registered Votes In Kenya Communities',
                  subtitle = "Taking logs helps us deal with outliers")
```

### 

### Exercise 25

Instead of simply transforming variables, we can add more terms which are transformed versions of a variable. We will be using the `nhanes` data set. Type `nhanes` and hit "Run Code."

```{r transforming-variables-25, exercise = TRUE}

```

```{r transforming-variables-25-hint-1, eval = FALSE}
nhanes
```

```{r transforming-variables-25-test, include = FALSE}
nhanes
```

### 

### Exercise 26

Consider the relation of `height` to `age` in `nhanes`. Pipe `nhanes` to `select()` with `height` and `age` as the arguments. 

```{r transforming-variables-26, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r transforming-variables-26-hint-1, eval = FALSE}
... |> 
  select(..., ...)
```

```{r transforming-variables-26-test, include = FALSE}
nhanes |> 
  select(height, age)
```

### 

<!-- Add knowledge drop about the data -->

### Exercise 27

Let’s start by dropping the missing values. Copy your previous code, continue the pipe with `drop_na()`. Pipe the result to an object called `no_na_nhanes`.

```{r transforming-variables-27, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r transforming-variables-27-hint-1, eval = FALSE}
... <- nhanes |> 
  select(..., ...) |> 
  ...
```

```{r transforming-variables-27-test, include = FALSE}
no_na_nhanes <- nhanes |> 
  select(height, age) |> 
  drop_na() 
```

### 

### Exercise 28

Let's create a model to study the relationship between `height` and `age`. Create a model using `brm()` from the **brms**. Use the argument `formula = height ~ age`, `data = no_na_nhanes`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 16`. Assign the result to an object called `nhanes_1`. 

```{r transforming-variables-28, exercise = TRUE}

```

```{r transforming-variables-28-hint-1, eval = FALSE}
... <- brm(formula = ...,
                data = ...,
                family = ...,
                ... = 2,
                refresh = ...,
                ... = 16)
```

### 

### Exercise 29

How accurate our model is can be determined by whether it represent the pattern of our data. Hit "Run Code". 

```{r transforming-variables-29, exercise = TRUE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_1)[, "Estimate"]),
             color = "red",
             linewidth = 2) +
    labs(title = "Age and Height",
         subtitle = "Children are shorter, but a linear fit is poor",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

```{r transforming-variables-29-test, include = FALSE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_1)[, "Estimate"]),
             color = "red",
             linewidth = 2) +
    labs(title = "Age and Height",
         subtitle = "Children are shorter, but a linear fit is poor",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

### 

That is not a very good model, obviously. Adding a quadratic term makes it better.

### Exercise 30

Run the `brm()` command. Use the argument `formula = height ~ age + I(age^2)`, `data = no_na_nhanes`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 27`. Assign the result to an object called `nhanes_2`. 

```{r transforming-variables-30, exercise = TRUE}

```

```{r transforming-variables-30-hint-1, eval = FALSE}
... <- brm(... = height ~ age + I(age^2),
                data = ...,
                ... = gaussian(),
                silent = ...,
                ... = 0,
                seed = ...)
```

```{r transforming-variables-30-test, include = FALSE}
nhanes_2 <- brm(formula = height ~ age + I(age^2),
                data = no_na_nhanes,
                family = gaussian(),
                silent = 2,
                refresh = 0,
                seed = 27)
```

### 

Note the need for `I()` in creating the squared term within the `formula` argument.

### Exercise 31

Let's see whether this model is better in terms of demonstrating the relationship between `age` and `height` in our data set. Hit "Run Code".

```{r transforming-variables-31, exercise = TRUE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_2)[, "Estimate"]), 
              color = "red") +
    labs(title = "Age and Height",
         subtitle = "Quadratic fit is much better, but still poor",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

```{r transforming-variables-31-test, include = FALSE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_2)[, "Estimate"]), 
              color = "red") +
    labs(title = "Age and Height",
         subtitle = "Quadratic fit is much better, but still poor",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

### 

This line looks better, but not the best we could do. We have not used our background knowledge that people don't get any taller after age 18 or so. 

### Exercise 32

Let's create variables which capture that break. Run the `brm()` command. Use the argument `formula = height ~ I(ifelse(age > 18, 18, age))`, `data = no_na_nhanes`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 87`. Assign the result to an object called `nhanes_3`. 

```{r transforming-variables-32, exercise = TRUE}

```

```{r transforming-variables-32-hint-1, eval = FALSE}
... <- brm(... = ... ~ I(ifelse(age > 18, 18, age)),
                data = ...,
                ... = gaussian(),
                silent = ...,
                ... = 0,
                seed = ...)
```


### 

<!-- Add knowledge drop about `ifelse` -->

### Exercise 33

Let's see how this model does in terms of demonstrating the relationship between the two variables. Hit "Run Code". 

```{r transforming-variables-33, exercise = TRUE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_3)[, "Estimate"]), 
              color = "red") +
    labs(title = "Age and Height",
         subtitle = "Domain knowledge makes for better models",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

```{r transforming-variables-33-test, include = FALSE}
no_na_nhanes |> 
  ggplot(aes(x = age, y = height)) +
    geom_point(alpha = 0.1) +
    geom_line(aes(y = fitted(nhanes_3)[, "Estimate"]), 
              color = "red") +
    labs(title = "Age and Height",
         subtitle = "Domain knowledge makes for better models",
         x = "Age",
         y = "Height (cm)",
         caption = "Data source: NHANES")
```

### 

<!-- Knowledge drop about the importance of domain knowledge -->

## Selecting variables
### 

How do we decide which variables to include in a model? There is no one right answer to this question.

### Exercise 1

We will be using variables in the `trains` data set as an example. Type `trains` and hit "Run Code". The `trains` data set include `gender`, `liberal`, `party`, `age`, `income`, `att_start`, `treatment`, `att_end`.

```{r selecting-variables-1, exercise = TRUE}

```

```{r selecting-variables-1-hint-1, eval = FALSE}
trains
```

```{r selecting-variables-1-test, include = FALSE}
trains
```

### 

Which variables would be best to include in a model depends on the question we are asking. For example, if we want to know if the ending attitude toward immigration differs between men and women, we need to include `gender` in the model.

### Exercise 2

Let's say we want to investigate the causal effect of exposing people to Spanish-speakers on their attitudes towards immigration. Pipe `trains` to `select()` with `att_end`, `treatment`, `att_start` as the arguments. 

```{r selecting-variables-2, exercise = TRUE}

```

```{r selecting-variables-2-hint-1, eval = FALSE}
... |> 
  select(..., ..., ...)
```

```{r selecting-variables-2-test, include = FALSE}
trains |> 
  select(att_end, treatment, att_start)
```

### 

<!-- Knowledge drop describing the selected variables. -->

We also keep X if the underlying theory/observation suggests that X has a meaningfully connection to the outcome variable. It can also be the case when it is standard in your field to include X in such regressions, or simply just because your boss wants to include X. 

### Exercise 3

Run the `brm()` command. Use the argument `formula = att_end ~ treatment + att_start`, `data = trains`, `family = gaussian()`, `silent = 2`, `refresh = 0`, `seed = 16`. Pipe the result to an object called `fit_1_model`. 

```{r selecting-variables-3, exercise = TRUE}

```

```{r selecting-variables-3-hint-1, eval = FALSE}
... <- brm(... = att_end ~ treatment + att_start,
                   data = ...,
                   ... = gaussian(),
                   silent = ...,
                   ... = 0,
                   seed = ...)
```

```{r selecting-variables-3-test, include = FALSE}
fit_1_model <- brm(formula = att_end ~ treatment + att_start,
                   data = trains,
                   family = gaussian(),
                   silent = 2,
                   refresh = 0,
                   seed = 16)
```

### 

`att_end`, the variable before the tilde, is our outcome. The explanatory variables are `treatment`, which says whether a commuter relieved treatment or control conditions, and `att_start`, which measures attitude at the start of the study.

### Exercise 4

Run `fixef()` on `fit_1_model`. Hit "Run Code". 

```{r selecting-variables-4, exercise = TRUE}

```

```{r selecting-variables-4-hint-1, eval = FALSE}
fixef(...)
```

```{r selecting-variables-4-test, include = FALSE}
fixef(fit_1_model)
```

### 

### Exercise 5

How do we decide which variables are useful? First, let’s interpret our coefficients. In your own words, explain the coefficient of the Intercept. 

```{r selecting-variables-5}
question_text(NULL,
	message = "The 95% confidence interval for `att_end`, our outcome, is equal to the coefficient -2.34- plus or minus two standard errors. This shows the estimate for the `att_end` where the commuters were under treatment and **were not** in the control group.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 6

In your own words, explain what 

```{r selecting-variables-6}
question_text(NULL,
	message = "Place correct answer here.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- Add questions and knowledge drop about interpreting the coefficients -->

### Exercise 7

Let's us now consider `income` as a function of `age` and `liberal`, a proxy for political party. Pipe `trains` to `select()` with `income`, `age`, `liberal` as the arguments. 

```{r selecting-variables-7, exercise = TRUE}

```

```{r selecting-variables-7-hint-1, eval = FALSE}
... |> 
  select(..., ..., ...)
```

```{r selecting-variables-7-test, include = FALSE}
trains |> 
  select(income, age, liberal)
```

### 

### Exercise 8

Run the `brm()` command. Use the argument `formula = income ~ age + liberal`, `data = trains`, `family = gaussian()`, `silent = 2`, `refresh = 0`, `seed = 16`. Pipe the result to an object called `fit_2_model`. 

```{r selecting-variables-8, exercise = TRUE}

```

```{r selecting-variables-8-hint-1, eval = FALSE}
... <- brm(... = income ~ age + liberal,
                   data = ...,
                   ... = gaussian(),
                   silent = ...,
                   ... = 0,
                   seed = ...)
```

```{r selecting-variables-8-test, include = FALSE}
fit_2_model <- brm(formula = income ~ age + liberal,
                   data = trains,
                   family = gaussian(),
                   silent = 2,
                   refresh = 0,
                   seed = 16)
```

### 

### Exercise 9

Run `fixef()` on `fit_2_model`.

```{r selecting-variables-9, exercise = TRUE}

```

```{r selecting-variables-9-hint-1, eval = FALSE}
fixef(...)
```

```{r selecting-variables-9-test, include = FALSE}

fixef(fit_2_model)
```

### 

<!-- Add exercises and knowledge drop about interpreting and choosing variables -->

## Comparing models in theory
### 

Deciding which variables to include in a model is a subset of the larger question: How do we decide which model, out of the set of possible models, to choose?

### Exercise 1

Consider the first model which seeks to explain the attitudes towards immigration among Boston commuters, using political ideology (`liberal`) as the explantory variable. Run the `brm()` command. Use the argument `formula = att_end ~  liberal`, `data = trains`, `family = gaussian()`, `silent = 2`, `refresh = 0`, `seed = 12`. Pipe the result to an object called `fit_liberal`. 

```{r comparing-models-in-theory-1, exercise = TRUE}

```

```{r comparing-models-in-theory-1-hint-1, eval = FALSE}
fit_liberal <- brm(... = att_end ~ liberal,
                   data = ...,
                   ... = gaussian(),
                   silent = ...,
                   ... = 0,
                   seed = ...)
```

```{r comparing-models-in-theory-1-test, include = FALSE}
fit_liberal <- brm(formula = att_end ~ liberal,
                   data = trains,
                   family = gaussian(),
                   silent = 2,
                   refresh = 0,
                   seed = 12)
       
```

### 

### Exercise 2

Run `fixef()` on `fit_liberal` and hit "Run Code".

```{r comparing-models-in-theory-2, exercise = TRUE}

```

```{r comparing-models-in-theory-2-hint-1, eval = FALSE}
fixef(...)
```

```{r comparing-models-in-theory-2-test, include = FALSE}
fixef(fit_liberal)
```

### 

### Exercise 3

Consider another model which seeks to explain the attitudes towards immigration among Boston commuters, using `att_start` as the explanatory variable. Run the `brm()` command. Use the argument `formula = att_end ~  att_start`, `data = trains`, `family = gaussian()`, `silent = 2`, `refresh = 0`, `seed = 37`. Pipe the result to an object called `fit_att_start`. 

```{r comparing-models-in-theory-3, exercise = TRUE}

```

```{r comparing-models-in-theory-3-hint-1, eval = FALSE}
... <- brm(... = att_end ~ att_start,
                     data = ...,
                     ... = gaussian(),
                     silent = ...,
                     ... = 0,
                     seed = ...)
```

```{r comparing-models-in-theory-3-test, include = FALSE}
fit_att_start <- brm(formula = att_end ~ att_start,
                     data = trains,
                     family = gaussian(),
                     silent = 2,
                     refresh = 0,
                     seed = 37)
```

### 

### Exercise 4

Run `fixef()` on `fit_att_start` and hit "Run Code". 

```{r comparing-models-in-theory-4, exercise = TRUE}

```

```{r comparing-models-in-theory-4-hint-1, eval = FALSE}
fixef(...)
```

```{r comparing-models-in-theory-4-test, include = FALSE}
fixef(fit_att_start)
```

### 

### Exercise 5

The most obvious criteria for comparing models is the accuracy of the predictions. For example, consider the use of `liberal` to predict `att_end`. Pipe `trains` to `mutate()` with the argument `pred_liberal = fitted(fit_liberal)[,"Estimate"]`. 

```{r comparing-models-in-theory-5, exercise = TRUE}

```

```{r comparing-models-in-theory-5-hint-1, eval = FALSE}
... |> 
  mutate(... = fitted(...)[,"Estimate"])
```

```{r comparing-models-in-theory-5-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"])
```

### 

### Exercise 6

Copy the previous code, continue the pipe to `select()` and choose `pred_liberal` and `att_end` as the argument. 

```{r comparing-models-in-theory-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-6-hint-1, eval = FALSE}
... |> 
  select(att_end, pred_liberal)
```

```{r comparing-models-in-theory-6-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  select(att_end, pred_liberal)
```

### 

### Exercise 7

Copy your previous code in exercise 5, continue the pipe with `ggplot()`. Map `x` to `pred_liberal`, `y` to `att_end` in the `aes()` argument. This will return a plain graph with two axes. 

```{r comparing-models-in-theory-7, exercise = TRUE}

```

```{r comparing-models-in-theory-7-hint-1, eval = FALSE}
... |> 
  ggplot(...(x = ..., y = ...))
```

```{r comparing-models-in-theory-7-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end))
```

### 

### Exercise 8

Copy the previous code, add `geom_jitter()` as a another layer. Set `width` equal 0.05, `height` equal 0.2, and `alpha` equal 0.5. 

```{r comparing-models-in-theory-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-8-hint-1, eval = FALSE}
... +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5)
```

```{r comparing-models-in-theory-8-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5)
```

### 

### Exercise 9

Copy the previous code, add the `annotate()` command as another layer. The first argument is `"point"`, set `x` equal 8, `y` equal 8, `size` equal 20, `pch` equal 1, and `color` equal "red". 

```{r comparing-models-in-theory-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-9-hint-1, eval = FALSE}
... + 
    annotate("...", ... = 8, ... = 8, size = ..., pch = ..., color = "red")
```

```{r comparing-models-in-theory-9-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) + 
    annotate("point", x = 8, y = 8, size = 20, pch = 1, color = "red")
```

### 

By running this command, we add a red circle where our predictions are most accurate (where x and y values are the same, which is where our predictions equal the true attitudes).

### Exercise 10

Copy the previous code, add another `annotate()` command. The first argument is `"point"`, set `x` equal 10, `y` equal 10, `size` equal 20, `pch` equal 1, and `color` equal "red". Setting `pch` equal 1 makes the inside of the point translucent to show the number of correct predictions. 

```{r comparing-models-in-theory-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-10-hint-1, eval = FALSE}
... + 
    annotate("point", x = 10, y = 10, size = 20, pch = 1, color = "red")
```

```{r comparing-models-in-theory-10-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) + 
    annotate("point", x = 8, y = 8, size = 20, pch = 1, color = "red") + 
    annotate("point", x = 10, y = 10, size = 20, pch = 1, color = "red")
```

### 

### Exercise 11

Finally, add `title`, `subtitle`, labels for `x` and `y`. Remember that your graph should look like this. 

```{r}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) +
    annotate("point", x = 8, y = 8, size = 20, pch = 1, color = "red") +
    annotate("point", x = 10, y = 10, size = 20, pch = 1, color = "red") +
    labs(title = "Modeling Attitude Toward Immigration",
         subtitle = "Liberals are less conservative",
         x = "Predicted Attitude",
         y = "True Attitude")
```

```{r comparing-models-in-theory-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-11-hint-1, eval = FALSE}
... + 
  labs(title = ...,
       subtitle = ..., 
       x = ..., 
       y = ...)
```

```{r comparing-models-in-theory-11-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_liberal)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) +
    annotate("point", x = 8, y = 8, size = 20, pch = 1, color = "red") +
    annotate("point", x = 10, y = 10, size = 20, pch = 1, color = "red") +
    labs(title = "Modeling Attitude Toward Immigration",
         subtitle = "Liberals are less conservative",
         x = "Predicted Attitude",
         y = "True Attitude")
```

### 

### Exercise 12

Consider another model, using `att_start` to forecast `att_end`. Pipe `trains` to `mutate()` with the argument `pred_liberal = fitted(fit_att_start)[,"Estimate"]`. 

```{r comparing-models-in-theory-12, exercise = TRUE}

```

```{r comparing-models-in-theory-12-hint-1, eval = FALSE}
... |> 
  mutate(... = fitted(...)[,"Estimate"])
```

```{r comparing-models-in-theory-12-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"])
```

### 

### Exercise 13

Copy the previous code, continue the pipe to `select()` and choose `pred_liberal` and `att_end` as the argument. 

```{r comparing-models-in-theory-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-13-hint-1, eval = FALSE}
... |> 
  select(pred_liberal, att_end)
```

```{r comparing-models-in-theory-13-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  select(pred_liberal, att_end)
```

### 

### Exercise 14

Copy your previous code in exercise 12, continue the pipe with `ggplot()`. Map `x` to `pred_liberal`, `y` to `att_end` in the `aes()` argument. This will return a plain graph with two axes. 

```{r comparing-models-in-theory-14, exercise = TRUE}

```

```{r comparing-models-in-theory-14-hint-1, eval = FALSE}
... |> 
  ggplot(...(x = ..., y = ...))
```

```{r comparing-models-in-theory-14-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end))
```

### 

### Exercise 15

Copy the previous code, add `geom_jitter()` as another layer. Set `width` equal 0.05, `height` equal 0.2, and `alpha` equal 0.5. 

```{r comparing-models-in-theory-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-15-hint-1, eval = FALSE}
... +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5)
```

```{r comparing-models-in-theory-15-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5)
```

### Exercise 16

Copy the previous code, add `geom_abline()` as another layer. Set `intercept` equal 0, `slope` equal 1, and `color` equal "red". This will insert a red line where our preductions are correct using `geom_abline()` with an intercept, slope and color.

```{r comparing-models-in-theory-16-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-16-hint, eval = FALSE}

```

```{r comparing-models-in-theory-16-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) + 
    geom_abline(intercept = 0, slope = 1, color = "red")
```

###

### Exercise 17

Finally, add `title`, `subtitle`, labels for `x` and `y` axes for your graph. Remember this is what your graph should look like. 

```{r}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) + 
  geom_abline(intercept = 0, slope = 1, color = "red") +
    labs(title = "Modeling Attitude Toward Immigration",
         subtitle = "Survey responses are somewhat consistent",
         x = "Predicted Attitude",
         y = "True Attitude")
```


```{r comparing-models-in-theory-17-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-17-hint, eval = FALSE}
... + 
  labs(title = ..., 
       subtitle = ...,
       x = ...,
       y = ...)
```

```{r comparing-models-in-theory-17-test, include = FALSE}
trains |> 
  mutate(pred_liberal = fitted(fit_att_start)[,"Estimate"]) |> 
  ggplot(aes(x = pred_liberal, y = att_end)) +
    geom_jitter(width = 0.05, height = 0.2, alpha = 0.5) + 
  geom_abline(intercept = 0, slope = 1, color = "red") +
    labs(title = "Modeling Attitude Toward Immigration",
         subtitle = "Survey responses are somewhat consistent",
         x = "Predicted Attitude",
         y = "True Attitude")
```

###

Rather than looking at individual cases, we need to look at the errors for all the predictions. Fortunately, a prediction error is the same thing as a residual, which is easy enough to calculate.

### Exercise 18

Pipe `trains` to `select()` with `att_end`, `att_start`, and `liberal`. 

```{r comparing-models-in-theory-18-ex, exercise = TRUE}

```

```{r comparing-models-in-theory-18-hint, eval = FALSE}
... |> 
  ...(..., ..., ...)
```

```{r comparing-models-in-theory-18-test, include = FALSE}
trains |> 
  select(att_end, att_start, liberal)
```

###

### Exercise 19

Continue the pipe with `mutate()`. Set `pred_lib` equal `fitted(fit_liberal)[,"Estimate"]` as the argument. 

```{r comparing-models-in-theory-19-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-19-hint, eval = FALSE}
... |> 
  mutate(... = fitted(...)[,"Estimate"])
```

```{r comparing-models-in-theory-19-test, include = FALSE}
trains |> 
  select(att_end, att_start, liberal) |> 
  mutate(pred_lib = fitted(fit_liberal)[,"Estimate"])
```

###

### Exercise 20

Add another column `resid_lib` equal `pred_lib - att_end` to the current tibble using the `mutate()` command. 

```{r comparing-models-in-theory-20-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-20-hint, eval = FALSE}
...|> 
  mutate(resid_lib = pred_lib - att_end)
```

```{r comparing-models-in-theory-20-test, include = FALSE}
trains |> 
  select(att_end, att_start, liberal) |> 
  mutate(pred_lib = fitted(fit_liberal)[,"Estimate"]) |> 
  mutate(resid_lib = pred_lib - att_end)
```

###

### Exercise 21


Continue the pipe with `mutate()`, create a new column called `pred_as` and set it equal to `fitted(fit_att_start)[,"Estimate"]`.

```{r comparing-models-in-theory-21-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-21-hint, eval = FALSE}
... |> 
  mutate(pred_as = fitted(fit_att_start)[,"Estimate"])
```

```{r comparing-models-in-theory-21-test, include = FALSE}
trains |> 
  select(att_end, att_start, liberal) |> 
  mutate(pred_lib = fitted(fit_liberal)[,"Estimate"]) |> 
  mutate(resid_lib = pred_lib - att_end) |> 
  mutate(pred_as = fitted(fit_att_start)[,"Estimate"])
```

###

### Exercise 22

Finally, calculate the residual when using `att_start` to forecast `att_end`. Using `mutate()`, add `resid_as` and set it equal to `pred_as - att_end`.

```{r comparing-models-in-theory-22-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-22-hint, eval = FALSE}

```

```{r comparing-models-in-theory-22-test, include = FALSE}
trains |> 
  select(att_end, att_start, liberal) |> 
  mutate(pred_lib = fitted(fit_liberal)[,"Estimate"]) |> 
  mutate(resid_lib = pred_lib - att_end) |> 
  mutate(pred_as = fitted(fit_att_start)[,"Estimate"]) |> 
  mutate(resid_as = pred_as - att_end)
```

###

### Exercise 23


```{r comparing-models-in-theory-23-ex, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r comparing-models-in-theory-23-hint, eval = FALSE}

```

```{r comparing-models-in-theory-23-test, include = FALSE}

```

###



## Comparing models in practice 
### 

### Exercise 1

First, we will familiarize ourselves with our first model, `fit_liberal`. Run `fixef()` on `fit_liberal` to print out the previous result. 

```{r comparing-models-in-practice-1, exercise = TRUE}

```

```{r comparing-models-in-practice-1-hint-1, eval = FALSE}
fixef(...)
```

```{r comparing-models-in-practice-1-test, include = FALSE}
fixef(fit_liberal)
```

### 

### Exercise 2

Now, we will perform `loo()` on our model and look at the results. Run the `loo()` command on `fit_liberal` and pipe the result to an object called `loo_liberal`.
Type `loo_liberal` in a separate line and hit "Run Code". 

```{r comparing-models-in-practice-2-ex, exercise = TRUE}

```

```{r comparing-models-in-practice-2-hint, eval = FALSE}
... <- loo(...)

loo_liberal
```

```{r comparing-models-in-practice-2-test, include = FALSE}
loo_liberal <- loo(fit_liberal)

loo_liberal
```

###

### Exercise 3

Let’s turn our attention to our second model. To begin, let’s observe the qualities of `fit_att_start` once again. Run `fixef()` on `fit_att_start` to print out the previous result. 

```{r comparing-models-in-practice-3-ex, exercise = TRUE}

```

```{r comparing-models-in-practice-3-hint, eval = FALSE}
fixef(...)
```

```{r comparing-models-in-practice-3-test, include = FALSE}
fixef(fit_att_start)
```

###

### Exercise 4

Great! Now, let’s perform `loo()` on this model. Run the `loo()` command on `fit_att_start` and pipe the result to an object called `loo_att_start`.
Type `loo_att_start` in a separate line and hit "Run Code". 

```{r comparing-models-in-practice-4-ex, exercise = TRUE}

```

```{r comparing-models-in-practice-4-hint, eval = FALSE}
... <- loo(...) 

loo_att_start
```

```{r comparing-models-in-practice-4-test, include = FALSE}
loo_att_start <- loo(fit_att_start) 

loo_att_start
```

###

The `elpd_loo` value for this model is higher than the `elpd_loo` for att_liberal, implying that this model is superior. However, we can’t see our estimates together. Is there a simpler way to calculate which model is better? 

### Exercise 5

To compare the two models directly, we can use the function `loo_compare` with our two `loo` objects created above. This will calculate the difference in `elpd_loo()` between our models for us, making our job easier. Run the command `loo_compare()` with `loo_att_start` and `loo_liberal` as the arguments. 

```{r comparing-models-in-practice-5-ex, exercise = TRUE}

```

```{r comparing-models-in-practice-5-hint, eval = FALSE}
loo_compare(..., ...)
```

```{r comparing-models-in-practice-5-test, include = FALSE}
loo_compare(loo_att_start, loo_liberal)
```

###

## Summary
### 

This tutorial covers [Chapter 7: Mechanics](https://ppbds.github.io/primer/mechanics.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 


### 

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
