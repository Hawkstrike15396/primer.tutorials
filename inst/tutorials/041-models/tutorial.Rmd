---
title: Models
author: David Kane and Sanaka Dash
tutorial:
  id: models
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 4 Tutorial: Models'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(gt)    # Need because library(gtsummary) does not load gt.
library(brms)
library(tidybayes)
library(gtsummary)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))


# fit_bern <- brm(formula = biden ~ 1,
#                 data = poll_data,
#                 family = bernoulli(),
#                 refresh = 0,
#                 silent = 2,
#                 seed = 12)
# write_rds(fit_bern, "data/fit_bern.rds")

fit_bern <- read_rds("data/fit_bern.rds")

population_table <- 
tibble(source = c("...", "...", "...","...",  
                  "Data", "Data", "Data", "Data", "...",
                  "...", "...", "...","...", 
                  "Preceptor Table", "Preceptor Table", "Preceptor Table", "...",
                  "...", "...", "..."),
       time = c("February 2024", "February 2024", "February 2024", "...",
                "March 2024", "March 2024", "March 2024", "March 2024", "...",
                "October 2024", "October 2024", "October 2024", "...",
                "November 2024", "November 2024", "November 2024", "...",
                "December 2024", "December 2024", "December 2024"),
       id = c("1", "200", "976", "...",
              "1", "200", "...", "1559", "...",
              "1", "200", "2025", "...",
              "1", "200", "2078", "...",
              "1", "200", "2300"),
       biden = c("?", "?", "?", "...",
              "0", "1", "...", "1", "...",
              "?", "?", "?", "...",
              "1", "0", "1", "...",
              "?", "?", "?")) |>
  gt() |>
  cols_label(source = md("Source"),
             time = md("Time"),
             id = md("ID"),
             biden = md("Biden")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())

ndata <- tibble(.rows = 1)

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- DK: This tutorial does not exactly follow the new template tutorial. Edit it to do so. -->

<!-- Some concerns that this is too long. -->

<!-- DK: Need more knowledge drops during Courage.  The Courage section of each chapter is the most complex because modeling is hard. Use opportunities for knowledge drops, like this one, judiciously.  -->

## Introduction
### 

This tutorial covers [Chapter 4: Models](https://ppbds.github.io/primer/models.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

In Chapter 3, we learned about sampling, the process of gathering data to answer our questions. In this chapter, we will learn about constructing models, creating the data generating mechanism (DGM) which we will use to answer our questions.

## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

The general question we are interested in is the future results of the 2024 election, as seen from a survey conducted March 2024.

Our specific question:

> *What proportion of all votes will be cast for Joe Biden in the 2024 election?*


### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Precisely describing the Preceptor Table for this problem is the first step in trying to solve it. 


### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "covariates," and "outcomes." 

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The way I like to think of it is that the units are the objects that are being affected (rows), while the outcome column is how the units are being affected.


### Exercise 4

Create a Github repo called `tutorial-4`. Connect it to an new R Project called `tutorial-4`. Edit the `.gitignore` file to ignore the Rproj file.

In the Console, run `show_file(".gitignore")`. CP/CR. Don't forget to run `library(tutorial.helpers)` if you get a "function not found" error message.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### Exercise 5

In this new R Project, create a new Quarto Document, naming it `models`. Now save the file as `models.qmd`. Note that the `.qmd` will be added automatically.

Type `show_file("models.qmd")` into the Console. CP/CR.

```{r wisdom-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 6

What are the units for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "The units are the individual voters.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that this is not all American adults or even all registered voters. To answer our question, we only need information about actual voters. Any other rows would be superfluous.

### Exercise 7

What is the outcome for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "The outcome is the candidate for whom the vote was cast.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Looking at the question, this formulation is too broad. We don't actually need to know the name of the candidate. We just need to know if the vote was cast for Biden or not. The name of the candidate, if it was not Biden, is irrelevant to our question. So, we can represent the outcome as 0 (did not vote for Biden) and 1 (did vote for Biden).

Realistically, then, this question only has 1 outcome. This means that the problem would be a predictive model.


### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "There is no treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

This is a predictive model, not a causal model, so there are no treatments, by definition. Recall that treatment is just a covariate which, given the question we are trying to answer, might at least in theory be manipulable.


### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "Just after Election Day, 2024",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Take note of the date of the Preceptor Table, as this will be different from our data. When working with multiple data sources, it's important to keep track of the date and how the information may be affected by it.


### Exercise 10

Describe in words what the Preceptor Table would look for this problem.

```{r wisdom-10}
question_text(NULL,
	message = "There is one row for each voter in the 2024 US presidential election. There is one output column indicating whether or not the voter voted for Biden (1) or not (0).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks like this:

```{r}
#| echo: false
tibble(voter_ID = c("1", "2", 
                   "...", "200", "201", "...", "2078", "2079", "..."),
       biden = c("0", "0", 
                   "...", "1", "0", "...", "1", "0", "...")) |>
  gt() |>
    tab_header(title = "Preceptor Table") |> 
    cols_label(voter_ID = "Voter ID",
               biden = "Voted for Biden") |>
    tab_style(cell_borders(sides = "right"),
              location = cells_body(columns = c(voter_ID))) |>
    cols_align(align = "center", columns = everything())
```

On the other hand, let's take a look at our data for today: 

The data we have came from a YouGov poll [pdf](https://github.com/PPBDS/primer/blob/master/sources/you-gov-2024-03-12.pdf) of 1,559 US adult citizens, conducted March 10 - 12, 2024. 


### Exercise 11

Run the following code to see what our data looks like in a data table.

```{r wisdom-11, exercise = TRUE}
#| echo: false
tibble(poll_ID = c("1", "2", 
                   "...", "200", "201", "...", "1,559"),
       biden = c("0", "0", 
                   "...", "1", "0", "...", "1")) |>
  gt() |>
    tab_header(title = "Polling Data") |> 
    cols_label(poll_ID = "Poll ID",
               biden = "Would Vote for Biden") |>
    tab_style(cell_borders(sides = "right"),
              location = cells_body(columns = c(poll_ID))) |>
    cols_align(align = "center", columns = everything())
```

```{r wisdom-11-test, include = FALSE}
#| echo: false
tibble(poll_ID = c("1", "2", 
                   "...", "200", "201", "...", "1,559"),
       biden = c("0", "0", 
                   "...", "1", "0", "...", "1")) |>
  gt() |>
    tab_header(title = "Polling Data") |> 
    cols_label(poll_ID = "Poll ID",
               biden = "Would Vote for Biden") |>
    tab_style(cell_borders(sides = "right"),
              location = cells_body(columns = c(poll_ID))) |>
    cols_align(align = "center", columns = everything())
```

### 

<!-- DK: This is better off as a separate question -->

There are key differences between our data table and our Preceptor Table:

1. Our Polling Data includes exactly 1,559 rows. We don’t know how many rows are in our Preceptor Table because we don’t know how many people will vote in November 2024.

2. The ID column is “Voter ID” in the Preceptor Table and “Poll ID” in the Polling Data. This means that Person 2 in the Data Table is not the same as Person 2 in the Preceptor Table.

3. The variable labels differ. “Voted for Biden” is not the same thing as “Would Vote for Biden.” 


### Exercise 12

Write one sentence describing the data you have to answer your question. 

In any question related to polling, you always want to include the name of the polling organization, the date and the number of individuals successfully contacted.


```{r wisdom-12}
question_text(NULL,
	message = "We have data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, indicating which respondents intend to vote for Joe Biden and which do not.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The question from the poll that we will be analyzing is:

*If an election for president were going to be held now and the Democratic nominee was Joe Biden and the Republican nominee was Donald Trump, would you vote for…*

The allowed choices are “Joe Biden,” “Donald Trump,” “Other,” “Not Sure,” and “I would not vote.” 


### Exercise 13

In your own words, define "validity" as the term is used in the *Primer*.

```{r wisdom-13}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

42% of those polled indicated Joe Biden. Although rounding makes it impossible to know for sure, we will assume that 655 of the 1,559 “US adult citizens” would vote for Biden. 


### Exercise 14

Provide one reason why the assumption of validity might not hold for this problem.


```{r wisdom-14}
question_text(NULL,
	message = "People sometimes don't vote for the person they claim they are going to vote for.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

What we tell other people we will do is often not what we actually do. Consider a voter who is embarrassed about her support for Biden. Perhaps she perceives the interviewer as a Republican and doesn't care to admit to him, in March, her support for Biden. But, in November, in the privacy of the polling booth, she votes for Biden. In her case, the outcome from the data (what she told the pollster) did not have a *valid* correspondence with her behavior in the polling booth.


### Exercise 15

*So what do we want to get out of this data?* 

In one or two sentences, make a statement to this question that consists of 2 parts: 
1) Where the data is from/collected
2) What we intend to do with the data

For the second part, start with something along the lines of "we seek to".

<!-- DK: Is this questions repeated twice? -->

```{r wisdom-15}
question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Justice
### 

*Justice is truth in action.* - Benjamin Disraeli


### Exercise 1

In your own words, name the four key components of Justice (without describing them) for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

<!-- DK: Add some knowledge drops. All of Justice is about concerns that you have, reasons why the model you create might not work as well as you hope. Drop knowledge/discussion as you see fit, but the central theme is *worries*. Connect some of the specific data discussion from Wisdom to these assumptions. -->


### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

Here is our Population Table:
```{r}
#| echo: false
population_table
```

Describe the Population Table for this problem. In particular, are any of the rows in the Preceptor Table also rows in the data? Are there other rows in the Population Table which are not from the Preceptor Table or the data? If so, describe some of those rows.

```{r justice-3}
question_text(NULL,
	message = "Each row in the Population Table corresponds to a person/date combination. None of the rows for the Preceptor Table and the data overlap. Rows from the overall population feature dates outside the survey dates and the election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Notice how, although the Population Table is helping us by adding data, the data that it's adding isn't doesn't convey validity, i.e. it is measuring a different metric (in this case the voters' opinions from different time periods). We don't know if the voters' opinions changed over that time period, making the data invalid.


### Exercise 4

In your own words, define the assumption of "stability" when employed in the context of data science.


```{r justice-4}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 5

Provide one reason why the assumption of stability might not be true in this case. (This is somewhat of a trick question.)

```{r justice-5}
question_text(NULL,
	message = "Our Population Table is so simple that stability is almost automatically true. There is only one column!",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability might become important as we think about the actual process by which we might meet the two voters in our original question, but, in terms of the Population Table itself, there is no problem.


### Exercise 6

In your own words, define the assumption of "representativeness" when employed in the context of data science.


```{r justice-6}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.


### Exercise 7

Provide one reason why the assumption of representativeness might not be true in this case.


```{r justice-7}
question_text(NULL,
	message = "One concern might involve the process by which YouGov sampled potential voters in March. If that process were flawed, if the people it sampled were systematically different than the people it did not, then the assumption of representativeness would fail. Imagine that YouGov only polled residents in Washington DC. That would be bad, even if everyone polled answered truthfully. We would end up with data which was much more pro-Biden than the country as a whole.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The assumption of representativeness is never completely true. We can only hope/assume that it is true enough that the inferences we draw from our data can be roughly applied to our question. Let’s assume that is this case.


### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. This assumption is only relevant for casual models.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true.



### Exercise 9

1. Copy your work from the end of the Wisdom section.

Modify your previous response to reflect the question we are trying to answer. Then, mention at least one specific problem which casts doubt on your approach. 

```{r justice-9}
question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. Biden’s popularity might change significantly over the course of the election campaign.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Courage
### 

*Courage is found in unlikely places.* - J.R.R. Tolkien


### Exercise 1

In your own words, describe Courage in data science.

```{r courage-1}
question_text(NULL,
	message = "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

The [**brms**](https://paul-buerkner.github.io/brms/) package provides a user-friendly interface to work with the statistical language [Stan](https://mc-stan.org/), the leading tool for Bayesian model building.

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

The [**tidybayes**](https://mjskay.github.io/tidybayes/) package aims to make it easy to integrate popular Bayesian modeling methods into a `tidy data + ggplot` workflow.

### Exercise 4

To learn about what the **tidybayes** package does, let's use the built-in help menu.

First, load in the **tidybayes** package into the Console.

Now, type `?tidybayes` into the Console. Copy/Paste the first paragraph under the Details section.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

<!-- TJ: I feel it would be better to ask them to summarize, that way they would not be just blindly copy and pasting -->

### Exercise 5

Before we move on, let's back up our work to our `models.qmd` file. Under your paragraph, create a new code chunk, and label it `startup`. Now type in the two `library()` commands from above, along with `library(tidyverse)`. 

<!-- TJ: I don't recall being instructed to copy and paste the paragraph -->
<!-- TJ: Also, what about cleaning the file? -->

Run `Command/Ctrl + Shift + K`.

Run `show_file("models.qmd", start = -6)` in the Console. CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 6

Notice how you both see the code and also get many error messages. To fix this, insert `#| message = false` and `#| warning = false` after your label in the code chunk. Also, add in `execute: echo = false` to your YAML Header (at the very top). 

Run `Command/Ctrl + Shift + K` and make sure that all you get is a clean document.

Run `show_file("models.qmd")` in the Console. CP/CR.

```{r courage-6}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 7

Run this code in order to generate the polling data.

```{r courage-7, exercise = TRUE}
poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))

slice_sample(poll_data, n = 10)
```

```{r courage-7-test, include = FALSE}
poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))

slice_sample(poll_data, n = 10)
```

### 

We don't care exactly who voted for Biden and who did not. In that sense, the rows of the data (and the Preceptor Table) are "exchangeable," which means (roughly) that nothing changes if we re-arrange the IDs of any of the rows.


### Exercise 8

Use `brm()` to fit a model. Use the arguments: `formula = biden ~ 1`, `data = poll_data`, `family = bernoulli()`, `refresh = 0`, `silent = 2`, and `seed = 9`.


```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
brm(formula = ...,
    ... = poll_data,
    family = bernoulli(),
    ... = 0,
    silent = ...,
    ... = 9)
```

```{r courage-8-test, include = FALSE}
brm(formula = biden ~ 1,
    data = poll_data,
    family = bernoulli(),
    refresh = 0,
    silent = 2,
    seed = 9)
```

<!-- TJ: There was no test chunk here, added one-->

This will take a little while to run. 

### 

An interesting thing to note in this model is the inclusion of `seed`. In computer science, a *seed* causes a random process to produce the same answer as long as the same seed is used. Fitting Bayesian models requires an algorithm which uses randomness. Running `brm()` twice will produce very slightly different answers, although the answers will not be substantively different enough to matter.

However, for teaching, we want your answer to be identical to ours. If we both use the same seed, it will be.


### Exercise 9

Behind the scenes, we have assigned the result of this call to `brm()` to a new object: `fit_bern`. Type `fit_bern` and hit "Run Code."

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
fit_bern
```

```{r courage-9-test, include = FALSE}
fit_bern
```

### 

Here's a way that you can understand the concept of `seed`:

If you played MineCraft as a kid, then it's the same concept here. If you load the same seed, it loads up the same world.


### Exercise 10

Run `family()` on `fit_bern`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
family(...)
```

```{r courage-10-test, include = FALSE}
family(fit_bern)
```

### 

`bernoulli()` indicates a Bernoulli distribution, which is a probability distribution for a random variable that has exactly two possible outcomes. It is used to model situations with binary outcomes, such as success/failure, yes/no, or true/false.


### Exercise 11

Run `formula()` on `fit_bern`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
formula(...)
```

```{r courage-11-test, include = FALSE}
formula(fit_bern)
```

### 

In this case, we have the simplest possible formula. `biden`, which is a zero/one binary variable is a function of a constant. There are no independent variables.


### Exercise 12

Run `nobs()` on `fit_bern`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-12-test, include = FALSE}
nobs(fit_bern)
```

<!-- ###  -->

<!-- DK: Knowledge drop. -->

### Exercise 13

Run `posterior_interval()` on `fit_bern`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-13-test, include = FALSE}
posterior_interval(fit_bern)
```

### 

There are several parameters in the model, almost all of them so-called "nuisance" parameters, meaning that we don't care about them. Their particular values don't really help us to directly calculate any quantity of interest.


### Exercise 14

Run `fixef()` on `fit_bern`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-14-test, include = FALSE}
fixef(fit_bern)
```

### 

The "Intercept" is the key part of the model. Because the family is Bernoulli and the link function an identity, the actual model we are estimating looks like:

$$ biden_i =  \mu + \epsilon_i $$

$y_i$ is the height of male $i$. $\mu$ is true proportion of Biden voters. $\epsilon_i$ is the "error term," the difference between the vote of person $i$ and the true proportion of Biden voters. The $\mu$, also called the "Intercept," is about 0.42. The value of `biden` is either `0` or `1`. So, the value of $\epsilon$ is either -0.42 or + 0.58. No other value is possible.


### Exercise 15

It would be a good idea for us to include this mathematical expression in our `models.qmd` file. So, add the following line at the bottom of the file (doesn't need to be in a code chunk): `$$ biden_i =  \mu + \epsilon_i $$`

Run `Command/Ctrl + Shift + K` to make sure that everything works.

Run `show_file("models.qmd", start = -3)` in the Console. CP/CR.

```{r courage-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

What you entered is $\LaTeX$ math. The "_" symbol causes what follows to be a subscript. The "\" symbol causes $\LaTeX$ to evaluate what follows as a special operator. In this case `\rho` generates the Greek letter $\rho$.

Note that in order to enter math in $\LaTeX$, the math has to be surrounded by `$$`.


### Exercise 16

Run `pp_check()` on `fit_bern` with the `type` argument set to `"bars"`.  The `pp_check()` runs a **p**osterior **p**redictive check.


```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
pp_check(...,  type = "...")
```

```{r courage-16-test, include = FALSE}
pp_check(fit_bern,  type = "bars")
```

### 

In this case, there are two possible outcomes: 0/1. The actual values in the data are labeled `y`. We use our fitted model, `fit_bern` to generate 10 alternate data sets, 10 "fake" data sets. What might the number of votes for (and not for) Biden look like if `fit_bern` is true. The graphic demonstrates that the fake data is very similar to the real data, thus suggesting that our model has captured reality, at least somewhat. 

If the fake data had looked very different from the real data, there is a problem with our model.


### Exercise 17

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-17, exercise = TRUE}

```

```{r courage-17-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-17-test, include = FALSE}
library(gtsummary)
```

### 

Read [this tutorial](https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html) for an introduction to `tbl_regression()`, the most important function in the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

### Exercise 18

Now be sure to add this package to your `models.qmd` file in the setup code chunk. Run `Command/Ctrl + Shift + K` to make sure that you don't get anything suspicious.

Run `show_file("models.qmd", start = 8)` in the Console. CP/CR.

```{r courage-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package includes many functions for formatting our table. The better your work looks, the more seriously people will take it.


### Exercise 19

Run `tbl_regression()` on `fit_bern` with `intercept = TRUE`. 


```{r courage-19, exercise = TRUE}

```

```{r courage-19-hint-1, eval = FALSE}
tbl_regression(..., intercept = ...)
```

```{r courage-19-test, include = FALSE}
tbl_regression(fit_bern, intercept = TRUE)
```

### 

**Estimate:** The estimated intercept is `-0.35`. In the context of a Bernoulli model, this is the log-odds of the outcome (support for Biden). To convert this to a probability, the baseline probability of support for Biden is approximately 41%. Also note the low **Standard Error* of `0.04`, indicating that this figure has relatively low variability.


### Exercise 20

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using. Then, add a sentence which tells us something about the model.

```{r courage-20}
question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. Biden’s popularity might change significantly over the course of the election campaign. In the poll, Biden’s support was much less than 50%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

**95% Credible Interval:** The credible interval ranges from -0.43 to -0.27. This means that with 95% probability, the true log-odds of support for Biden lies within this range. Converting these bounds to probabilities, we would have a 95% credible interval for the probability of support for Biden of approximately 39% to 43%.


## Temperance
### 

<!-- XX: Discuss newdata objects slowly. "A newdata tibble must include columns for all the right-hand side variables --- all the "covariates" --- in the model, and with all the same variable names and, mostly, variable types" - DONE

First ask a question about which columns are needed in the newdata object. This might just be a written question. The answer is all the variables which are on the rightside of the formula. - DONE

Second, ask a question about which values you want those variables to have. That is not easy! Again, a written answer. For each row in the newdata tibble, you get a new posterior. How many posteriors do you want? 

Third, give them the R code which creates the newdata object. All they need to do is run it. Asking them to create it, even after you help them figure out the columns (question 1) and rows (question 2) is too hard, at least until they get more experiences. - DONE

Fourth, inform them that you have, behind the scenes (which really means the setup code chunk), already assigned this tibble to the `ndata` object. In this question, they just type `ndata` to confirm. - DONE

The knowledge drops for all four of these questions allow you to explain/teach more about what goes in the argument for newdata and what does not. Explaining what other newdata objects would produce, if we used them, is a good idea.

-->

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha


### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- Drop knowledge -->


### Exercise 2

Let's understand what a `newdata` tibble is. A `newdata` tibble must include columns for all the right-hand side variables --- all the "covariates" --- in the model, and with all the same variable names and, mostly, variable types.

Based on this, which columns should we include in the `newdata` object?

```{r temperance-2}
question_text(NULL,
	message = "all the variables which are on the right side of the formula",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

Now let's create the `newdata` tibble. Run the code in the box to make sure it works.

```{r temperance-3, exercise = TRUE}
newdata = tibble(.rows = 1)
```

```{r temperance-3-test, include = FALSE}
newdata = tibble(.rows = 1)
```

### Exercise 4

Behind the scenes, this tibble has already been assigned to us as `ndata`. Type this into the box below to make sure that it works.

```{r temperance-4, exercise = TRUE}

```

```{r temperance-4-hint-1, eval = FALSE}
ndata
```

```{r temperance-4-test, include = FALSE}
ndata
```

### Exercise 5

Recall the question that we were answering:

> What proportion of all votes will be cast for Joe Biden in the 2024 election?

Let's make a graph to answer this question.

Start by piping `fit_bern` to `add_epred_draws()`, with `ndata` being the argument. Now continue the pipe to `select()`, selecting `.epred` as the argument.

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
... |> 
  add_epred_draws(...) |> 
  ...(.epred) |> 
```

```{r temperance-5-test, include = FALSE}
fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred)
```

### 

It's crucial to understand the value of the `add_epred_draws()` function. For starters, it generates a series of predicted values from the posterior distribution for the new data. These predictions represent the distribution of the intercept's expected value.


### Exercise 6

Now continue the pipe to `ggplot()`, setting `x` to `.epred` inside of the aesthetics. 

```{r temperance-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-6-hint-1, eval = FALSE}
... |>
  ggplot(...(x = ...))
```

```{r temperance-6-test, include = FALSE}
fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred) |> 
  ggplot(aes(x = .epred))
```

This will create a blank plot because we didn't add anything yet.

### 

The function `add_epred_draws()` is so powerful because, unlike `add_predicted_draws()`, it doesn't factor in any additional randomness of individual observations. Essentially, it assumes that the data was recorded absolutely perfectly, and therefore gwnerates a model that represents a picture-perfect scenario.


### Exercise 7

Let's add `geom_density()`, setting `y` to `after_stat(count/sum(count))` inside of aesthetics. Remember to add `geom_density()` with a `+` instead of a `|>`!

```{r temperance-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-7-hint-1, eval = FALSE}
... +
  geom_density(aes(y = after_stat(count/sum(count))))
```

```{r temperance-7-test, include = FALSE}
fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred) |> 
  ggplot(aes(x = .epred)) +
    geom_density(aes(y = after_stat(count/sum(count))))
```

### 

By setting `y = after_stat(count / sum(count))`, the density plot is normalized such that the total area under the curve is equal to 1. This makes it easier to interpret the plot as a probability distribution.

The y-axis now represents the proportion of the total observations that fall within each bin, which is useful for visualizing the distribution of the expected predictions.


### Exercise 8

It would also be a good idea to include `scale_x_continuous(labels = scales::percent_format())` and `scale_y_continuous(labels = scales::percent_format())`. Remember to also add these with a `+` rather than a `|>`. 

```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}
... +
 ...(labels = ...::percent_format()) +
 scale_y_continuous(... = scales::...())
```

```{r temperance-8-test, include = FALSE}
fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred) |> 
  ggplot(aes(x = .epred)) +
    geom_density(aes(y = after_stat(count/sum(count))))  +
    scale_x_continuous(labels = scales::percent_format()) +
    scale_y_continuous(labels = scales::percent_format())
```

### 

The `scale_x_continous` (and its `y` version) modify the values on that scale (`x` or `y`).

The argument `labels = scales::percent_format()` ensures that the values are in `%` format.


### Exercise 9

Finish it off by adding labels for the title, subtitle, and the axis using `labs()`. 

```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}
... +
 labs(...)
```

```{r temperance-9-test, include = FALSE}
fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred) |> 
  ggplot(aes(x = .epred)) +
    geom_density(aes(y = after_stat(count/sum(count))))  +
    labs(title = expression(paste("Posterior Distribution for  ", rho)),
         subtitle = "There is a 95% chance for a value between XX and XX.",
         x = expression(paste("Proportion, ", rho, ", of Red Beads in Urn")),
         y = "Probability") +
    scale_x_continuous(labels = scales::percent_format()) +
    scale_y_continuous(labels = scales::percent_format())
```

Your finished graph should look something like this:

```{r}
#| echo: false
#| warning: false

fit_bern |> 
  add_epred_draws(newdata = ndata) |> 
  select(.epred) |> 
  ggplot(aes(x = .epred)) +
    geom_density(aes(y = after_stat(count/sum(count))))  +
    labs(title = expression(paste("Posterior Distribution for  ", rho)),
         subtitle = "There is a 95% chance for a value between XX and XX.",
         x = expression(paste("Proportion, ", rho, ", of Red Beads in Urn")),
         y = "Probability") +
    scale_x_continuous(labels = scales::percent_format()) +
    scale_y_continuous(labels = scales::percent_format())
```

### 

Now add this graph to the bottom of your `models.qmd` file. We'll be checking the file itself (later!) rather than making you use `show_file()`.


### Exercise 10

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI. 

```{r temperance-10}
question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. Biden’s popularity might change significantly over the course of the election campaign. In the poll, Biden’s support was much less than 50%. We estimate that Biden’s percentage of the vote in Election Day will be about 42%, plus or minus 2.5%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 11

Now add this paragraph to the end of your `models.qmd` document.

Remember to `Command/Ctrl + Shift + K` every time you make a change to the file.

Run `show_file("models.qmd", start = 7)` in the Console. CP/CR.

```{r temperance-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 12

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 13

Rearrange the material in `models.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

<!-- TJ: Don't recall being told to add the table to the file -->
<!-- TJ: Also need to add fitted model -->

At the Console, run:

```
tutorial.helpers::show_file("models.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

## Summary
### 

This tutorial covered [Chapter 4: Models](https://ppbds.github.io/primer/models.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
