---
title: Two Parameters
author: David Kane and Mihir Kaushal
tutorial:
  id: two-parameters
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 5 Tutorial: Two Parameters'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)
library(skimr)
library(primer.data)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

ch5 <- nhanes |>
  filter(sex == "Male", age >= 18) |>
  select(height) |>
  drop_na()

# fit_male_height <- brm(formula = height ~ 1,
#              data = ch5,
#              family = gaussian(),
#              silent = 2,
#              refresh = 0,
#              seed = 12)
# 
# write_rds(fit_male_height, "data/fit_male_height.rds")

fit_male_height <- read_rds("data/fit_male_height.rds")

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- This is the template tutorial for creating any tutorial which uses the Cardinal Virtues to answer a question given a data set. Although its primary use is for the main chapters in the Primer, it could be used for other assignments as well. The letters `XX` are used to indicate locations which require editing. Comments with instructions are interspersed. Read https://ppbds.github.io/primer/key-concepts.html for details on the Cardinal Virtues. -->

<!-- There should be a bunch of quotes for each Cardinal Virtue. All quotes are listed at the introduction of each section. Select just one for each virtue in this tutorial. -->

<!-- There are many opportunities for knowledge drops, especially after definition questions. Use them! Point out something about the details of the particular problem from the chapter. Recall that students often won't read the chapter, so we need to pull out the highlights. -->

<!-- The more that questions force students to consult the chapter, the better. -->

<!-- Key problems with current version: We need (?) to flesh out the Courage and Temperance sections. Key skills to practice each time including writing math formulas in Quarto and creating nice looking tables of regression results. -->

## Introduction
### 

This tutorial covers [Chapter 5: Two Parameters](https://ppbds.github.io/primer/two-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/).

In this chapter, we have **two** unknown parameters: the mean $\mu$ height in the US and the standard deviation, $\sigma$, of the normally distributed error term.

The reason for making models is not, primarily, that making models is fun -- although it is! The reason is that the world confronts us. Make decisions we must. We must decide between options X or Y. We must choose from actions A, B and C. Confronted by a choice, we need to make a model of the world to help us choose wisely.

The real world is complex. Any substantive decision problem includes a great deal of complexity and requires even more context. We do not have the time to get into that level of detail now. So, we simplify. We are going to create a model of height for adult men. We will then use that model to answer the following question:

* What is the probability that the next man we meet will be taller than 180 centimeters?

The hope for this tutorial is that, by answering this question, we'll gain a better and more thorough understanding of how professionals do data science.

## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Wisdom begins with the Preceptor Table. What data would we, ideally, require to answer our questions? We then explore the data that we actually have. We apply the concept of validity to ensure that the data we want and the data we have are similar enough to allow the latter to inform us about the former.

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A Preceptor Table has rows and columns of data such that, if you had them all, the calculation of the quantity of interest would be trivial.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table includes: Units, Outcome, Treatment, Causal or predictive model, Covariates, and Moment in Time (This is often implicit in the question itself).

### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "All the men in the world, one row per man.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The rows of the Preceptor Table are the units, the objects on which the outcome is measured.

### Exercise 5

What is the outcome for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "This is the variable which we are trying to explain/understand/predict. This is not the same thing as the answer to the question we have been asked. The question might, as above, be about the probability that the next man we meet will be taller than 180 centimeters. But the concepts of 100 do not appear in the Preceptor Table. Instead, height is our outcome variable. But, if we can build a model which explains/understands/predicts height, we can use that model to answer our questions.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Outcome is the variable we are trying to predict/understand/influence.

### Exercise 6

What are the covariates for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "There are no (explicit) covariates in this model, although we will need to make use of variables like age and sex to construct our sample data.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When we are looking at a “category” of units we call this a covariate. Possible covariates include, but are not limited to, sex, age, political party and almost everything else which might be associated with our data.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "There are not treatment variables.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Treatment is the thing that we are trying to see the effect of. This data has no treatment which means we cannot create a causal inference. 

### Exercise 8

What moment in time does the Preceptor Table refer to?

```{r wisdom-8}
question_text(NULL,
	message = "Now.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is often implicit in the question itself. One of our key roles as data scientists is to clarify the questions which we are asked. In this case, it seems clear that the questions refer to now, the present moment.

### Exercise 9

Write one sentence describing the data you have to answer your question.

```{r wisdom-9}
question_text(NULL,
	message = "The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Some variables of interest are age, sex and height. We will look at these more in depth later on.

### Exercise 10

Let's load the important packages.

Load the **tidyverse** package.

```{r wisdom-10, exercise = TRUE}

```

```{r wisdom-10-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-10-test, include = FALSE}
library(tidyverse)
```

### 

So, what does our Preceptor Table look like? Assuming we are predicting height for every adult male on Earth at this moment in time, we would have height data for every male at least 18 years of age. This means that we would have about 4 billion rows, one for each male, along with a column for each individual’s height.

### Exercise 11

Load the **primer.data** package.

```{r wisdom-11, exercise = TRUE}

```

```{r wisdom-11-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-11-test, include = FALSE}
library(primer.data)
```

### 

This Preceptor Table would extend all the way until person 4 billion-and-something. If we had this table, all of our questions could be answered with simple math and/or simulations. No inference is necessary if we have a Preceptor Table.

### Exercise 12

Load the **skimr** package.

```{r wisdom-12, exercise = TRUE}

```

```{r wisdom-12-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-12-test, include = FALSE}
library(skimr)
```

### 

But what does our actual data look like? We will now start playing around with the data. Before that, let's practice creating and publish a quarto document to answer the question we have in a professional way. Professional data scientists always store their work somewhere safe. This is so you don't lose your code even if something happens to your computer. 

### Exercise 13

Create a Github repo called `two-parameters`. Make sure to click the "Add a README file" check box. Copy/paste the URL for its Github location.

```{r wisdom-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look something like:

```         
https://github.com/MihirKaushal/two-parameters.git
```

### Exercise 14

Connect the `two-parameters` Github repo to an R project on your computer. Name the R project `two-parameters` also. 

In the Console, run:

````
list.files()
````

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- Add knowledge drop XX -->

### Exercise 15

Select `File -> New File -> Quarto Document ...`. Provide a title ("Two Parameters") and an author (you). Save the document as `analysis.qmd`. 

In the Console, run:

````
list.files(all.files = TRUE)
````

CP/CR.

The `all.files = TRUE` argument for `list.files()` generates all the files/directories, including the "hidden" ones whose names begin with a period, `.`. 

```{r wisdom-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 16

Edit the `.gitignore` by adding `*Rproj`. Edit the `.gitignore` by adding `*_files`.

In the Console, run:

````
tutorial.helpers::show_file(".gitignore")
````

CP/CR.

```{r wisdom-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `analysis.qmd` and save the file.

### Exercise 17

Add a new code chunk, load the **tidyverse** and **primer.data** packages. Render the file, this will automatically save the file as well. In the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r wisdom-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 18

Add `#| echo: FALSE` to prevent repeating the code in the preview. Instead of adding this in every code chunk, we can add this in the YAML header: 

```
execute: 
  echo: false
```

Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", start = 5)
```

```{r wisdom-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 19

Edit the `.gitignore` by adding `*_files`.

In the Console, run:

````
tutorial.helpers::show_file(".gitignore")
````

CP/CR.

```{r wisdom-19}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We will continue to add more to this qmd file. For now, let's shift our focus back on the `nhanes` data. 

### Exercise 20

Run `glimpse()` on `nhanes`.

```{r wisdom-20, exercise = TRUE}
    
```

```{r wisdom-20-hint-1, eval = FALSE}
glimpse(nhanes)
```

```{r wisdom-20-test, include = FALSE}
glimpse(nhanes)
```

### 

The `nhanes` data set includes 15 variables, including physical attributes like weight and height. Let’s restrict our attention to three variables: age, sex and height.

### Exercise 21

Pipe `nhanes` to `select()` with `age`, `sex`, and `height` as parameters.

```{r wisdom-21, exercise = TRUE}
    
```

```{r wisdom-21-hint-1, eval = FALSE}
nhanes |> 
  select(...)
```

```{r wisdom-21-test, include = FALSE}
nhanes |> 
  select(age, sex, height)
```

### 

We can notice some observations about the data: younger people generally are shorter, the heights of men is greater than the heights of woman. Keep in mind that we only care about males who are 18 or older for our project. 

### Exercise 22

Continue the pipe and examine a random sample using `slice_sample()` and setting `n = 5`.

```{r wisdom-22, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-22-hint-1, eval = FALSE}
... |> 
  slice_sample(...)
```

```{r wisdom-22-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  slice_sample(n = 5)
```

### 

We think of both age and height as numbers. And they are numbers! But R distinguishes between “integers” and “doubles,” only the second of which allow for decimal values. In the nhanes data, age is an integer and height is a double.

### Exercise 23

Delete `slice_sample()` and instead use `glimpse()`.

```{r wisdom-23, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-23-hint-1, eval = FALSE}
... |> 
  glimpse()
```

```{r wisdom-23-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  glimpse()
```

### 

Be on the lookout for anything suspicious. Are there any NA’s in your data? What types of data are the columns, i.e. why is age characterized as integer instead of double? Are there more females than males?

### Exercise 24

In addition to `glimpse()`, we can run `skim()`, from the `skimr()` package, to calculate summary statistics. Delete `glimpse()` and instead use `skim()`.

```{r wisdom-24, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-24-hint-1, eval = FALSE}
... |> 
  skim()
```

```{r wisdom-24-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  skim()
```

### 

Interesting! There are 353 missing values of height in our subset of data. Just using `glimpse()` does not show us that. Let’s filter out the NA’s using `drop_na()`. This will delete the rows in which the value of any variable is missing. Because we want to examine height in men (not boys, nor females), let’s limit our data to only include adult males.

### Exercise 25

Pipe `nhanes` to `filter()`, making sure to only have *adult men*. Then, continue the pipe to `select()` to only the `height` and then finally drop the NA's using `drop_na()`.

```{r wisdom-25, exercise = TRUE}
    
```

```{r wisdom-25-hint-1, eval = FALSE}
nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(...) |> 
  drop_na()
```

```{r wisdom-25-test, include = FALSE}
nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(height) |> 
  drop_na()
```

### 

Now that we have the clean data, let’s make a plot using `geom_histogram()`.

### Exercise 26

Pipe the previous code to `ggplot()`, with `height` in `x` axis in the `aes()`. Add `geom_histogram()` with `bins = 50` and then finally add `labs()` layer with the `title`, `x` and `y` axis title, and a `caption`.

```{r wisdom-26, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-26-hint-1, eval = FALSE}
... |>
  ggplot(aes(...)) + 
    geom_histogram(...) +
    labs(...)
```

This is what the finished graph should look like:

```{r}
nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(height) |> 
  drop_na() |>
  ggplot(aes(x = height)) + 
    geom_histogram(bins = 50) +
    labs(title = "Male Adult Height in the US in 2010",
         x = "Height (cm)",
         y = "Count",
         caption = "Source: National Health and Nutrition Examination Survey"
         ) 
```

### 

Will the data we have — which is only for a sample of adult American men more than a decade ago — allow us to answer our questions, however roughly? Only if the assumption of validity makes sense.

### Exercise 27

Now update your quarto document. Copy your code from above and put it in a new code chunk in the `analysis.qmd` file. In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

```{r wisdom-27}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 28

In your own words, define "validity" as we use the term.

```{r wisdom-28}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other.

### Exercise 29

What can't we do if the assumption of validity is not true?

```{r wisdom-29}
question_text(NULL,
	message = "We can't combine the Preceptor Table and the data in order to construct the Population Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity, if true (or at least reasonable), allows us to construct the Population Table. So if validity is not true, then we cannot construct the Population Table.

### Exercise 30

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-30}
question_text(NULL,
	message = "We need to be careful about mistakes like measurement units, like centimeters in one and inches in the other. And there can be issues like: Are measurements taken with shoes on or shoes off?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There are several reasons why this data might not be valid, such as inaccurate measurements. But, for the most part, the “height” variable in NHANES in 2010 is a valid proxy for the “height” of individuals today. We can stack the two data sets together and consider them to have come from the same population.

### Exercise 31

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer.

```{r wisdom-31}
question_text(NULL,
	message = "Using The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height, we seek to create a model of height for adult men.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We still haven't answered our main question:

What is the probability that the next man we meet will be taller than 180 centimeters?

## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The mathematical structure of the Data Generating Mechanism. Models require math, so we need to create a mathematical formula which connects our outcome to our covariates.

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table, a structure which includes a row for every unit in the population. We generally break the rows in the Population Table into three categories: the data for units we want to have (the Preceptor Table), the data for units which we actually have (our actual data), and the data for units we do not care about (the rest of the population, not included in the data or the Preceptor Table).

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

*The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes.* 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

<!-- DK: Change this answer. -->

<!-- MK: is this better? --> 

```{r justice-4}
question_text(NULL,
	message = "There might have been an outside factor that changed the height of male adults in America from 2009 to 2011. One possible reason may be the increase in immigrants who have a different average adult male height. This will change the overall average adult male height in America.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The actual data comes from a study conducted on males in 2009-2011. Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship at the time the data was gathered the same as the relationship at the time references by the Preceptor Table?

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Reprentativeness looks within time periods.

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Since participation in the survey is voluntary, it could mean that, for example, taller men are more likely to answer this question.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

It is important that our data is accurately reflecting the population whom we want to measure. Our data might underrepresent people who do not want to participate in the study for various reasons. If these people have a different average height compared to the overall average, then the lack of their participation will impact our data. 

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. Our current data is not being used for a causal model so this assumption does not matter as much as the other ones. 

### Exercise 8

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention at least one specific problem which casts doubt on your approach.

<!-- DK: Rework. Use Key Concepts as an example. -->

<!-- MK: is this better? --> 

```{r justice-8}
question_text(NULL,
	message = "Using The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height, we seek to create a model of height for adult men. We use the Population Table, which includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

## Courage
### 

*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe

<!-- Questions about models, tests, and the DGM. -->

### Exercise 1

<!-- DK: Not sure I like this answer. -->

In your own words, name the key goal of Courage and the process we use to get there.

```{r courage-1}
question_text(NULL,
	message = "Courage selects the data generating mechanism. We first specify the mathematical formula which connects the outcome variable we are interested in with the other data that we have. We explore different models. We need to decide which variables to include and to estimate the values of unknown parameters. We check our models for consistency with the data we have. We avoid hypothesis tests. We select one model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In data science, we deal with words, math, and code, but the most important of these is code. We need Courage to create the model, to take the leap of faith that we can make our ideas real.

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

For this section, we use a simple linear model:

$$ y_i =  \mu + \epsilon_i $$

with $\epsilon_i \sim N(0, \sigma^2)$. $y_i$ is the height of male $i$. $\mu$ is the average height of all males in the population. $\epsilon_i$ is the "error term," the difference between the height of male $i$ and the average height of all males. $\epsilon_i$ is normally distributed with a mean of 0 and a standard deviation of $\sigma$. 

This is the simplest model we can construct. The model has two unknown parameters: $\mu$ and $\sigma$. 

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

The parameter we most care about is $\mu$. That is the parameter with a substantively meaningful interpretation. Not only is the meaning of $\sigma$ difficult to describe, we also don't particular care about its value. Parameters like $\sigma$ in this context are *nuisance* or *auxiliary* parameters. We still estimate their posterior distributions, but we don't really care what those posteriors look like.

<!-- XX: Might need an exercise which gets/creates/cleans the data you need for fitting the model. -->

### Exercise 4

Update the `analysis.qmd` file. In the code chunk with the other libraries, load the **tidybayes** and **brms** packages. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", pattern = "tidybayes|brms")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments are `formula = height ~ 1`, `data = ch5`, `family = gaussian()`, `silent = 2`, `refresh = 0`, and `seed = 12`.

Assign the result to an object called `fit_male_height`.

<!-- Do not forget to create this model yourself in the setup chunk. Do this once, save the object, comment out that code and then just read_rds to create the object for this tutorial. -->

<!-- Depending on code speed, you can run this function multiple times, without assigning the return value, looking at the printout, and seeing how things change. -->

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
fit_male_height <- brm(...)
```

### 

Note:

* There is a direct connection between the mathematical form of the model created under Justice and the code we use to fit the model under Courage. `height ~ 1` is the code equivalent of $y_i =  \mu$. 

* There are several ways to examine the fitted model. The simplest is to print it. Recall that just typing `x` at the prompt is the same as writing `print(x)`.

### Exercise 6

Update the `analysis.qmd` file. Copy the code from above and put it in the qmd file. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r courage-6}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 7

Type `fit_male_height` and hit "Run Code." This generates the same results as using `print(fit_male_height)`.

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
print(...)
```

```{r courage-7-test, include = FALSE}
print(fit_male_height)
```

### 

Note:

* We will be looking at this print out many times in the rest of the *Primer*. You will get used to it. The header information about Family, Links and so on just confirms what we already know. Still, you want to check this to make sure you did not make a mistake in the call to `brm()`.

* The "Estimate" of 175.87 makes sense. After all, the simple mean of the `height` in the data is:


```{r}
#| code-fold: false
mean(ch5$height)
```

### Exercise 8

Run `family()` on `fit_male_height`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable.

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
family(...)
```

```{r courage-8-test, include = FALSE}
family(fit_male_height)
```

### 

In this case, setting `family = gaussian()` implies that $\epsilon_i \sim N(0, \sigma^2)$, just as we assumed. That is not a coincidence! If $\epsilon_i$ had a different distribution, we would need to use a different statistical family. 

### Exercise 9

Run `formula()` on `fit_male_height`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s).

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
formula(...)
```

```{r courage-9-test, include = FALSE}
formula(fit_male_height)
```

### 

In this case, the key parameter is the "Intercept," which is the same thing as $\mu$ in the mathematical description of the model and the same thing as `1` when we set `formula = height ~ 1`. In other words, we are speaking three languages here: English ("Intercept"), math (\$mu$), and code (`height ~ 1`). But all three languages are referring to the same underlying concept.

### Exercise 10

Run `nobs()` on `fit_male_height`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-10-test, include = FALSE}
nobs(fit_male_height)
```

### 

<!-- XX -->

The output should be 3658. This is the number of observations or, in other words, it is the number of rows.

### Exercise 11

Run `posterior_interval()` on `fit_male_height`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-11-test, include = FALSE}
posterior_interval(fit_male_height)
```

### 

$\mu$ is not the average height of the men in the sample. We can calculate that directly. It is `r mean(ch5$height)`. Instead, $\mu$ is the average height of men in the *population*. Recall that the population is the universe of people/units/whatever about which we seek to draw conclusions. On some level, this seems simple. On a deeper level, it is very subtle. Each case is a different and the details matter.

$\sigma$ is an estimate for the standard deviation of the errors,  i.e., variability in height after accounting for the mean. 

### Exercise 12

Run `fixef()` on `fit_male_height`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-12-test, include = FALSE}
fixef(fit_male_height)
```

### 

If a parameter’s estimated value is more than 2 or 3 standard errors away from zero, we generally keep that parameter (and its associated variable) in the model. This is, probably, a variable which “matters.” The main exception to this rule is a parameter whose value is so close to zero that changes in its associated variable, within the general range of that variable, can’t change the value of the outcome by much.

<!-- DK: Consider adding questions about conditional_effects(), ranef() and other commands, if relevant. -->

### Exercise 13

Run `pp_check()` on `fit_male_height`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-13-test, include = FALSE}
pp_check(fit_male_height)
```

### 

In this case, note how similar our actual data, $y$, is to the 10 versions of the replicated data, $y_rep$. They are close enough that we are happy to use `fit_male_height`. However, the match is not perfect! The actual data is slightly more "peaked" and also features some weird bumps in the tails, especially around 200 cm. It would be possible, but not easy, to modify our model to match the actual data more closely. For now, we will just accept `fit_male_height` as our data generating mechanism.

<!-- If the fake data had looked very different from the real data, we have had a problem. But, for the most part, we conclude that, although not perfect, pp_check() shows that the fake outcomes generated by our model are like the actual outcome data. -->

### Exercise 14

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package. *Remember to do the same in the* `analysis.qmd` *file.*

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-14-test, include = FALSE}
library(gtsummary)
```

### 

We modeled `height`, a continuous variable measured in centimeters, as a linear function of a constant term. The average adult male height in the US was around 176 cm. Mathematically:

$$ height_i =  176 + \epsilon_i $$

with $\epsilon_i \sim N(0, 0.75^2)$.

### Exercise 15

<!-- DK: Fix this. -->

Run `tbl_regression()` on `fit_male_height` and set `intercept` equal to `TRUE` inside `tbl_regression()`.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
tbl_regression(...)
```

```{r courage-15-test, include = FALSE}
fit_male_height |> 
  tbl_regression(intercept = TRUE)
```

### 

This is what the table should look like:

```{r}
fit_male_height |> 
  tbl_regression(intercept = TRUE)
```

We can see some important numbers from our data in this table, such as the average height of 176 cm.

### Exercise 16

Update the `analysis.qmd` file. Copy the code from above and put it in the qmd file. 

Again, don't forget to add the **gtsummary** package in the qmd file. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r courage-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 17

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add at least one sentence which describes the modelling approach which you are using, specifying at least the functional form and the dependent variable. Add at least one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

<!-- XX change to make more understandable by ALL (for all summaries)-->

```{r courage-17}
question_text(NULL,
	message = "Using The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height, we seek to create a model of height for adult men. We use the Population Table, which includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn. We have used a simple linear model to model the average male height and we can calculate some important numbers from our data, such as the average height of 176 cm.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha 

### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance guides us in the use of the data generating mechanism --- or the 'model' ---  we have created to answer the questions with which we began. We create posteriors for the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

Recall the task with which we began:

Create a model of height for adult men to answer the question:

What is the probability that the next man we meet will be taller than 180 centimeters?

Pipe `fit_male_height` to `add_predicted_draws()`. Inside, have `newdata` set to `tibble()`. Have parameter `.rows = 1` inside `tibble()`.

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
fit_male_height |> 
  add_predicted_draws(...)
```

```{r temperance-2-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = tibble(.rows = 1))
```

### 

There are two fundamentally different kinds of unknowns which we care about: expected values and predicted values. With the latter, the relevant function is `add_predicted_draws()`. 

### Exercise 3

Continue the pipe to `mutate()`. Inside, have `tall` set to `if_else()`. Have parameters `.prediction > 180, TRUE, FALSE` inside `if_else()`.

```{r temperance-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-3-hint-1, eval = FALSE}
... |> 
  mutate(...)
```

```{r temperance-3-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = tibble(.rows = 1)) |> 
  mutate(tall = if_else(.prediction > 180, TRUE, FALSE))
```

### 

Again, the key conceptual difficulty is the population. Now that we have created a model, we look to the virtue of Temperance for guidance in using that model. The data we have is never a perfect match for the world we face. We need to temper our confidence and act with humility. Our forecasts will never be as good as a naive use of the model might suggest. Reality will surprise us. We need to take the model’s claims with a family-sized portion of salt.

### Exercise 4

Finish up the pipe with `summarize()`. Inside, have `odds` set to `mean()` with parameter `tall`.

```{r temperance-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-4-hint-1, eval = FALSE}
... |> 
  summarize(...)
```

```{r temperance-4-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = tibble(.rows = 1)) |> 
  mutate(tall = if_else(.prediction > 180, TRUE, FALSE)) |>
  summarize(odds = mean(tall))
```

### 

If 30% or so of the draws from the posterior probability distribution are greater than 180 cm, then there is about a 30% chance that the next individual will be taller than 180 cm.

### Exercise 5

Add the code from above to the `analysis.qmd` file. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", end = 5)
```

CP/CR.

```{r temperance-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX -->

### Exercise 6

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.

<!-- XX change to make more understandable by ALL (for all summaries)-->

```{r temperance-6}
question_text(NULL,
	message = "Using The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height, we to created a model of height for adult men. We used the Population Table, which includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn. We used a simple linear model to model the average male height and we can calculate some important numbers from our data, such as the average height of 176 cm. Finaly, we used our data to answer our question about adult male heights.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Revise your answer to make it better and then add it to the `analysis.qmd` file. Don't just copy and paste the given example. 

### Exercise 7

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval.

```{r temperance-7}
question_text(NULL,
	message = "When answering questions as we have been, it can be easy to falsely believe that we are delivering the truth. This is not the case. This is because a lot of the assumptions we make during the process of building a model, the processes in Wisdom, are subject to error. Perhaps our data did not match the future as well as we had hoped. Ultimately, we try to account for our uncertainty in our estimates. Even with this safeguard, we aren’t surprised if we are a bit off.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX -->

### Exercise 8

Now that you are done with the qmd file, show the `analysis.qmd` file. 

In the console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

```{r temperance-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 9

Publish the `two-parameters` quarto document. Copy and paste the link of the published document.

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Your answer should look something like:

```         
https://rpubs.com/MihirKaushal/two-parameters
```


## Summary
### 

This tutorial covered [Chapter 5: Two Parameters](https://ppbds.github.io/primer/two-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/).

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
